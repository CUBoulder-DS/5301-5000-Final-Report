{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some setup notes and Help - \n",
    "Patrick Connelly\n",
    "pconnell89@gmail.com\n",
    "\n",
    "Getting Fair Face Up-and-running\n",
    "\n",
    "To get all of the data to start some work, I began by downloading some files and storing them in a folder structure.\n",
    "\n",
    "Spreadsheet/CSV is located here: https://github.com/Raschka-research-group/coral-cnn/tree/master/datasets.  I believe I was using the afad_test csv.\n",
    "\n",
    "The images themselves for AFAD (Asian Face Age Dataset) are tarballs located in a separate repo on github: https://github.com/John-niu-07/tarball.  To decompress / extract them, you can use 7-zip on windows, or tar xvf filename_here on linux or mac.\n",
    "\n",
    "Some other dependencies - \n",
    "\n",
    "    1) Install windows subsystem for linux (WSL)\n",
    "\n",
    "    2) Simple method for Windows - install miniconda on WSL\n",
    "\n",
    "        - enter WSL shell\n",
    "    \n",
    "        - wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "    \n",
    "        - bash Miniconda3-latest-Linux-x86_64.sh\n",
    "    \n",
    "        - rm Miniconda3-latest-Linux-x86_64.sh\n",
    "    \n",
    "        - conda init\n",
    "    \n",
    "        - conda activate\n",
    "\n",
    "    3) Create a python env within conda (https://learn.microsoft.com/en-us/windows/ai/directml/gpu-pytorch-windows)\n",
    "\n",
    "        - conda create --name directml python=3.8 ipython (or whatever you want) \n",
    "\n",
    "        - conda activate directml (to enter the environment)\n",
    "\n",
    "        - Within the environment - \n",
    "\n",
    "            a) Install Python 3.8\n",
    "\n",
    "            b) Pip install torch - https://pytorch.org/get-started/locally/\n",
    "\n",
    "            c) Pip torch_directml, numpy, pandas, dlib, deepface\n",
    "\n",
    "Overall purpose of the code in this file is to identify locally stored and unzipped data, and use that to filter down the spreadsheet of data from a source dataset. \n",
    "The output provides you with a csv called \"img_paths\" which can be fed to deepFaceIteration.py or to predict.py as a parameter for iteration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FairFace and DeepFace Master Script\n",
    "Author: Patrick Connelly\n",
    "Purpose:\n",
    "\n",
    "Design scripts that provide ease of running both the FairFace and DeepFace models within a Python 3.8 environment\n",
    "\n",
    "Non-Functional Facial Detection Backends (DeepFace):\n",
    "\n",
    "* ssd\n",
    "* dlib\n",
    "* mediapipe\n",
    "* yolov8\n",
    "* yunet\n",
    "\n",
    "This leaves opencv, ssd, mtcnn, and retinaface as available facial detection backends.\n",
    "\n",
    "ssd requires resizing and opencv commonly fails to detect faces with parameter enforce_detection = True.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading and Setting Up FairFace\n",
    "\n",
    "* Clone the repo:\n",
    "* install dependencies (PyTorch, pandas, dlib)\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fairface modified code.\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch_directml\n",
    "import dlib\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "def rect_to_bb(rect):\n",
    "\t# take a bounding predicted by dlib and convert it\n",
    "\t# to the format (x, y, w, h) as we would normally do\n",
    "\t# with OpenCV\n",
    "\tx = rect.left()\n",
    "\ty = rect.top()\n",
    "\tw = rect.right() - x\n",
    "\th = rect.bottom() - y\n",
    "\t# return a tuple of (x, y, w, h)\n",
    "\treturn (x, y, w, h)\n",
    "\n",
    "def detect_face(image_paths,  SAVE_DETECTED_AT, default_max_size=800,size = 300, padding = 0.25):\n",
    "    cnn_face_detector = dlib.cnn_face_detection_model_v1('dlib_models/mmod_human_face_detector.dat')\n",
    "    sp = dlib.shape_predictor('dlib_models/shape_predictor_5_face_landmarks.dat')\n",
    "    base = 2000  # largest width and height\n",
    "    for index, image_path in enumerate(image_paths):\n",
    "        if index % 1000 == 0:\n",
    "            print('---%d/%d---' %(index, len(image_paths)))\n",
    "        img = dlib.load_rgb_image(image_path)\n",
    "\n",
    "        old_height, old_width, _ = img.shape\n",
    "\n",
    "        if old_width > old_height:\n",
    "            new_width, new_height = default_max_size, int(default_max_size * old_height / old_width)\n",
    "        else:\n",
    "            new_width, new_height =  int(default_max_size * old_width / old_height), default_max_size\n",
    "        img = dlib.resize_image(img, rows=new_height, cols=new_width)\n",
    "\n",
    "        dets = cnn_face_detector(img, 1)\n",
    "        num_faces = len(dets)\n",
    "        if num_faces == 0:\n",
    "            print(\"Sorry, there were no faces found in '{}'\".format(image_path))\n",
    "            continue\n",
    "        # Find the 5 face landmarks we need to do the alignment.\n",
    "        faces = dlib.full_object_detections()\n",
    "        for detection in dets:\n",
    "            rect = detection.rect\n",
    "            faces.append(sp(img, rect))\n",
    "        images = dlib.get_face_chips(img, faces, size=size, padding = padding)\n",
    "        for idx, image in enumerate(images):\n",
    "            img_name = image_path.split(\"/\")[-1]\n",
    "            path_sp = img_name.split(\".\")\n",
    "            face_name = os.path.join(SAVE_DETECTED_AT,  path_sp[0] + \"_\" + \"face\" + str(idx) + \".\" + path_sp[-1])\n",
    "            dlib.save_image(image, face_name)\n",
    "\n",
    "def detect_face_single(image_path, save=False, SAVE_DETECTED_AT='', default_max_size=800, size=300, padding-0.25):\n",
    "    cnn_face_detector = dlib.cnn_face_detection_model_v1('dlib_models/mmod_human_face_detector.dat')\n",
    "    sp = dlib.shape_predictor('dlib_models/shape_predictor_5_face_landmarks.dat')\n",
    "    base = 2000\n",
    "    img = dlib.load_rgb_image(image_path)\n",
    "    old_height,old_width, _ = img.shape\n",
    "    if old_width > old_height:\n",
    "        new_width, new_height = default_max_size, int(default_max_size * old_height / old_width)\n",
    "    else:\n",
    "        new_width, new_height =  int(default_max_size * old_width / old_height), default_max_size\n",
    "    img = dlib.resize_image(img, rows=new_height, cols=new_width)\n",
    "    dets = cnn_face_detector(img, 1)\n",
    "    num_faces = len(dets)\n",
    "    if num_faces == 0:\n",
    "        print(\"Sorry, there were no faces found in '{}'\".format(image_path))\n",
    "    # Find the 5 face landmarks we need to do the alignment.\n",
    "    faces = dlib.full_object_detections()\n",
    "\n",
    "    for detection in dets:\n",
    "        rect = detection.rect\n",
    "        faces.append(sp(img, rect))\n",
    "\n",
    "    images = dlib.get_face_chips(img, faces, size=size, padding = padding)\n",
    "    # for idx, image in enumerate(images):\n",
    "    #     img_name = image_path.split(\"/\")[-1]\n",
    "    #     path_sp = img_name.split(\".\")\n",
    "    #     face_name = os.path.join(SAVE_DETECTED_AT,  path_sp[0] + \"_\" + \"face\" + str(idx) + \".\" + path_sp[-1])\n",
    "    #     dlib.save_image(image, face_name)\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def save_preprocessed(SAVE_DETECTED_AT,images):\n",
    "    for idx, image in enumerate(images):\n",
    "        img_name = image_path.split(\"/\")[-1]\n",
    "        path_sp = img_name.split(\".\")\n",
    "        face_name = os.path.join(SAVE_DETECTED_AT,  path_sp[0] + \"_\" + \"face\" + str(idx) + \".\" + path_sp[-1])\n",
    "        dlib.save_image(image, face_name)\n",
    "\n",
    "\n",
    "def get_os_torch_device():\n",
    "    dev = None\n",
    "    if torch.cuda.is_available():\n",
    "        dev = torch.device('cuda:0')\n",
    "    else:\n",
    "        dev = torch.device(torch_directml.device())\n",
    "    \n",
    "    return dev\n",
    "\n",
    "device = get_os_torch_device()\n",
    "model_fair_7.fc = nn.Linear(model_fair_7.fc.in_featurese,18)\n",
    "\n",
    "def pred_age_gen_race_single(save_prediction_at,img_path,enforce_detection=False):\n",
    "    if enforce_detection == True:\n",
    "        #assume single face\n",
    "        image = detect_face_single(img_path)[0]\n",
    "    else:\n",
    "        image = dlib.load_rgb_image(img_path)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    pass\n",
    "\n",
    "def predidct_age_gender_race(save_prediction_at, imgs_path = 'cropped_faces/'):\n",
    "    img_names = [os.path.join(imgs_path, x) for x in os.listdir(imgs_path)]\n",
    "    #original code line\n",
    "    #device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #added torch_directml to allow evaluation to take place on GPU with model loaded to CPU. It's weird but works on AMD.\n",
    "    device = torch.device(torch_directml.device())\n",
    "    model_fair_7 = torchvision.models.resnet34(pretrained=True)\n",
    "    model_fair_7.fc = nn.Linear(model_fair_7.fc.in_features, 18)\n",
    "    #original code line\n",
    "    #model_fair_7.load_state_dict(torch.load('fair_face_models/fairface_alldata_20191111.pt'))\n",
    "    #changed this to match the filename of the online downloadable dataseet and to use CPU because I have AMD graphics, and torch.load doesn't like directml\n",
    "    model_fair_7.load_state_dict(torch.load('fair_face_models/res34_fair_align_multi_7_20190809.pt',map_location=torch.device('cpu')))\n",
    "    model_fair_7 = model_fair_7.to(device)\n",
    "    model_fair_7.eval()\n",
    "\n",
    "    model_fair_4 = torchvision.models.resnet34(pretrained=True)\n",
    "    model_fair_4.fc = nn.Linear(model_fair_4.fc.in_features, 18)\n",
    "    #original code line\n",
    "    #model_fair_4.load_state_dict(torch.load('fair_face_models/fairface_alldata_4race_20191111.pt'))\n",
    "    #changed this to match the filename of the online downloadable dataseet and to use CPU because I have AMD graphics, and torch.load doesn't like directml\n",
    "    model_fair_4.load_state_dict(torch.load('fair_face_models/res34_fair_align_multi_4_20190809.pt',map_location=torch.device('cpu')))\n",
    "    model_fair_4 = model_fair_4.to(device)\n",
    "    model_fair_4.eval()\n",
    "\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    # img pth of face images\n",
    "    face_names = []\n",
    "    # list within a list. Each sublist contains scores for all races. Take max for predicted race\n",
    "    race_scores_fair = []\n",
    "    gender_scores_fair = []\n",
    "    age_scores_fair = []\n",
    "    race_preds_fair = []\n",
    "    gender_preds_fair = []\n",
    "    age_preds_fair = []\n",
    "    race_scores_fair_4 = []\n",
    "    race_preds_fair_4 = []\n",
    "\n",
    "    for index, img_name in enumerate(img_names):\n",
    "        if index % 1000 == 0:\n",
    "            print(\"Predicting... {}/{}\".format(index, len(img_names)))\n",
    "\n",
    "        face_names.append(img_name)\n",
    "        image = dlib.load_rgb_image(img_name)\n",
    "        image = trans(image)\n",
    "        image = image.view(1, 3, 224, 224)  # reshape image to match model dimensions (1 batch size)\n",
    "        image = image.to(device)\n",
    "\n",
    "        # fair\n",
    "        outputs = model_fair_7(image)\n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        outputs = np.squeeze(outputs)\n",
    "\n",
    "        race_outputs = outputs[:7]\n",
    "        gender_outputs = outputs[7:9]\n",
    "        age_outputs = outputs[9:18]\n",
    "\n",
    "        race_score = np.exp(race_outputs) / np.sum(np.exp(race_outputs))\n",
    "        gender_score = np.exp(gender_outputs) / np.sum(np.exp(gender_outputs))\n",
    "        age_score = np.exp(age_outputs) / np.sum(np.exp(age_outputs))\n",
    "\n",
    "        race_pred = np.argmax(race_score)\n",
    "        gender_pred = np.argmax(gender_score)\n",
    "        age_pred = np.argmax(age_score)\n",
    "\n",
    "        race_scores_fair.append(race_score)\n",
    "        gender_scores_fair.append(gender_score)\n",
    "        age_scores_fair.append(age_score)\n",
    "\n",
    "        race_preds_fair.append(race_pred)\n",
    "        gender_preds_fair.append(gender_pred)\n",
    "        age_preds_fair.append(age_pred)\n",
    "\n",
    "        # fair 4 class\n",
    "        outputs = model_fair_4(image)\n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        outputs = np.squeeze(outputs)\n",
    "\n",
    "        race_outputs = outputs[:4]\n",
    "        race_score = np.exp(race_outputs) / np.sum(np.exp(race_outputs))\n",
    "        race_pred = np.argmax(race_score)\n",
    "\n",
    "        race_scores_fair_4.append(race_score)\n",
    "        race_preds_fair_4.append(race_pred)\n",
    "\n",
    "    result = pd.DataFrame([face_names,\n",
    "                           race_preds_fair,\n",
    "                           race_preds_fair_4,\n",
    "                           gender_preds_fair,\n",
    "                           age_preds_fair,\n",
    "                           race_scores_fair, race_scores_fair_4,\n",
    "                           gender_scores_fair,\n",
    "                           age_scores_fair, ]).T\n",
    "    result.columns = ['face_name_align',\n",
    "                      'race_preds_fair',\n",
    "                      'race_preds_fair_4',\n",
    "                      'gender_preds_fair',\n",
    "                      'age_preds_fair',\n",
    "                      'race_scores_fair',\n",
    "                      'race_scores_fair_4',\n",
    "                      'gender_scores_fair',\n",
    "                      'age_scores_fair']\n",
    "    result.loc[result['race_preds_fair'] == 0, 'race'] = 'White'\n",
    "    result.loc[result['race_preds_fair'] == 1, 'race'] = 'Black'\n",
    "    result.loc[result['race_preds_fair'] == 2, 'race'] = 'Latino_Hispanic'\n",
    "    result.loc[result['race_preds_fair'] == 3, 'race'] = 'East Asian'\n",
    "    result.loc[result['race_preds_fair'] == 4, 'race'] = 'Southeast Asian'\n",
    "    result.loc[result['race_preds_fair'] == 5, 'race'] = 'Indian'\n",
    "    result.loc[result['race_preds_fair'] == 6, 'race'] = 'Middle Eastern'\n",
    "\n",
    "    # race fair 4\n",
    "\n",
    "    result.loc[result['race_preds_fair_4'] == 0, 'race4'] = 'White'\n",
    "    result.loc[result['race_preds_fair_4'] == 1, 'race4'] = 'Black'\n",
    "    result.loc[result['race_preds_fair_4'] == 2, 'race4'] = 'Asian'\n",
    "    result.loc[result['race_preds_fair_4'] == 3, 'race4'] = 'Indian'\n",
    "\n",
    "    # gender\n",
    "    result.loc[result['gender_preds_fair'] == 0, 'gender'] = 'Male'\n",
    "    result.loc[result['gender_preds_fair'] == 1, 'gender'] = 'Female'\n",
    "\n",
    "    # age\n",
    "    result.loc[result['age_preds_fair'] == 0, 'age'] = '0-2'\n",
    "    result.loc[result['age_preds_fair'] == 1, 'age'] = '3-9'\n",
    "    result.loc[result['age_preds_fair'] == 2, 'age'] = '10-19'\n",
    "    result.loc[result['age_preds_fair'] == 3, 'age'] = '20-29'\n",
    "    result.loc[result['age_preds_fair'] == 4, 'age'] = '30-39'\n",
    "    result.loc[result['age_preds_fair'] == 5, 'age'] = '40-49'\n",
    "    result.loc[result['age_preds_fair'] == 6, 'age'] = '50-59'\n",
    "    result.loc[result['age_preds_fair'] == 7, 'age'] = '60-69'\n",
    "    result.loc[result['age_preds_fair'] == 8, 'age'] = '70+'\n",
    "\n",
    "    result[['face_name_align',\n",
    "            'race', 'race4',\n",
    "            'gender', 'age',\n",
    "            'race_scores_fair', 'race_scores_fair_4',\n",
    "            'gender_scores_fair', 'age_scores_fair']].to_csv(save_prediction_at, index=False)\n",
    "\n",
    "    print(\"saved results at \", save_prediction_at)\n",
    "\n",
    "\n",
    "def ensure_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "def detect_ind_face(image_path,  SAVE_DETECTED_AT):\n",
    "    frame=pd.DataFrame({'img_path':[image_path]})\n",
    "    image_paths = frame['img_path']\n",
    "    detect_face(image_paths,  SAVE_DETECTED_AT)\n",
    "\n",
    "def analyze_ind_face(save_prediction_at, imgs_path = 'cropped_faces/'):\n",
    "    pass\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     #Please create a csv with one column 'img_path', contains the full paths of all images to be analyzed.\n",
    "#     #Also please change working directory to this file.\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--csv', dest='input_csv', action='store',\n",
    "#                         help='csv file of image path where col name for image path is \"img_path')\n",
    "#     dlib.DLIB_USE_CUDA = False #True\n",
    "#     print(\"using CUDA?: %s\" % dlib.DLIB_USE_CUDA)\n",
    "#     args = parser.parse_args()\n",
    "#     SAVE_DETECTED_AT = \"detected_faces\"\n",
    "#     ensure_dir(SAVE_DETECTED_AT)\n",
    "#     imgs = pd.read_csv(args.input_csv)['img_path']\n",
    "#     detect_face(imgs, SAVE_DETECTED_AT)\n",
    "#     print(\"detected faces are saved at \", SAVE_DETECTED_AT)\n",
    "#     #Please change test_outputs.csv to actual name of output csv. \n",
    "#     predidct_age_gender_race(\"test_outputs.csv\", SAVE_DETECTED_AT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "afad_test = pd.read_csv('C:\\\\Users\\\\pconn\\\\OneDrive\\\\Desktop\\\\AFAD-Full\\\\afad_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I pull in the CSV from the Asian Face Dataset.  I downloaded the CSV and one chunk of the images locally.\n",
    "\n",
    "This first block below is just to test and verify that I was able to bring in the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>path</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>406208-0.jpg</td>\n",
       "      <td>39/112/406208-0.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>470804-0.jpg</td>\n",
       "      <td>39/112/470804-0.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>411657-2.jpg</td>\n",
       "      <td>39/112/411657-2.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>471528-2.jpg</td>\n",
       "      <td>39/112/471528-2.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>398608-1.jpg</td>\n",
       "      <td>39/112/398608-1.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>470572-0.jpg</td>\n",
       "      <td>39/112/470572-0.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>401238-0.jpg</td>\n",
       "      <td>39/112/401238-0.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           file                 path  age  gender\n",
       "0  406208-0.jpg  39/112/406208-0.jpg   24  female\n",
       "1  470804-0.jpg  39/112/470804-0.jpg   24  female\n",
       "2  411657-2.jpg  39/112/411657-2.jpg   24  female\n",
       "3  471528-2.jpg  39/112/471528-2.jpg   24  female\n",
       "4  398608-1.jpg  39/112/398608-1.jpg   24  female\n",
       "5  470572-0.jpg  39/112/470572-0.jpg   24  female\n",
       "6  401238-0.jpg  39/112/401238-0.jpg   24  female"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afad_test = pd.read_csv('C:\\\\Users\\\\pconn\\\\OneDrive\\\\Desktop\\\\AFAD-Full\\\\afad_test.csv')\n",
    "afad_test.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spreadsheet/CSVs were located here on the web: https://github.com/Raschka-research-group/coral-cnn/tree/master/datasets \n",
    "\n",
    "The images themselves are tarballs located in a separate repo on github: https://github.com/John-niu-07/tarball.\n",
    "\n",
    "In terms of this dataset - the images are \"chunked\" into tarball/zip files in GitHub for the AFAD dataset.  The spreadsheet/csv, however, has a listing of ALL file paths for all files in the dataset.  In order to get to a point where I could only iterate over the target files, I had to do a directory walk to identify only .jpg files, searching recursively through a local folder.  \n",
    "\n",
    "This folder ahd the repo / files from a git clone of FairFace, models downloaded separately from Google Drive (not in the GitHub repo directly), the chunk of images from the AFAD dataface extracted into two subfolders, and the full spreadsheet of all items in the AFAD dataset.\n",
    "\n",
    "So I did the directory walk to get a list of all JPGs.  I left-joined the source spreadsheet (left table) to the present files (right table), and then filtered where the right table was blank/NA, so that the result was a table only of the available files for iteration, and then wrote that out to a csv.\n",
    "\n",
    "I used this to build my input for my deepFaceIteration.py script and the modified version of predict.py from the FairFace model.\n",
    "\n",
    "I didn't set this up with functions or parameters (i.e. tell me where you wanna save the file).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"C:\\\\Users\\\\pconn\\\\OneDrive\\\\Desktop\\\\AFAD-Full\"\n",
    "EXT = \"*.jpg\"\n",
    "\n",
    "# get a list of all filenames recursively from the current directory in which this script runs\n",
    "# and down into any subfolders as well\n",
    "\n",
    "all_jpg = [file \n",
    "           for path, subdir, files in os.walk(PATH)\n",
    "           for file in glob(os.path.join(path,EXT))]\n",
    "\n",
    "#can be used to verify how many you identified in the local folder(s)\n",
    "#len(all_jpg)\n",
    "#all_jpg[0]\n",
    "\n",
    "present_files = pd.DataFrame({'jpgs': all_jpg})\n",
    "present_files['file']=(present_files['jpgs'].str.split('\\\\')).str[-1]\n",
    "present_files\n",
    "\n",
    "#do a left join between the files we know could exist (left) and the files we found (right)\n",
    "#filter the list down only to items where there was a match as well (maybe inner join is smarter)\n",
    "merged=afad_test.merge(present_files,on='file',how='left')\n",
    "merged = merged[merged['jpgs'].notna()]\n",
    "\n",
    "#trim and generate the output file!\n",
    "merged['jpgs'] = merged['jpgs'].str.replace('C:\\\\Users\\\\pconn\\\\OneDrive\\\\Desktop\\\\AFAD-Full','.')\n",
    "merged['img_path'] = merged['jpgs']\n",
    "merged=merged.drop(labels=['jpgs','path','file','age','gender'],axis=1)\n",
    "\n",
    "merged.to_csv('C:\\\\Users\\\\pconn\\\\OneDrive\\\\Desktop\\\\AFAD-Full\\\\afad_loc_clean.csv',index=False)\n",
    "\n",
    "len(merged)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
