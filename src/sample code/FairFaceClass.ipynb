{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First - install dependencies in your local machine or python environment (Python 3.8):\n",
    "```\n",
    "pip install torch #reference torch documentation for correct install commands for your system: https://pytorch.org/get-started/locally/\n",
    "pip install torch_directml #necessary if you have windows with windows sub-system for linux (WSL) to achieve a degree of optimization in Python 3.8\n",
    "pip install numpy #you probably already have it\n",
    "pip install pandas #you probably already have it\n",
    "pip install dlib #easiest to handle on linux / mac systems - in Windows it's a nightmare and will take me about 8 hrs to document.\n",
    "pip install deepface \n",
    "```\n",
    "\n",
    "Here, we've taken the script from the FairFace GitHub and converted it to a class.  We did this out of necessity, as we sought the ability to evaluate one image at a time, or images in a batch, as well as the ability to classify an image with or without pre-processing (and optionally, without storing the pre-processed image).  Without a class, it would have required re-loading the detection and classification models to CPU/GPU with every function call.  As such, we built this class which gave us the flexibility we sought in processing our data.\n",
    "\n",
    "This class can be used as part of the script, or could potentially be re-uploaded back to the FairFace GitHub, potentially advancing its design so that it could eventually become a pip package installable similar to DeepFace for ease of use by others.\n",
    "\n",
    "To be able to use this class and script, you must first download or clone the FairFace package from GitHub directly (not currently a pip package).  You can do that here:\n",
    "https://github.com/dchen236/FairFace\n",
    "\n",
    "After you've pulled the file, you'll need to download copies of the models and save them in a new folder called fair_face_models.  Models are located here: https://drive.google.com/drive/folders/1F_pXfbzWvG-bhCpNsRj6F_xsdjpesiFu\n",
    "\n",
    "After you do these steps, you can store this script in the main folder where you've saved/copied the FairFace repository. \n",
    "\n",
    "From there, I recommend you get access to/download any images you wish to process and store them in a local folder, and use some code to generate a CSV of all the files in that folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch_directml\n",
    "import dlib\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "\n",
    "class fairface:\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "        \"\"\"_summary_\n",
    "        return instance of the FairFace class with models loaded to CPU/GPU\n",
    "        leverages torch_directml for users with AMD GPU systems (especially on Linux)\n",
    "        \"\"\"\n",
    "        self.cnn_face_detector = dlib.cnn_face_detection_model_v1('dlib_models/mmod_human_face_detector.dat')\n",
    "        self.sp = dlib.shape_predictor('dlib_models/shape_predictor_5_face_landmarks.dat')\n",
    "        self.base = 2000\n",
    "        self.__device = torch.device(\"cuda:0\" if torch.cuda.is_available() else torch_directml.device())\n",
    "        self.__map_location= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.__model_fair_7 = torchvision.models.resnet34(pretrained=True)\n",
    "        self.__model_fair_7.fc = nn.Linear(self.__model_fair_7.fc.in_features, 18)\n",
    "        self.__model_fair_7 = self.__model_fair_7.to(self.__device)\n",
    "        self.__model_fair_7.eval()\n",
    "        self.__model_fair_4 = torchvision.models.resnet34(pretrained=True)\n",
    "        self.__model_fair_4.fc = nn.Linear(self.__model_fair_4.fc.in_features, 18)\n",
    "        self.__model_fair_4 = self.__model_fair_4.to(self.__device)\n",
    "        self.__model_fair_4.eval()\n",
    "\n",
    "        self.__save_detections_at = \"\"\n",
    "        self.__trans = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.__load_state_dicts()\n",
    "\n",
    "    def __load_state_dicts(self):\n",
    "        \"\"\"_summary_\n",
    "        loads the appropriate FairFace Detection model to the appropriate device (CPU/GPU)\n",
    "        \"\"\"\n",
    "        self.__model_fair_7.load_state_dict(torch.load('fair_face_models/res34_fair_align_multi_7_20190809.pt',map_location=self.__map_location))\n",
    "        self.__model_fair_7 = self.__model_fair_7.to(self.__device)\n",
    "        self.__model_fair_7.eval()        \n",
    "        self.__model_fair_4.load_state_dict(torch.load('fair_face_models/res34_fair_align_multi_4_20190809.pt',map_location=self.__map_location))\n",
    "        self.__model_fair_4 = self.__model_fair_4.to(self.__device)\n",
    "        self.__model_fair_4.eval()\n",
    "\n",
    "    def set_save_location(self,path):\n",
    "        \"\"\"_summary_\n",
    "        not sure this function is needed.\n",
    "        Args:\n",
    "            path (_type_): string - path to save location\n",
    "        \"\"\"\n",
    "        self.__save_detections_at = path\n",
    "        self.__ensure_dir(path)\n",
    "\n",
    "    def __ensure_dir(self,directory):\n",
    "        \"\"\"_summary_\n",
    "        This function may not be needed.\n",
    "        Args:\n",
    "            directory (_type_): path to a folder / location to ensure it exists\n",
    "        \"\"\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "    def detect_face(self, img_path, default_max_size = 800, size=300, padding=0.25,\n",
    "                    save=False):\n",
    "        \"\"\"detects faces in an image; serves as a helper function to analyze function\n",
    "            if enforce_detection is enabled.\n",
    "            returns an image if save is False, otherwise saves the image at self.__save_location\n",
    "            for later processing\n",
    "        Args:\n",
    "            img_path (string): filepath to an image in which to detect faces\n",
    "            default_max_size (int, optional): Defaults to 800.\n",
    "            size (int, optional):  Defaults to 300.\n",
    "            padding (float, optional):  Defaults to 0.25.\n",
    "            save (bool, optional): If true, will save a .jpg file of the input file at self.__save_location. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: an opened, pre-processed/cropped image focused on a face for categorization models.\n",
    "        \"\"\"\n",
    "        #print(os.path.join(img_path))\n",
    "        img = dlib.load_rgb_image(os.path.join(img_path))\n",
    "        old_height, old_width, _ = img.shape\n",
    "        if old_width > old_height:\n",
    "            new_width, new_height = default_max_size, int(default_max_size * old_height / old_width)\n",
    "        else:\n",
    "            new_width, new_height =  int(default_max_size * old_width / old_height), default_max_size\n",
    "        img = dlib.resize_image(img, rows=new_height, cols=new_width)\n",
    "        dets = self.cnn_face_detector(img, 1)\n",
    "        num_faces = len(dets)\n",
    "        if num_faces == 0:\n",
    "            print(\"Sorry, there were no faces found in '{}'\".format(img_path))\n",
    "        # Find the 5 face landmarks we need to do the alignment.\n",
    "        else:\n",
    "            faces = dlib.full_object_detections()\n",
    "            for detection in dets:\n",
    "                rect = detection.rect\n",
    "                faces.append(self.sp(img, rect))\n",
    "            images = dlib.get_face_chips(img, faces, size=size, padding = padding)\n",
    "            if save: \n",
    "                for idx, image in enumerate(images):\n",
    "                    img_name = img_path.split(\"/\")[-1]\n",
    "                    path_sp = img_name.split(\".\")\n",
    "                    face_name = os.path.join(self.__save_detections_at,  path_sp[0] + \"_\" + \"face\" + str(idx) + \".\" + path_sp[-1])\n",
    "                    dlib.save_image(image, face_name)\n",
    "                print(\"Saved detected face(s) at \"+self.__save_detections_at)\n",
    "            else:\n",
    "                return images\n",
    "\n",
    "    def analyze(self,image,mode='fair7',enforce_detection=True):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            image (str): relative filepath to an image from the current directory\n",
    "            mode (str, optional): options include 'fair4' and 'fair7' for the respective FairFace models. Defaults to 'fair7'.\n",
    "            enforce_detection (bool, optional): Allows this function and the selected model to evaluate an image directly without preprocessing. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            result (pandas DataFrame): a dataframe with the respective predictions and calculations from the selected FairFace model on the provided image.\n",
    "        \"\"\"\n",
    "        indices={'race_start':0,'race_end':0,'gen_start':0,'gen_end':0,'age':0}\n",
    "        race_scores,gender_scores,age_scores=[],[],[]\n",
    "        race_pred,gender_pred,age_pred = [],[],[]\n",
    "        face_names = []\n",
    "        face_names.append(image)\n",
    "        race_dict={}\n",
    "        gender_dict = {0:'Male',1:'Female'}\n",
    "        age_dict = {\n",
    "            0:'0-2',\n",
    "            1:'3-9',\n",
    "            2:'10-19',\n",
    "            3:'20-29',\n",
    "            4:'30-39',\n",
    "            5:'40-49',\n",
    "            6:'50-59',\n",
    "            7:'60-69',\n",
    "            8:'70+'\n",
    "        }\n",
    "        if mode == 'fair7':\n",
    "            #print('fair7')\n",
    "            #outputs = self.__model_fair_7(image)\n",
    "            race_dict = {\n",
    "                0:'White',\n",
    "                1:'Black',\n",
    "                2:'Latino_Hispanic',\n",
    "                3:'East Asian',\n",
    "                4:'Southeast Asian',\n",
    "                5:'Indian',\n",
    "                6:'Middle Eastern'\n",
    "            }\n",
    "            indices={'race_start':0,'race_end':7,'gen_start':7,'gen_end':9,'age_start':9,'age_end':18}\n",
    "        elif mode == 'fair4':\n",
    "            #print('fair4')\n",
    "            #outputs = self.__model_fair_4(image)\n",
    "            race_dict = {\n",
    "                0:'White',\n",
    "                1:'Black',\n",
    "                2:'Asian',\n",
    "                3:'Indian',\n",
    "            }\n",
    "            indices={}\n",
    "        else:\n",
    "            print(\"unsupported mode.\")\n",
    "\n",
    "        if enforce_detection:\n",
    "            image = self.__trans(self.detect_face(image)[0])\n",
    "        else:\n",
    "            #print(os.path.join(image))\n",
    "            image = self.__trans(dlib.load_rgb_image(os.path.join(image)))\n",
    "        \n",
    "        image=image.view(1,3,224,224)\n",
    "        image=image.to(self.__device)\n",
    "\n",
    "        outputs = None\n",
    "\n",
    "        if mode=='fair7':\n",
    "            outputs = self.__model_fair_7(image)\n",
    "        else:\n",
    "            outputs = self.__model_fair_4(image)\n",
    "        \n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        outputs = np.squeeze(outputs)\n",
    "        race_outputs,gender_outputs,age_outputs=[],[],[]\n",
    "        race_score,gender_score,age_score=0,0,0\n",
    "        #print(\"Outputs: \", outputs)\n",
    "        gender_outputs = outputs[7:9]\n",
    "        age_outputs = outputs[9:18]\n",
    "        if mode=='fair7':\n",
    "            race_outputs = outputs[:7]\n",
    "            race_score = np.exp(race_outputs) / np.sum(np.exp(race_outputs))\n",
    "        else:\n",
    "            race_outputs = outputs[:4]\n",
    "            race_score = np.exp(race_outputs) / np.sum(np.exp(race_outputs))\n",
    "\n",
    "        race_pred = np.argmax(race_score)\n",
    "        gender_score = np.exp(gender_outputs) / np.sum(np.exp(gender_outputs))\n",
    "        age_score = np.exp(age_outputs) / np.sum(np.exp(age_outputs))\n",
    "        gender_pred = np.argmax(gender_score)\n",
    "        age_pred=np.argmax(age_score)\n",
    "\n",
    "        race_scores.append(race_score)\n",
    "        age_scores.append(age_score)\n",
    "        gender_scores.append(gender_score)\n",
    "        #print(face_names,race_pred,gender_pred,age_pred,race_scores,gender_scores,age_scores)\n",
    "        result = pd.DataFrame(\n",
    "               [face_names,\n",
    "                [race_pred],\n",
    "                [gender_pred],\n",
    "                [age_pred],\n",
    "                race_scores, \n",
    "                gender_scores,\n",
    "                age_scores] \n",
    "        ).T\n",
    "        result.columns = ['face_name_align',\n",
    "                'race_preds_fair',\n",
    "                'gender_preds_fair',\n",
    "                'age_preds_fair',\n",
    "                'race_scores_fair',\n",
    "                'gender_scores_fair',\n",
    "                'age_scores_fair']\n",
    "        #result[['race','gender','age']] = '','',''\n",
    "        #print(result)\n",
    "        result['race_preds_fair'] = result.apply(lambda row: race_dict[row['race_preds_fair']],axis=1)\n",
    "        result['gender_preds_fair']=result.apply(lambda row: gender_dict[row['gender_preds_fair']],axis=1)\n",
    "        result['age_preds_fair']=result.apply(lambda row: age_dict[row['age_preds_fair']],axis=1)\n",
    "        \n",
    "        return result[['face_name_align',\n",
    "                'race_preds_fair',\n",
    "                'gender_preds_fair',\n",
    "                'age_preds_fair',\n",
    "                'race_scores_fair',\n",
    "                'gender_scores_fair',\n",
    "                'age_scores_fair']]\n",
    "\n",
    "    def get_map_loc(self):\n",
    "        \"\"\"debugging function to ensure the correct available device(s) (cpu,gpu) are available and used\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        return self.__map_location\n",
    "\n",
    "    def get_device(self):\n",
    "        \"\"\"debugging function to ensure the correct available device(s) (cpu,gpu) are available and used\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        return self.__device\n",
    "\n",
    "    def batch_detect_analyze(self, img_paths):\n",
    "        #function not currently used and can be improved upon.\n",
    "        for i, img in enumerate(img_paths):\n",
    "            self.detect_face(img)\n",
    "        img_names = [os.path.join(img_paths, x) for x in os.listdir(img_paths)]\n",
    "        for img in img_names:\n",
    "            self.analyze_face(self.__save_detections_at+'/'+img)\n",
    "        return 0\n",
    "\n",
    "    def _rect_to_bb(self,rect):\n",
    "        \"\"\"function was present and undocumented in original script\n",
    "        code was not used elsewhere within the source script\n",
    "\n",
    "        Args:\n",
    "            rect (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        # take a bounding predicted by dlib and convert it\n",
    "        # to the format (x, y, w, h) as we would normally do\n",
    "        # with OpenCV\n",
    "        x = rect.left()\n",
    "        y = rect.top()\n",
    "        w = rect.right() - x\n",
    "        h = rect.bottom() - y\n",
    "        # return a tuple of (x, y, w, h)\n",
    "        return (x, y, w, h)        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If seeking to use both models, they must be imported and instantiated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an instance of the fairface class\n",
    "#class may benefit from being turned into a singleton\n",
    "#or an importable module.\n",
    "FairFace = fairface()\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def create_image_csv(target_folder):\n",
    "#     pass\n",
    "\n",
    "def batch_analyze(model, in_csv, out_csv, preprocess=True):\n",
    "    \"\"\"allows user to select a facial recognition/categorization model \n",
    "    and a CSV of image file locations to evaluate all those images against the selected model,\n",
    "    and output the results to a CSV.\n",
    "\n",
    "    Note:  The column with paths to the image files' directory are relative paths, and the column in the \n",
    "    CSV containing those paths must be labeled 'img_path'\n",
    "\n",
    "    Args:\n",
    "        model (str): 'FairFace' or 'DeepFace' - model to use when evaluating images\n",
    "        in_csv (str): relative path location to a CSV containing paths to images for evaluation\n",
    "        out_csv (_type_): relative path location and name in which to store output for this evaluation\n",
    "        preprocess (bool, optional): if true, facial detection is performed on each image within the given model before it performs image classification. Defaults to True.\n",
    "    \"\"\"\n",
    "    files = pd.read_csv(os.path.join(in_csv))['img_path']\n",
    "    result=[]\n",
    "    if model == 'FairFace':\n",
    "        for index,record in enumerate(files):\n",
    "            #print(record)\n",
    "            curr = FairFace.analyze(os.path.join(record),mode='fair7',enforce_detection=preprocess)\n",
    "            if len(result)==0:\n",
    "                result = curr\n",
    "            else:\n",
    "                result = pd.concat([result,curr])\n",
    "    else:\n",
    "        backend=input('select DeepFace Detector Backend: ')\n",
    "        #cat_model=input('select DeepFace model: ')\n",
    "        for index,record in enumerate(files):\n",
    "            #DeepFace.analyze(img_path=image_path,enforce_detection=False,silent=True)[0]\n",
    "            print(record)\n",
    "\n",
    "            try:\n",
    "                curr = DeepFace.analyze(img_path=record,enforce_detection=preprocess,actions=['age','gender','race'],silent=True,detector_backend=backend)\n",
    "                #print(\"Post-analysis:\",curr)\n",
    "                curr=curr[0]\n",
    "                del curr['gender']\n",
    "                del curr['race']\n",
    "                del curr['region']\n",
    "                print(curr)\n",
    "                curr = pd.DataFrame(curr,index=[0])\n",
    "                #print(curr)\n",
    "                #print(result)\n",
    "                if len(result) == 0:\n",
    "                    result = pd.DataFrame(curr)\n",
    "                else:\n",
    "                    result = pd.concat([result,curr])\n",
    "                #print(result,'\\n\\n\\n\\n\\n')\n",
    "            except:\n",
    "                print(\"error processing {}\".format(record))\n",
    "    \n",
    "    result.to_csv(os.path.join(out_csv))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below section allows this to be run via command line as follows:\n",
    "\n",
    "`python MasterScript.py --in_csv [input csv file path] --out_csv [desired output csv file path and name] --model [DeepFace|FairFace] --preproc [True|False]`\n",
    "\n",
    "in_csv parameter allows you to specify an input CSV.  The csv must have, at a minimum, a column with the name img_path that specifies the relative path to the files you'll be working with.\n",
    "\n",
    "out_csv parameter allows you to specify a file to which you wish to write your output.  This is also written with respect to the current directory.\n",
    "\n",
    "model parameter allows you to select whether you're using DeepFace or FairFace.  If DeepFace is selected, you will be prompted to enter the facial detection backend once (recommend using mtcnn or opencv, others are failing to install or showing substantial failure to detect faces)\n",
    "\n",
    "preproc parameter allows you to specify whether or not you wish for the image to have a face detected and pre-processed prior to attempted classification.  Setting to True means that faces will be detected first, and False skips detection and goes straight to classification\n",
    "\n",
    "Also this notebook shouldn't be used directly - it is simply amplifying documentation to better explain the script file MasterScript.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turns this into a command-line script so that it can be called as follows:\n",
    "\n",
    "\"python MasterScript.py --in_csv [input csv file path] --out_csv [desired output csv file path and name] --model [DeepFace|FairFace] --preproc [True|False]\"\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    #in_csv arg\n",
    "    parser.add_argument('--in_csv',dest='in_csv',action='store',\n",
    "                        help='csv containing filepaths to input images to categorize'\n",
    "                        )\n",
    "    #out_csv arg\n",
    "    parser.add_argument('--out_csv',dest='out_csv',action='store',\n",
    "                        help='filename in which to store model output'\n",
    "                        )\n",
    "    #model arg\n",
    "    parser.add_argument('--model',dest='model',action='store',\n",
    "                        help='FairFace or DeepFace'\n",
    "                        )\n",
    "    #preprocess arg\n",
    "    parser.add_argument('--preproc',dest='preproc',action='store',\n",
    "                        help='True or False - preprocess images before evaluating'\n",
    "                        )\n",
    "    args=parser.parse_args()\n",
    "    batch_analyze(args.model,args.in_csv,args.out_csv,args.preproc)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
