{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First - install dependencies in your local machine or python environment (Python 3.8):\n",
    "```\n",
    "pip install torch #reference torch documentation for correct install commands for your system: https://pytorch.org/get-started/locally/\n",
    "pip install torch_directml #necessary if you have windows with windows sub-system for linux (WSL) to achieve a degree of optimization in Python 3.8\n",
    "pip install numpy #you probably already have it\n",
    "pip install pandas #you probably already have it\n",
    "pip install dlib #easiest to handle on linux / mac systems - in Windows it's a nightmare and will take me about 8 hrs to document.\n",
    "pip install deepface \n",
    "```\n",
    "\n",
    "Here, we've taken the script from the FairFace GitHub and converted it to a class.  We did this out of necessity, as we sought the ability to evaluate one image at a time, or images in a batch, as well as the ability to classify an image with or without pre-processing (and optionally, without storing the pre-processed image).  Without a class, it would have required re-loading the detection and classification models to CPU/GPU with every function call.  As such, we built this class which gave us the flexibility we sought in processing our data.\n",
    "\n",
    "This class can be used as part of the script, or could potentially be re-uploaded back to the FairFace GitHub, potentially advancing its design so that it could eventually become a pip package installable similar to DeepFace for ease of use by others.\n",
    "\n",
    "To be able to use this class and script, you must first download or clone the FairFace package from GitHub directly (not currently a pip package).  You can do that here:\n",
    "https://github.com/dchen236/FairFace\n",
    "\n",
    "After you've pulled the file, you'll need to download copies of the models and save them in a new folder called fair_face_models.  Models are located here: https://drive.google.com/drive/folders/1F_pXfbzWvG-bhCpNsRj6F_xsdjpesiFu\n",
    "\n",
    "After you do these steps, you can store this script in the main folder where you've saved/copied the FairFace repository. \n",
    "\n",
    "From there, I recommend you get access to/download any images you wish to process and store them in a local folder, and use some code to generate a CSV of all the files in that folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch_directml\n",
    "import dlib\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "\n",
    "class fairface:\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "        \"\"\"_summary_\n",
    "        return instance of the FairFace class with models loaded to CPU/GPU\n",
    "        leverages torch_directml for users with AMD GPU systems (especially on Linux)\n",
    "        \"\"\"\n",
    "        self.cnn_face_detector = dlib.cnn_face_detection_model_v1('dlib_models/mmod_human_face_detector.dat')\n",
    "        self.sp = dlib.shape_predictor('dlib_models/shape_predictor_5_face_landmarks.dat')\n",
    "        self.base = 2000\n",
    "        self.__device = torch.device(\"cuda:0\" if torch.cuda.is_available() else torch_directml.device())\n",
    "        self.__map_location= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.__model_fair_7 = torchvision.models.resnet34(pretrained=True)\n",
    "        self.__model_fair_7.fc = nn.Linear(self.__model_fair_7.fc.in_features, 18)\n",
    "        self.__model_fair_7 = self.__model_fair_7.to(self.__device)\n",
    "        self.__model_fair_7.eval()\n",
    "        self.__model_fair_4 = torchvision.models.resnet34(pretrained=True)\n",
    "        self.__model_fair_4.fc = nn.Linear(self.__model_fair_4.fc.in_features, 18)\n",
    "        self.__model_fair_4 = self.__model_fair_4.to(self.__device)\n",
    "        self.__model_fair_4.eval()\n",
    "\n",
    "        self.__save_detections_at = \"\"\n",
    "        self.__trans = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.__load_state_dicts()\n",
    "\n",
    "    def __load_state_dicts(self):\n",
    "        \"\"\"_summary_\n",
    "        loads the appropriate FairFace Detection model to the appropriate device (CPU/GPU)\n",
    "        \"\"\"\n",
    "        self.__model_fair_7.load_state_dict(torch.load('fair_face_models/res34_fair_align_multi_7_20190809.pt',map_location=self.__map_location))\n",
    "        self.__model_fair_7 = self.__model_fair_7.to(self.__device)\n",
    "        self.__model_fair_7.eval()        \n",
    "        self.__model_fair_4.load_state_dict(torch.load('fair_face_models/res34_fair_align_multi_4_20190809.pt',map_location=self.__map_location))\n",
    "        self.__model_fair_4 = self.__model_fair_4.to(self.__device)\n",
    "        self.__model_fair_4.eval()\n",
    "\n",
    "    def set_save_location(self,path):\n",
    "        \"\"\"_summary_\n",
    "        not sure this function is needed.\n",
    "        Args:\n",
    "            path (_type_): string - path to save location\n",
    "        \"\"\"\n",
    "        self.__save_detections_at = path\n",
    "        self.__ensure_dir(path)\n",
    "\n",
    "    def __ensure_dir(self,directory):\n",
    "        \"\"\"_summary_\n",
    "        This function may not be needed.\n",
    "        Args:\n",
    "            directory (_type_): path to a folder / location to ensure it exists\n",
    "        \"\"\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "    def detect_face(self, img_path, default_max_size = 800, size=300, padding=0.25,\n",
    "                    save=False):\n",
    "        \"\"\"detects faces in an image; serves as a helper function to analyze function\n",
    "            if enforce_detection is enabled.\n",
    "            returns an image if save is False, otherwise saves the image at self.__save_location\n",
    "            for later processing\n",
    "        Args:\n",
    "            img_path (string): filepath to an image in which to detect faces\n",
    "            default_max_size (int, optional): Defaults to 800.\n",
    "            size (int, optional):  Defaults to 300.\n",
    "            padding (float, optional):  Defaults to 0.25.\n",
    "            save (bool, optional): If true, will save a .jpg file of the input file at self.__save_location. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: an opened, pre-processed/cropped image focused on a face for categorization models.\n",
    "            none (if save is enabled) -> saves the np.ndarray to the specified path in this instance's \n",
    "            self.__save_detections_at variable.\n",
    "        \"\"\"\n",
    "        img = dlib.load_rgb_image(os.path.join(img_path))\n",
    "        old_height, old_width, _ = img.shape\n",
    "        if old_width > old_height:\n",
    "            new_width, new_height = default_max_size, int(default_max_size * old_height / old_width)\n",
    "        else:\n",
    "            new_width, new_height =  int(default_max_size * old_width / old_height), default_max_size\n",
    "        img = dlib.resize_image(img, rows=new_height, cols=new_width)\n",
    "        dets = self.cnn_face_detector(img, 1)\n",
    "        num_faces = len(dets)\n",
    "        if num_faces == 0:\n",
    "            print(\"Sorry, there were no faces found in '{}'\".format(img_path))\n",
    "        # Find the 5 face landmarks we need to do the alignment.\n",
    "        else:\n",
    "            faces = dlib.full_object_detections()\n",
    "            for detection in dets:\n",
    "                rect = detection.rect\n",
    "                faces.append(self.sp(img, rect))\n",
    "            images = dlib.get_face_chips(img, faces, size=size, padding = padding)\n",
    "            if save: \n",
    "                for idx, image in enumerate(images):\n",
    "                    img_name = img_path.split(\"/\")[-1]\n",
    "                    path_sp = img_name.split(\".\")\n",
    "                    face_name = os.path.join(self.__save_detections_at,  path_sp[0] + \"_\" + \"face\" + str(idx) + \".\" + path_sp[-1])\n",
    "                    dlib.save_image(image, face_name)\n",
    "                print(\"Saved detected face(s) at \"+self.__save_detections_at)\n",
    "            else:\n",
    "                return images\n",
    "\n",
    "    def analyze(self,image,mode='fair7',enforce_detection=True):\n",
    "        \"\"\"evaluates an input image on either the fair7 or fair4 model. defaults to fair7.\n",
    "enables analysis and classification with or without preprocessing (defaults to preprocessing enabled).\n",
    "if pre-processing is enabled, calls to detect_face and gets its return data for classifying the image. \n",
    "\n",
    "        Args:\n",
    "            image (str): relative filepath to an image from the current directory\n",
    "            mode (str, optional): options include 'fair4' and 'fair7' for the respective FairFace models. Defaults to 'fair7'.\n",
    "            enforce_detection (bool, optional): Allows this function and the selected model to evaluate an image directly without preprocessing. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            result (pandas DataFrame): a dataframe with the respective predictions and calculations from the selected FairFace model on the provided image.\n",
    "        \"\"\"\n",
    "        race_scores,gender_scores,age_scores=[],[],[]\n",
    "        race_pred,gender_pred,age_pred = [],[],[]\n",
    "        face_names = []\n",
    "        face_names.append(image)\n",
    "        if enforce_detection:\n",
    "            image = self.__trans(self.detect_face(image)[0])\n",
    "        else:\n",
    "            image = self.__trans(dlib.load_rgb_image(os.path.join(image)))\n",
    "        \n",
    "        image=image.view(1,3,224,224)\n",
    "        image=image.to(self.__device)\n",
    "\n",
    "        outputs = None\n",
    "\n",
    "        if mode=='fair7':\n",
    "            outputs = self.__model_fair_7(image)\n",
    "        else:\n",
    "            outputs = self.__model_fair_4(image)\n",
    "        \n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        outputs = np.squeeze(outputs)\n",
    "        race_outputs,gender_outputs,age_outputs=[],[],[]\n",
    "        race_score,gender_score,age_score=0,0,0\n",
    "        gender_outputs = outputs[7:9]\n",
    "        age_outputs = outputs[9:18]\n",
    "        if mode=='fair7':\n",
    "            race_outputs = outputs[:7]\n",
    "            race_score = np.exp(race_outputs) / np.sum(np.exp(race_outputs))\n",
    "        else:\n",
    "            race_outputs = outputs[:4]\n",
    "            race_score = np.exp(race_outputs) / np.sum(np.exp(race_outputs))\n",
    "\n",
    "        race_pred = np.argmax(race_score)\n",
    "        gender_score = np.exp(gender_outputs) / np.sum(np.exp(gender_outputs))\n",
    "        age_score = np.exp(age_outputs) / np.sum(np.exp(age_outputs))\n",
    "        gender_pred = np.argmax(gender_score)\n",
    "        age_pred=np.argmax(age_score)\n",
    "\n",
    "        race_scores.append(race_score)\n",
    "        age_scores.append(age_score)\n",
    "        gender_scores.append(gender_score)\n",
    "        result = pd.DataFrame(\n",
    "               [face_names,\n",
    "                [race_pred],\n",
    "                [gender_pred],\n",
    "                [age_pred],\n",
    "                race_scores, \n",
    "                gender_scores,\n",
    "                age_scores] \n",
    "        ).T\n",
    "        result.columns = ['face_name_align',\n",
    "                'race_preds_fair',\n",
    "                'gender_preds_fair',\n",
    "                'age_preds_fair',\n",
    "                'race_scores_fair',\n",
    "                'gender_scores_fair',\n",
    "                'age_scores_fair']\n",
    "        if mode == 'fair7':\n",
    "            race_src = [result['race_preds_fair']==0,result['race_preds_fair']==1,\n",
    "                        result['race_preds_fair']==2,result['race_preds_fair']==3,\n",
    "                        result['race_preds_fair']==4,result['race_preds_fair']==5,\n",
    "                        result['race_preds_fair']==6]\n",
    "            race_dst = ['White','Black','Latino_Hispanic',\n",
    "                        'East Asian','Southeast Asian','Indian',\n",
    "                        'Middle Eastern']\n",
    "        elif mode == 'fair4':\n",
    "            race_src = [result['race_preds_fair']==0,result['race_preds_fair']==1,\n",
    "                        result['race_preds_fair']==2,result['race_preds_fair']==3]\n",
    "            race_dst = ['White','Black','Asian','Indian']\n",
    "        else:\n",
    "            print(\"unsupported mode.\")\n",
    "\n",
    "        gen_src = [result['gender_preds_fair']==0,result['gender_preds_fair']==1]\n",
    "        gen_dst = ['Male','Female']\n",
    "        age_src = [result['age_preds_fair']==0,result['age_preds_fair']==1,\n",
    "                   result['age_preds_fair']==2,result['age_preds_fair']==3,\n",
    "                   result['age_preds_fair']==4,result['age_preds_fair']==5,\n",
    "                   result['age_preds_fair']==6,result['age_preds_fair']==7,\n",
    "                   result['age_preds_fair']==8]\n",
    "        age_dst = ['0-2','3-9','10-19','20-29','30-39','40-49','50-59','60-69','70+']\n",
    "        result['race_preds_fair']=np.select(race_src,race_dst,result['race_preds_fair'])\n",
    "        result['gender_preds_fair']=np.select(gen_src,gen_dst,result['gender_preds_fair'])\n",
    "        result['age_preds_fair']=np.select(age_src,age_dst,result['age_preds_fair'])\n",
    "\n",
    "        return result[['face_name_align',\n",
    "                'race_preds_fair',\n",
    "                'gender_preds_fair',\n",
    "                'age_preds_fair',\n",
    "                'race_scores_fair',\n",
    "                'gender_scores_fair',\n",
    "                'age_scores_fair']]\n",
    "\n",
    "    def get_map_loc(self):\n",
    "        \"\"\"debugging function to ensure the correct available device(s) (cpu,gpu) are available and used\n",
    "\n",
    "        Returns:\n",
    "            torch.device: either cpu or cuda:0\n",
    "        \"\"\"\n",
    "        return self.__map_location\n",
    "\n",
    "    def get_device(self):\n",
    "        \"\"\"debugging function to ensure the correct available device(s) (cpu,gpu) are available and used\n",
    "\n",
    "        Returns:\n",
    "            torch.device: either torch_directml device, or cuda:0\n",
    "        \"\"\"\n",
    "        return self.__device\n",
    "\n",
    "    def batch_detect_analyze(self, img_paths):\n",
    "        #function not currently used and can be improved upon.\n",
    "        for i, img in enumerate(img_paths):\n",
    "            self.detect_face(img)\n",
    "        img_names = [os.path.join(img_paths, x) for x in os.listdir(img_paths)]\n",
    "        # for img in img_names:\n",
    "        #     self.analyze(self.__save_detections_at+'/'+img)\n",
    "        # return 0\n",
    "\n",
    "    def _rect_to_bb(self,rect):\n",
    "        \"\"\"function was present and undocumented in original script\n",
    "        code was not used elsewhere within the source script\n",
    "\n",
    "        Args:\n",
    "            rect (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        # take a bounding predicted by dlib and convert it\n",
    "        # to the format (x, y, w, h) as we would normally do\n",
    "        # with OpenCV\n",
    "        x = rect.left()\n",
    "        y = rect.top()\n",
    "        w = rect.right() - x\n",
    "        h = rect.bottom() - y\n",
    "        # return a tuple of (x, y, w, h)\n",
    "        return (x, y, w, h)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If seeking to use both models, they must be imported and instantiated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an instance of the fairface class\n",
    "#class may benefit from being turned into a singleton\n",
    "#or an importable module.\n",
    "#FairFace = fairface()\n",
    "#from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_output(model,data):\n",
    "    \"\"\"\n",
    "    format the output from batch_analyze in a standard fashion for comparison\n",
    "    match the master dataframe format for the final product\n",
    "\n",
    "    Args:\n",
    "        model (str): _description_\n",
    "        data (pandas dataframe): output from batch_analyze function\n",
    "\n",
    "    Returns:\n",
    "        data (pandas dataframe): includes the following normalized columns:\n",
    "            model: FairFace|DeepFace (str)\n",
    "            pred_age_grp (str): a bin of age ranges (i.e. \"10-19\", \"20-29\", etc in which the model predicts the subject lay)\n",
    "            pred_age_lower (int): lower bound of the predicted age bin\n",
    "            pred_age_upper (int): upper bound of the predicted age bin\n",
    "            pred_gender (str): Male|Female\n",
    "        individual categorization scores are omitted from each models' output.\n",
    "    \"\"\"\n",
    "    if model == 'FairFace':       \n",
    "        #normalize race to those output by UTK\n",
    "        data.columns=['file','pred_race','pred_gender','pred_age_grp','race_scores','gender_scores','age_scores']\n",
    "        data=data.drop(labels=['race_scores','gender_scores','age_scores'],axis=1)\n",
    "        race_src = [data['pred_race']=='East Asian',data['pred_race']=='Southeast Asian',\n",
    "                    data['pred_race']=='Latino_Hispanic',data['pred_race']=='White',\n",
    "                    data['pred_race']=='Black',data['pred_race']=='Indian',data['pred_race']=='Middle Eastern']\n",
    "        race_dest = ['Asian','Asian','Other','White','Black','Indian','Other']\n",
    "        data['pred_race'] = np.select(race_src,race_dest,data['pred_race'])\n",
    "        data['pred_age_grp'] = np.where(data['pred_age_grp']=='70+','70-130',data['pred_age_grp'])\n",
    "\n",
    "    else:\n",
    "        #normalize race to those output by UTK\n",
    "        data.columns=['age','pred_gender','pred_race','file']\n",
    "        #asian, white, middle eastern, indian, latino and black\n",
    "        race_src = [data['pred_race']=='asian',data['pred_race']=='white',data['pred_race']=='middle eastern',\n",
    "                    data['pred_race']=='indian',data['pred_race']=='latino',data['pred_race']=='black']\n",
    "        race_dest = ['Asian','White','Other','Indian','Other','Black']\n",
    "        data['pred_race'] = np.select(race_src,race_dest,data['pred_race'])\n",
    "        #remap predicted genders\n",
    "        gen_src = [data['pred_gender']=='Man',data['pred_gender']=='Woman']\n",
    "        gen_dst = ['Male','Female']\n",
    "        data['pred_gender'] = np.select(gen_src,gen_dst,data['pred_gender'])\n",
    "        #bin the ages according to predicted age\n",
    "        bins = [0, 3, 10, 20, 30, 40, 50, 60, 70, np.inf]\n",
    "        group_names = [\"0-2\", \"3-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"70-130\"]\n",
    "        data[\"pred_age_grp\"] = pd.cut(data['age'], bins, right=False, labels=group_names)\n",
    "        data = data.drop(labels=['age'],axis=1)\n",
    "\n",
    "    data[[\"pred_age_lower\",\"pred_age_upper\"]] = data['pred_age_grp'].str.split('-',expand=True).astype(int) #convert to int somehow\n",
    "    \n",
    "    data = data[['file','pred_race','pred_gender','pred_age_grp','pred_age_lower','pred_age_upper']]\n",
    "    return data\n",
    "\n",
    "\n",
    "def batch_analyze(model, in_csv, out_csv, preprocess=True):\n",
    "    \"\"\"allows user to select a facial recognition/categorization model \n",
    "    and a CSV of image file locations to evaluate all those images against the selected model,\n",
    "    and output the results to a CSV.\n",
    "\n",
    "    Note:  The column with paths to the image files' directory are relative paths, and the column in the \n",
    "    CSV containing those paths must be labeled 'img_path'\n",
    "\n",
    "    Args:\n",
    "        model (str): 'FairFace' or 'DeepFace' - model to use when evaluating images\n",
    "        in_csv (str): relative path location to a CSV containing paths to images for evaluation\n",
    "        out_csv (_type_): relative path location and name in which to store output for this evaluation\n",
    "        preprocess (bool, optional): if true, facial detection is performed on each image within the given model before it performs image classification. Defaults to True.\n",
    "    \"\"\"\n",
    "    files = pd.read_csv(os.path.join(in_csv))['img_path']\n",
    "    result=[]\n",
    "    if model == 'FairFace':\n",
    "        FairFace=fairface()\n",
    "        for index,record in enumerate(files):\n",
    "            if index % 100 == 0:\n",
    "                print('{}/{}'.format(index,len(files)))\n",
    "            curr = FairFace.analyze(os.path.join(record),mode='fair7',enforce_detection=preprocess)\n",
    "            if len(result)==0:\n",
    "                result = curr\n",
    "            else:\n",
    "                result = pd.concat([result,curr])\n",
    "    else:\n",
    "        from deepface import DeepFace\n",
    "        import time\n",
    "        #probably need to introduce a cool-down period\n",
    "        if preprocess=='True':\n",
    "            backend=input('select DeepFace Detector Backend: ')\n",
    "        for index,record in enumerate(files):\n",
    "            if index % 100 == 0:\n",
    "                print('{}/{}'.format(index,len(files)))\n",
    "                if index > 0:\n",
    "                    print('sleeping / cooldown for 45 seconds')\n",
    "                    time.sleep(45)\n",
    "\n",
    "            try:\n",
    "                if preprocess=='False':\n",
    "                    curr = DeepFace.analyze(img_path=record,enforce_detection=False,actions=['age','gender','race'],silent=True)\n",
    "                else:\n",
    "                    curr = DeepFace.analyze(img_path=record,enforce_detection=True,actions=['age','gender','race'],silent=True,detector_backend=backend)\n",
    "                curr=curr[0]\n",
    "                del curr['gender']\n",
    "                del curr['race']\n",
    "                del curr['region']\n",
    "                curr['file'] = record\n",
    "                curr = pd.DataFrame(curr,index=[0])\n",
    "                if len(result) == 0:\n",
    "                    result = pd.DataFrame(curr)\n",
    "                else:\n",
    "                    result = pd.concat([result,curr])\n",
    "            except:\n",
    "                print(\"error processing {}\".format(record))\n",
    "    result.to_csv(os.path.join('non_normalized_'+model+'_'+out_csv))\n",
    "    result=normalize_output(model,result)\n",
    "    result['pred_model'] = model\n",
    "    result.to_csv(os.path.join(out_csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below section allows this to be run via command line as follows:\n",
    "\n",
    "`python MasterScript.py --in_csv [input csv file path] --out_csv [desired output csv file path and name] --model [DeepFace|FairFace] --preproc [True|False]`\n",
    "\n",
    "in_csv parameter allows you to specify an input CSV.  The csv must have, at a minimum, a column with the name img_path that specifies the relative path to the files you'll be working with.\n",
    "\n",
    "out_csv parameter allows you to specify a file to which you wish to write your output.  This is also written with respect to the current directory.\n",
    "\n",
    "model parameter allows you to select whether you're using DeepFace or FairFace.  If DeepFace is selected, you will be prompted to enter the facial detection backend once (recommend using mtcnn or opencv, others are failing to install or showing substantial failure to detect faces)\n",
    "\n",
    "preproc parameter allows you to specify whether or not you wish for the image to have a face detected and pre-processed prior to attempted classification.  Setting to True means that faces will be detected first, and False skips detection and goes straight to classification\n",
    "\n",
    "Also this notebook shouldn't be used directly - it is simply amplifying documentation to better explain the script file MasterScript.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\"python MasterScript.py --in_csv [input csv file path] --out_csv [desired output csv file path and name] --model [DeepFace|FairFace] --preproc [True|False]\"\n",
    "if __name__ == '__main__':\n",
    "    example_text = '''\n",
    "examples:\n",
    "    #generate a CSV for iteration from jpg files in folder 'path3' in the current directory & save as UTKpart3.csv\n",
    "    python MasterScript.py --fp part3 --out_csv UTKpart3.csv \n",
    "    python MasterScript.py -f part3 -o UTKpart3.csv\n",
    "\n",
    "    #evalutate contents of UTKpart3.csv using FairFace without pre-processing and save output to FF_UTKpart3_no_preproc.csv\n",
    "    python MasterScript.py --in_csv UTKpart3.csv --model FairFace --preproc False --out_csv FF_UTKpart3_no_preproc.csv\n",
    "    python MasterScript.py -i UTKpart3.csv -m FairFace -p False -o FF_UTKpart3_no_preproc.csv\n",
    "    \n",
    "    #evaulate contents of UTKpart3.csv using DeepFace with preprocessing enabled (requires specifying facial detection backend of mtcnn or opencv for DeepFace)\n",
    "    # and save output to DF_UTKpart3_preproc[mtcnn|opencv].csv\n",
    "    python MasterScript.py --in_csv UTKpart3.csv --model DeepFace --preproc True --out_Csv DF_UTKpart3_preproc[mtcnn|opencv].csv\n",
    "    python MasterScript.py -i UTKpart3.csv -m DeepFace -p True -o DF_UTKpart3_preproc[mtcnn|opencv].csv\n",
    "'''\n",
    "    parser = argparse.ArgumentParser(\n",
    "        prog='python MasterScript.py',\n",
    "        description='script to iterate through images using FairFace or DeepFace',\n",
    "        epilog=example_text,\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter\n",
    "    )\n",
    "    #in_csv arg\n",
    "    parser.add_argument('-i','--in_csv',dest='in_csv',action='store',\n",
    "                        help='csv containing filepaths to input images to categorize'\n",
    "                        )\n",
    "    #out_csv arg\n",
    "    parser.add_argument('-o','--out_csv',dest='out_csv',action='store',\n",
    "                        help='filename in which to store model output'\n",
    "                        )\n",
    "    #model arg\n",
    "    parser.add_argument('-m','--model',dest='model',action='store',\n",
    "                        help='FairFace or DeepFace'\n",
    "                        )\n",
    "    #preprocess arg\n",
    "    parser.add_argument('-p','--preproc',dest='preproc',action='store',\n",
    "                        help='True or False - preprocess images before evaluating'\n",
    "                        )\n",
    "    #fp arg - allows you to generate an input CSV file to use within this script\n",
    "    #depends on having a folder in the same root that contains .jpg files.\n",
    "    parser.add_argument('-f','--fp',dest='PATH',action='store',\n",
    "                    help='folder containing images for processing'\n",
    "                    )\n",
    "    args=parser.parse_args()\n",
    "    if args.PATH is None:\n",
    "        batch_analyze(args.model,args.in_csv,args.out_csv,args.preproc)\n",
    "    else:\n",
    "        EXT = \"*.jpg\"\n",
    "        all_jpg_path = [file \n",
    "                for path,subdir, files in os.walk(args.PATH)\n",
    "                for file in glob(os.path.join(path,EXT))]\n",
    "        all_jpg = [os.path.basename(file)\n",
    "            for path, subdirs, files in os.walk(args.PATH)\n",
    "            for file in glob(os.path.join(path,EXT))\n",
    "        ]\n",
    "        present_files = pd.DataFrame({'img_paths':all_jpg_path,'file':all_jpg})\n",
    "        present_files.to_csv(os.path.join(args.out_csv),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective testing parameters:\n",
    "Permutation Tests\t\n",
    "\t\n",
    "FairFace\t\n",
    "Detection vs. No Detection\t\n",
    "\t\n",
    "DeepFace\t\n",
    "No Detection vs Detection (Opencv) vs Detection (mtcnn)\tvs Detection (any others you can make work)\t\n",
    "\t\n",
    "Recommended datasets:\t\n",
    "part3.tar.gz\thttps://drive.google.com/drive/folders/1HROmgviy4jUUUaCdvvrQ8PcqtNg2jn3G\n",
    "crop_part1.tar.gz\thttps://drive.google.com/drive/folders/0BxYys69jI14kU0I1YUQyY1ZDRUE?resourcekey=0-01Pth1hq20K4kuGVkp3oBw\n",
    "\t\n",
    "Key metrics for tests:\n",
    "% of faces DeepFace was able to analyze\t\n",
    "% of faces FairFace was able to analyze\n",
    "% true positives / true negatives identified under specified detection parameters and dataset for both FairFace and DeepFace\t\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
