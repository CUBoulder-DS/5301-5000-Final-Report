{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some setup notes and Help - \n",
    "Patrick Connelly\n",
    "pconnell89@gmail.com\n",
    "\n",
    "Getting Fair Face Up-and-running\n",
    "\n",
    "To get all of the data to start some work, I began by downloading some files and storing them in a folder structure.\n",
    "\n",
    "Spreadsheet/CSV is located here: https://github.com/Raschka-research-group/coral-cnn/tree/master/datasets.  I believe I was using the afad_test csv.\n",
    "\n",
    "The images themselves for AFAD (Asian Face Age Dataset) are tarballs located in a separate repo on github: https://github.com/John-niu-07/tarball.  To decompress / extract them, you can use 7-zip on windows, or tar xvf filename_here on linux or mac.\n",
    "\n",
    "Some other dependencies - \n",
    "\n",
    "    1) Install windows subsystem for linux (WSL)\n",
    "\n",
    "    2) Simple method for Windows - install miniconda on WSL\n",
    "\n",
    "        - enter WSL shell\n",
    "    \n",
    "        - wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "    \n",
    "        - bash Miniconda3-latest-Linux-x86_64.sh\n",
    "    \n",
    "        - rm Miniconda3-latest-Linux-x86_64.sh\n",
    "    \n",
    "        - conda init\n",
    "    \n",
    "        - conda activate\n",
    "\n",
    "    3) Create a python env within conda (https://learn.microsoft.com/en-us/windows/ai/directml/gpu-pytorch-windows)\n",
    "\n",
    "        - conda create --name directml python=3.8 ipython (or whatever you want) \n",
    "\n",
    "        - conda activate directml (to enter the environment)\n",
    "\n",
    "        - Within the environment - \n",
    "\n",
    "            a) Install Python 3.8\n",
    "\n",
    "            b) Pip install torch - https://pytorch.org/get-started/locally/\n",
    "\n",
    "            c) Pip torch_directml, numpy, pandas, dlib, deepface\n",
    "\n",
    "Overall purpose of the code in this file is to identify locally stored and unzipped data, and use that to filter down the spreadsheet of data from a source dataset. \n",
    "The output provides you with a csv called \"img_paths\" which can be fed to deepFaceIteration.py or to predict.py as a parameter for iteration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "afad_test = pd.read_csv('C:\\\\Users\\\\pconn\\\\OneDrive\\\\Desktop\\\\AFAD-Full\\\\afad_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I pull in the CSV from the Asian Face Dataset.  I downloaded the CSV and one chunk of the images locally.\n",
    "\n",
    "This first block below is just to test and verify that I was able to bring in the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>path</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>406208-0.jpg</td>\n",
       "      <td>39/112/406208-0.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>470804-0.jpg</td>\n",
       "      <td>39/112/470804-0.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>411657-2.jpg</td>\n",
       "      <td>39/112/411657-2.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>471528-2.jpg</td>\n",
       "      <td>39/112/471528-2.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>398608-1.jpg</td>\n",
       "      <td>39/112/398608-1.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>470572-0.jpg</td>\n",
       "      <td>39/112/470572-0.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>401238-0.jpg</td>\n",
       "      <td>39/112/401238-0.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           file                 path  age  gender\n",
       "0  406208-0.jpg  39/112/406208-0.jpg   24  female\n",
       "1  470804-0.jpg  39/112/470804-0.jpg   24  female\n",
       "2  411657-2.jpg  39/112/411657-2.jpg   24  female\n",
       "3  471528-2.jpg  39/112/471528-2.jpg   24  female\n",
       "4  398608-1.jpg  39/112/398608-1.jpg   24  female\n",
       "5  470572-0.jpg  39/112/470572-0.jpg   24  female\n",
       "6  401238-0.jpg  39/112/401238-0.jpg   24  female"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afad_test = pd.read_csv('C:\\\\Users\\\\pconn\\\\OneDrive\\\\Desktop\\\\AFAD-Full\\\\afad_test.csv')\n",
    "afad_test.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spreadsheet/CSVs were located here on the web: https://github.com/Raschka-research-group/coral-cnn/tree/master/datasets \n",
    "\n",
    "The images themselves are tarballs located in a separate repo on github: https://github.com/John-niu-07/tarball.\n",
    "\n",
    "In terms of this dataset - the images are \"chunked\" into tarball/zip files in GitHub for the AFAD dataset.  The spreadsheet/csv, however, has a listing of ALL file paths for all files in the dataset.  In order to get to a point where I could only iterate over the target files, I had to do a directory walk to identify only .jpg files, searching recursively through a local folder.  \n",
    "\n",
    "This folder ahd the repo / files from a git clone of FairFace, models downloaded separately from Google Drive (not in the GitHub repo directly), the chunk of images from the AFAD dataface extracted into two subfolders, and the full spreadsheet of all items in the AFAD dataset.\n",
    "\n",
    "So I did the directory walk to get a list of all JPGs.  I left-joined the source spreadsheet (left table) to the present files (right table), and then filtered where the right table was blank/NA, so that the result was a table only of the available files for iteration, and then wrote that out to a csv.\n",
    "\n",
    "I used this to build my input for my deepFaceIteration.py script and the modified version of predict.py from the FairFace model.\n",
    "\n",
    "I didn't set this up with functions or parameters (i.e. tell me where you wanna save the file).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"C:\\\\Users\\\\pconn\\\\OneDrive\\\\Desktop\\\\AFAD-Full\"\n",
    "EXT = \"*.jpg\"\n",
    "\n",
    "# get a list of all filenames recursively from the current directory in which this script runs\n",
    "# and down into any subfolders as well\n",
    "\n",
    "all_jpg = [file \n",
    "           for path, subdir, files in os.walk(PATH)\n",
    "           for file in glob(os.path.join(path,EXT))]\n",
    "\n",
    "#can be used to verify how many you identified in the local folder(s)\n",
    "#len(all_jpg)\n",
    "#all_jpg[0]\n",
    "\n",
    "present_files = pd.DataFrame({'jpgs': all_jpg})\n",
    "present_files['file']=(present_files['jpgs'].str.split('\\\\')).str[-1]\n",
    "present_files\n",
    "\n",
    "#do a left join between the files we know could exist (left) and the files we found (right)\n",
    "#filter the list down only to items where there was a match as well (maybe inner join is smarter)\n",
    "merged=afad_test.merge(present_files,on='file',how='left')\n",
    "merged = merged[merged['jpgs'].notna()]\n",
    "\n",
    "#trim and generate the output file!\n",
    "merged['jpgs'] = merged['jpgs'].str.replace('C:\\\\Users\\\\pconn\\\\OneDrive\\\\Desktop\\\\AFAD-Full','.')\n",
    "merged['img_path'] = merged['jpgs']\n",
    "merged=merged.drop(labels=['jpgs','path','file','age','gender'],axis=1)\n",
    "\n",
    "merged.to_csv('C:\\\\Users\\\\pconn\\\\OneDrive\\\\Desktop\\\\AFAD-Full\\\\afad_loc_clean.csv',index=False)\n",
    "\n",
    "len(merged)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
