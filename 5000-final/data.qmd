
# Data


We describe the data here. Note that the default global setting for Quarto is set to NOT output the code into the rendered document, aka only including the results of any R code.

**We should include a print of the head of the dataframe of our data, along with some sample images!!**

## Exploration of Source Data

::: {#fig-faces layout-ncol=3}

![Age=6, Gender=F, Race=Indian](images/utk_imgs/6_1_3_20161220223052131.jpg){#fig-img1}

![Age=38, Gender=M, Race=White](images/utk_imgs/38_0_0_20170105172756958.jpg){#fig-img2}

![Age=80, Gender=M, Race=Asian](images/utk_imgs/80_0_2_20170111201008732.jpg){#fig-img3}

Example face images from the UTK dataset [@utkDataset] with their associated given labels.
:::

<!-- CK -->

::: {.content-visible when-format="html"}
::: {#fig-data-eda}
```{=html}
<iframe id="Shiny App" src="https://carlklein.shinyapps.io/5000-final/" style="border: none; width: 100%; height: 820px" frameborder="0"></iframe>
```

An interactive figure showcasing the distributions of various data factors in the image dataset, and showcasing the underlying data.
:::
:::

::: {.content-visible when-format="pdf"}
::: {#fig-data-eda-pdf layout-ncol=2}

![Image data EDA]("images/shiny1.png")

![Image dataset visualization]("images/shiny2.png")

Screenshots of the interactive figure showcasing the distributions of various data factors in the image dataset, and showcasing the underlying data. To see and interact with this figure, go to [the website link](https://cuboulder-ds.github.io/5301-5000-Final-Report/data.html)
:::
:::

::: callout-note
## From the report requirements

This section should describe the data you'll be using. Answer **at least** **all** of the following questions:

-   How was the data collected?

The dataset used in this research is a publicly non-commercial available dataset on Github called "UTKFace". The data was collected by the The University of Tennessee, Knoxville. It is specified on its Github page that the images were gathered from the internet. They are likely to be obtained through technique such as web scrapping. The dataset contains more than 20,000 images, representing a highly diversed demographic. However, face images are vary in pose, facial expression, lighting, and resolution.

-   What are the sources and influences of bias in the data?

The distribution of each demographic groups are not normally distributed. By plotting a distribution of each demographic group, it is evident that the dataset contains an uneven high volume of older White men. While a smaller porportion of female among ...(input race)... is present.

-   What are the important features (=columns) that you are using in your analysis? What do they mean?

There are three features in the dataset which are essential to our analysis. They are Race, Gender, and Age.

Race is categorized into five groups; Asian, Black, Indian, White, and Other. It should be noted by Asian group in this dataset mostly refers to people from East and Southeast Asia. Whereas, Other includes ethnicities such as Hispanic, Latino, and Middle Eastern.

Gender is divided into two groups, either male or female.

Lastly, Age is represented with an integer. This dataset contains people of all ages ranging from 0 to 116.

Feel free to add anything else that you think is necessary for understanding the paper and the context of the problem.
:::

## More information on data

```{r}
library(tidyverse)
f <- c(
"Croped_ff_np.csv",
"MasterDataFrame.csv",
"crop_df_np.csv",
"crop_df_p_mtcnn.csv",
"crop_df_p_opencv.csv",
"cropped_UTK.csv",
"cropped_UTK_dataset.csv",
"cropped_ff_p.csv",
"joined_permutations.csv",
"new_ff_c_np.csv",
"new_ff_c_p.csv",
"new_ff_uc_np.csv",
"new_ff_uc_p.csv",
"non_normalized_DeepFace_uncropped_DF_all.csv",
"non_normalized_FairFace_uncropped_FF_all.csv",
"uncropped_DF_all.csv",
"uncropped_FF_all.csv",
"uncropped_UTK.csv",
"uncropped_UTK_dataset.csv",
"uncropped_df_np.csv",
"uncropped_df_p_mtcnn.csv",
"uncropped_df_p_opencv.csv",
"uncropped_ff_np.csv",
"uncropped_ff_p.csv"
)
p <- c(
"Permutation evaluation (older version) for fairface, no preprocessing on cropped images.  Updated this file to look at the same files as the uncropped dataset.", #Croped_ff_np.csv",
"Final master data file containing all input and output files", #"MasterDataFrame.csv",
"Permutation evaluation for DeepFace, cropped images, no pre-processing", #"crop_df_np.csv",
"Permutation evaluation for DeepFace, cropped images, preprocessed with MTCNN backend.", #"crop_df_p_mtcnn.csv",
"Permutation evaluation for DeepFace, cropped images, preprocessed with OpenCV backend.",  #"crop_df_p_opencv.csv",
"Permutation evaluation (older version), list of cropped files to perform evaluation.", #"cropped_UTK.csv",
"Permutation evaluation (newest version), list of cropped files to perform evaluation.", #"cropped_UTK_dataset.csv",
"Permutation evaluation (older version), used older version of cropped images dataset.", #"cropped_ff_p.csv",
"Permutation evaluation (newest version), joined all permutation outputs from DeepFace and FairFace to a single file", #"joined_permutations.csv",
"Permutation evaluation (newest version), FairFaice outputs for cropped images with no preprocessing", #"new_ff_c_np.csv",
"Permutation evaluation (newest version), FairFaice outputs for cropped images with dlib preprocessing", #"new_ff_c_p.csv",
"Permutation evaluation (newest version), FairFaice outputs for uncropped images with no preprocessing", #"new_ff_uc_np.csv",
"Permutation evaluation (newest version), FairFaice outputs for uncropped images with dlib preprocessing.", #"new_ff_uc_p.csv",
"Final dataset of DeepFace Outputs (non-normalized)", #"non_normalized_DeepFace_uncropped_DF_all.csv",
"Final dataset of FairFace Outputs (non-normalized)", #"non_normalized_FairFace_uncropped_FF_all.csv",
"Final normalized output for DeepFace - used to build MasterDataFrame.csv", #"uncropped_DF_all.csv",
"Final normalized output for FairFace - used to build MasterDataFrame.csv", #"uncropped_FF_all.csv",
"Permutation evaluation (older version) - source data file for iteration script", #"uncropped_UTK.csv",
"Permutation evaluation (newest version) - source data file for uncropped images in iteration script", #"uncropped_UTK_dataset.csv",
"Permutation evaluation (newest version) - DeepFace uncropped images with no preprocessing", #"uncropped_df_np.csv",
"Permutation Evaluation (newest version) - DeepFace uncropped images with mtcnn preprocessing", #"uncropped_df_p_mtcnn.csv",
"Permutation Evaluation (newest version) - DeepFace uncropped images with opencv preprocessing", #"uncropped_df_p_opencv.csv",
"Permutation Evaluation (older version) - FairFace uncropped images with no preprocessing", #"uncropped_ff_np.csv",
"Permutation Evaluation (older version) - FairFace uncropped images with dlib preprocessing." #"uncropped_ff_p.csv"
)
r <- c(
"Remove from github data folder.", #"Permutation evaluation (older version) for fairface, no preprocessing on cropped images.  Updated this file to look at the same files as the uncropped dataset.", #Croped_ff_np.csv",
"Keep as-is with no changes", #"Final master data file containing all input and output files", #"MasterDataFrame.csv",
"Retain; rename to PERM_DF_c_np.csv", #"Permutation evaluation for DeepFace, cropped images, no pre-processing", #"crop_df_np.csv",
"Retain; rename to PERM_DF_c_p_mtcnn.csv", #"Permutation evaluation for DeepFace, cropped images, preprocessed with MTCNN backend.", #"crop_df_p_mtcnn.csv",
"Retain; rename to PERM_DF_c_p_opencv.csv", #"Permutation evaluation (newest version)for DeepFace, cropped images, preprocessed with OpenCV backend.",  #"crop_df_p_opencv.csv",
"Remove from github data folder", #"Permutation evaluation (older version), list of cropped files to perform evaluation.", #"cropped_UTK.csv",
"Retain with no changes", #"Permutation evaluation (newest version), list of cropped files to perform evaluation.", #"cropped_UTK_dataset.csv",
"Remove from github data folder.", #"Permutation evaluation (older version), used older version of cropped images dataset.", #"cropped_ff_p.csv",
"Retain with no changes", #"Permutation evaluation (newest version), joined all permutation outputs from DeepFace and FairFace to a single file", #"joined_permutations.csv",
"Retain; rename to PERM_FF_c_np.csv", #"Permutation evaluation (newest version), FairFaice outputs for cropped images with no preprocessing", #"new_ff_c_np.csv",
"Retain; rename to PERM_FF_c_p.csv", #"Permutation evaluation (newest version), FairFaice outputs for cropped images with dlib preprocessing", #"new_ff_c_p.csv",
"Retain; rename to PERM_FF_uc_np.csv", #"Permutation evaluation (newest version), FairFaice outputs for uncropped images with no preprocessing", #"new_ff_uc_np.csv",
"Retain; rename to PERM_FF_uc_p.csv", #"Permutation evaluation (newest version), FairFaice outputs for uncropped images with dlib preprocessing.", #"new_ff_uc_p.csv",
"Retain; rename to Master_DF_non_normalized.csv", #"Final dataset of DeepFace Outputs (non-normalized)", #"non_normalized_DeepFace_uncropped_DF_all.csv",
"Retain; rename to Master_FF_non_normalized.csv", #"Final dataset of FairFace Outputs (non-normalized)", #"non_normalized_FairFace_uncropped_FF_all.csv",
"Retain with no changes", #"Final normalized output for DeepFace - used to build MasterDataFrame.csv", #"uncropped_DF_all.csv",
"Retain with no changes", #"Final normalized output for FairFace - used to build MasterDataFrame.csv", #"uncropped_FF_all.csv",
"Remove from github data folder.", #"Permutation evaluation (older version) - source data file for iteration script", #"uncropped_UTK.csv",
"Retain with no changes", #"Permutation evaluation (newest version) - source data file for uncropped images in iteration script", #"uncropped_UTK_dataset.csv",
"Retain; rename to PERM_DF_uc_np.csv", #"Permutation evaluation (newest version) - DeepFace uncropped images with no preprocessing", #"uncropped_df_np.csv",
"Retain; rename to PERM_DF_uc_p_mtcnn.csv", #"Permutation Evaluation (newest version) - DeepFace uncropped images with mtcnn preprocessing", #"uncropped_df_p_mtcnn.csv",
"Retain; rename to PERM_DF_uc_p_opencv.csv", #"Permutation Evaluation (newest version) - DeepFace uncropped images with opencv preprocessing", #"uncropped_df_p_opencv.csv",
"Remove from github data folder.", #"Permutation Evaluation (older version) - FairFace uncropped images with no preprocessing", #"uncropped_ff_np.csv",
"Remove from github data folder." #"Permutation Evaluation (older version) - FairFace uncropped images with dlib preprocessing.", #"uncropped_ff_p.csv"
)

t <- tibble(filenames=f,purpose=p,recommendations=r)
knitr::kable(t)
```

## Data Selection (UTK Dataset) - LN DV

Motivation - has there been progress against bias?

Reference Articles from Ethics Class - Joy B's work, etc.  Lots of disparity back in 2018, how much of that still exists with free models?

In 2018, Joy Buolamwini, a PhD candinate at MIT Media Lab, published a thesis on gender and racial biases in facial recognition in algorithms. In her paper, she tested facial recongition softwares from multiple large technology companies such as Microsoft, IBM, and Amazom on its effectiveness for different demographic groups. From this research, it is concluded that most AI algorithms offer a substantially less accurate prediction for female and people with dark skin color.

(Add link to the story)

The primary motivation behind this research is to determine the degree in which bias is still present in modern facial recognition models. Therefore, we select a dataset which comprise of face images with high diversity in regards to race.

## Selected Models (LN DV)

Lorem ipsum 

### FairFace 

Motivation as to how / why we came across this

Developed by researchers at University of California, Los Angeles, FairFace was specifically designed to mitigate gender and racial biases. The model was trained on 100K+ face images of people of various ethnicities with normal distribution (equal stratification) across all groups. Beside facial recognition model, FairFace also provided the dataset which it was trained on. The dataset is highly popular among

We came across this model when we were searching for an

### DeepFace

Motivation as to how / why we came across this

DeepFace is a lightweight open-source model developed and used by Meta (Facebook). Since the model is used by one of the largest social media company, it is widely known among developers. Therefore, its popularity prompts us to evaluate its performance. It should be noted that this model of DeepFace is a free open-source version. It is highly likely that this version is less advanced than what Meta is actually using. Thus, we should not view the result of this model as a representative of Meta's algorithm.

### Permutation Analysis Information

```{r}
# Load required libraries
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(kableExtra))

# Read the CSV file
permu_data <- read.csv("../data/joined_permutations.csv")

# Create match columns
permu_data$match_age_grp <- permu_data$src_age_grp == permu_data$pred_age_grp
permu_data$match_gender <- permu_data$src_gender == permu_data$pred_gender
permu_data$match_race <- permu_data$src_race == permu_data$pred_race
permu_data$match_all <- permu_data$match_race & permu_data$match_age_grp & permu_data$match_gender

# Suppress all messages
suppressMessages({
  # Create permu_pivot
  permu_pivot <- permu_data %>%
    group_by(pred_model) %>%
    summarise(match_all = sum(match_all),
              match_age_grp = sum(match_age_grp),
              match_gender = sum(match_gender),
              match_race = sum(match_race))

  # Create setting_pivot
  setting_pivot <- permu_data %>%
    group_by(pred_model, detection_enabled, detection_model, image_type) %>%
    summarise(match_all = sum(match_all),
              match_age_grp = sum(match_age_grp),
              match_gender = sum(match_gender),
              match_race = sum(match_race))

  # Create setting_count
  setting_count <- permu_data %>%
    group_by(pred_model, detection_enabled, detection_model, image_type) %>%
    summarise(setting_count = n())

  # Merge setting_pivot and setting_count
  setting_merge <- merge(setting_pivot, setting_count, by = c("pred_model", "detection_enabled", "detection_model", "image_type"))

  # Calculate rates
  setting_merge$all_rate <- setting_merge$match_all / setting_merge$setting_count
  setting_merge$age_grp_rate <- setting_merge$match_age_grp / setting_merge$setting_count
  setting_merge$gender_rate <- setting_merge$match_gender / setting_merge$setting_count
  setting_merge$race_rate <- setting_merge$match_race / setting_merge$setting_count

  # Drop unnecessary columns
  setting_merge <- select(setting_merge, -c(match_all, match_age_grp, match_gender, match_race, setting_count))
  
  # Print the table with kableExtra
  kable(setting_merge, format = "html") %>%
    kable_styling()
})


```
