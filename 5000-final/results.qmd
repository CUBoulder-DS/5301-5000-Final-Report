# Results

```{r setup, include=FALSE}
#| include: false
# BJ
library(tidyverse)
library(caret)
library(kableExtra)
library(gt)
```

<!-- BJ !-->

```{r load_data, include=FALSE}
# CK, BJ
# master dataframe url
output_name <- 'https://raw.githubusercontent.com/CUBoulder-DS/5301-5000-Final-Report/main/data/MasterDataFrame.csv'

# entire master dataframe
output_df <- read_csv(output_name, show_col_types = FALSE) %>% 
  select(-c(img_path, file)) %>%
  mutate_if(is.character, as.factor) 

# Get chr columns as factors, re-ordered as they should
output_df$src_age_grp = factor(output_df$src_age_grp, 
                               levels = c("0-2", "3-9", "10-19", "20-29", "30-39", "40-49", "50-59", "60-69", "70-130"))
output_df$pred_age_grp = factor(output_df$pred_age_grp, 
                               levels = c("0-2", "3-9", "10-19", "20-29", "30-39", "40-49", "50-59", "60-69", "70-130"))
output_df$src_race = factor(output_df$src_race, levels=c("White", "Black", "Asian", "Indian", "Other"))
output_df$pred_race = factor(output_df$pred_race, levels=c("White", "Black", "Asian", "Indian", "Other"))

# Add correctness columns
output_df = output_df %>% 
  mutate(correct_gender = (src_gender == pred_gender), 
         correct_age = (src_age_grp == pred_age_grp), 
         correct_race = (src_race == pred_race))
  

# fairface dataframe
# exclude the indexing column and deepface only column
fairface_df <- output_df %>%
  filter(pred_model == 'FairFace') %>%
  select(-c(...1, pred_age_DF_only)) %>%
  drop_na()

# deepface dataframe
# exclude the indexing column
deepface_df <- output_df %>%
  filter(pred_model == 'DeepFace') %>%
  select(-...1) %>%
  drop_na()

# source dataframe
# use one of the models (since the data is doubled)
# include only the source ("src") columns
source_df <- output_df %>%
  filter(pred_model == 'FairFace') %>%
  select(c(src_age, src_age_grp, src_gender, src_race, src_timestamp)) %>%
  drop_na()
```

<!-- BJ !-->

::: panel-tabset
## Tabbed example output

```{r  ex2}
#| label: fig-sec4-ex2
#| fig-cap: ANother example caption
#| fig-subcap: 
#|   - Subcap
#|   - Subcap 2
#| layout-ncol: 2
# BJ

f <- 1:10
## Tabbed example output
ggplot() + 
  geom_line(aes(x=f, y=f^2))

ggplot() + 
  geom_line(aes(x=f, y=1/f))
```

## Example outout

```{r ex1}
#| label: fig-sec4-ex1
#| fig-cap: A caption for generated figure
# BJ

# Example code that's running
f <- 1:10
f

```
:::

::: callout-note
## From the report requirements

Describe the results of your analysis using visualizations, descriptive statistics, tables and similar.

Don't focus too much on the implications in this section -- that's what the next section is for. Just present the numbers/graphs.
:::

<!-- BJ !-->

## Model Output

The two models, DeepFace and FairFace, were run on the dataset described previously. In @fig-output-hists, one can see the results of the predictions done by each model, by each factor that was considered: age, gender, and race. Note that the histogram distributions match the correct (source dataset) distributions, so we can see exactly the difference between what was provided and what was predicted, along with how well each model did on each category within each factor.

```{r plot_hists}
#| label: fig-output-hists
#| fig-cap: Histograms of the output from DeepFace and FairFace, with correct vs incorrect values colored. Note that the distributions match the correct (source dataset) distributions.
#| fig-subcap: 
#|   - Gender predictions
#|   - Age predictions
#|   - Race predictions
#| layout-ncol: 2
#| layout-nrow: 2
# BJ

plot_category = function(src, correct, label) {
  num_cats = length(levels(output_df[[src]]))
  
  plot = ggplot() +
    geom_bar(mapping=aes(x=as.numeric(interaction(output_df[["pred_model"]], output_df[[src]])),
                         fill=interaction(output_df[["pred_model"]], output_df[[correct]]))) +
    scale_x_continuous(label, 
                       breaks=seq(1.5, 2*num_cats, 2), 
                       labels=levels(output_df[[src]]), 
                       limits=c(0,2*num_cats + 1)) +
    scale_fill_manual("Model and Correctness",
                      values = c("orangered", "firebrick", "springgreen", "green4"),
                      labels = c("DeepFace, incorrect", "FairFace, incorrect", "DeepFace, correct", "FairFace, correct"))
  
  return(plot)
}


plot_category("src_gender", "correct_gender", "Gender")
plot_category("src_age_grp", "correct_age", "Age")
plot_category("src_race", "correct_race", "Race")
```
## Model Performance

```{r perfomance_table}
# BJ 

get_f1_acc = function(df) {
  age = confusionMatrix(df$pred_age_grp, df$src_age_grp, mode="everything")[["byClass"]]
  race = confusionMatrix(df$pred_race, df$src_race, mode="everything")[["byClass"]]
  gender = confusionMatrix(df$pred_gender, df$src_gender, mode="everything")[["byClass"]]
  
  names = c(age[, "F1"] %>% names() %>% str_replace("Class: ", ""), 
            race[, "F1"] %>% names() %>% str_replace("Class: ", ""), 
            "")
  f1 = c(age[, "F1"], race[, "F1"], gender["F1"])
  acc = c(age[, "Balanced Accuracy"], race[, "Balanced Accuracy"], gender["Balanced Accuracy"])
  
  values = tibble(Category = names, F1 = f1, Accuracy = acc)
  return(values)
}

perf_table = full_join(get_f1_acc(fairface_df), 
                       get_f1_acc(deepface_df), 
                       suffix=c("_F", "_D"), 
                       by="Category")
```

For each category and model, we calculate the F1 score and accuracy, as described in section 3. The results are summarized in @tbl-model-perf. Cell values are colored according to the strength of the metric.

```{r tbl-model-perf}
#| label: tbl-model-perf
#| tbl-cap: Table of F1 score and accuracy, by each category evaluated by the models
#output: asis
# BJ 

perf_table %>%
  gt() %>%
  tab_spanner(label = md("**FairFace**"), columns = c(2, 3)) %>% 
  tab_spanner(label = md("**DeepFace**"), columns = c(4, 5)) %>%
  tab_row_group(label = md("**Gender**"), rows = c(15)) %>%
  tab_row_group(label = md("**Race**"), rows = 10:14) %>%
  tab_row_group(label = md("**Age**"), rows = 1:9) %>%
  cols_label(starts_with("F1") ~ md("**F1**"), starts_with("Accuracy") ~ md("**Accuracy**")) %>%
  tab_options(table.width = pct(100)) %>%
  # Color cells based on values
  tab_style_body(columns = where(is.numeric), 
                 style = cell_fill(color = "darkolivegreen1"),
                 fn = function(x) x >= 0.8) %>%
  tab_style_body(columns = where(is.numeric), 
                 style = cell_fill(color = "lightsalmon"),
                 fn = function(x) x < 0.5 || is.na(x))

```



## Hypothesis Testing

<!-- CK !-->

```{r load_pval_data, include = FALSE}
df_name <- 'https://raw.githubusercontent.com/CUBoulder-DS/5301-5000-Final-Report/main/data/pvalue_results.csv'
p_value_results <- read_csv(df_name)
```

```{r}
table_ages <- c("0-2", "3-9", "10-19", "20-29", "30-39", "40-49", "50-59", "60-69", "70-130")
table_races <- c("White", "Black", "Asian", "Indian", "Other")
table_genders <- c("Female", "Male")
```

```{r pval_ages}
p_value_results %>%
  filter(test_gender == "All") %>%
  filter(test_race == "All") %>%
  select(test_age, source_prop, fairface_prop,
         fairface_p_value, deepface_prop, deepface_p_value) %>%
  arrange(factor(test_age, levels = table_ages)) %>%
  kbl(col.names = c("Test cateogry", "Null Proportion", "FairFace Proportion", "FairFace P-Value",
                    "DeepFace Proportion", "DeepFace P-Value")) %>% 
  kable_styling(full_width = T) %>%
  column_spec(1, bold = T)
```
```{r pval_races}
p_value_results %>%
  filter(test_gender == "All") %>%
  filter(test_age == "All") %>%
  select(test_race, source_prop, fairface_prop,
         fairface_p_value, deepface_prop, deepface_p_value) %>%
  arrange(factor(test_race, levels = table_races)) %>%
  kbl(col.names = c("Test cateogry", "Null Proportion", "FairFace Proportion", "FairFace P-Value",
                    "DeepFace Proportion", "DeepFace P-Value")) %>% 
  kable_styling(full_width = T) %>%
  column_spec(1, bold = T)
```
```{r pval_genders}
p_value_results %>%
  filter(test_race == "All") %>%
  filter(test_age == "All") %>%
  select(test_gender, source_prop, fairface_prop,
         fairface_p_value, deepface_prop, deepface_p_value) %>%
  arrange(factor(test_gender, levels = table_genders)) %>%
  kbl(col.names = c("Test cateogry", "Null Proportion", "FairFace Proportion", "FairFace P-Value",
                    "DeepFace Proportion", "DeepFace P-Value")) %>% 
  kable_styling(full_width = T) %>%
  column_spec(1, bold = T)
```
```{r pval races_by_gender}
p_value_results %>%
  filter(test_prop == 'genders') %>%
  filter(test_age == 'All') %>%
  filter(test_gender != 'All') %>%
  filter(test_race != 'All') %>%
  select(test_gender, test_race,test_race, source_prop, fairface_prop,
         fairface_p_value, deepface_prop, deepface_p_value) %>%
  arrange(factor(test_gender, levels = table_genders)) %>%
  kbl(col.names = c("Test Category", "Test Condition", "Null Proportion", "FairFace Proportion", "FairFace P-Value",
                    "DeepFace Proportion", "DeepFace P-Value")) %>% 
  kable_styling(full_width = T) %>%
  column_spec(1, bold = T)
```


```{r PC_subgroup_pval_acc_f1}

#subgroups 
  #control for source? pred? race, then breakdown F1/accuracy for age and gender
  #Carl's tables - same story
  #do a left-join between on main group (race) and respective sub-group
  #merge into and present single table
  #provide color-coding for areas of issue:
    # p-value: where we're below 1-.997 (3-sigma significance level)
    # F1 and Accuracy - ?



rgrps <- as.character(unique(source_df$src_race))
#modified version of Bav's function - allows to first filter by racial group
#then proceed to compute accuracy for age and gender in each category
f1_acc_subset <- function(df,rgrp){
  tdf <- df %>% filter(as.character(src_race)==as.character(rgrp))
  age <- confusionMatrix(tdf$pred_age_grp, tdf$src_age_grp, mode="everything")[["byClass"]]
  #added additional steps for male and female so we have rows for each in the results.
  gen_m <- confusionMatrix(tdf$pred_gender, tdf$src_gender, mode="everything",positive='Male')[["byClass"]]
  gen_f <- confusionMatrix(tdf$pred_gender, tdf$src_gender, mode="everything",positive='Female')[["byClass"]]
  g_names <- c("Class: Male","Class: Female")
  gender<- cbind(gen_m,gen_f)
  colnames(gender) <- g_names
  gender <- t(gender)
  #end additional steps
  f1 <- c(age[,'F1'],gender[,'F1'])
  acc <- c(age[, "Balanced Accuracy"],gender[, "Balanced Accuracy"])
  names <- c(
    age[, "F1"] %>% names() %>% str_replace("Class: ",""),
    gender[, "F1"] %>% names() %>% str_replace("Class: ","")
  )
  res <- tibble(Category = names,F1=f1, Accuracy=acc, Race=rgrp)
  res %>% mutate(Race=rgrp)#,Key=str_c(rgrp,"-",Category)) #use to inner-join with hypothesis test results.
}

#helper function to merge results from sapply
table_join <- function(ff,df,rgrp){
  full_join(as_tibble(ff[, rgrp]),as_tibble(df[,rgrp]),suffix=c("_f","_d"),by=c('Category','Race'))
}

#use sapply to get a list of tibbles (one for each race) from fairface and deepface
FairFace <-sapply(rgrps,f1_acc_subset,df=fairface_df)
DeepFace <-sapply(rgrps,f1_acc_subset,df=deepface_df)

#take the results and extract the sub-tibbles from fairface and deepface, combine into single sub-tibble in one list
full <- sapply(rgrps,table_join,ff=FairFace,df=DeepFace)

#create a master table to which we can aggregate all results
result_table <- tibble(Race=character(),Category=character(),F1_f=numeric(),Accuracy_f=numeric(),F1_d=numeric(),Accuracy_d=numeric())

#build the result table
for (g in rgrps){
  x <- as_tibble(full[,g]) %>% select(Race,Category,F1_f,Accuracy_f,F1_d,Accuracy_d)
  result_table<-union(result_table,x)
}

#extract the data from Carl's calculations race by age
#transform to have similar columns to the result table for an inner-join
p_race_age <- p_value_results %>%
  filter(test_prop=='age_bins',test_gender=='All',test_age!='All',test_race!='All') %>% 
  select(
    test_race,test_age,fairface_p_value,deepface_p_value,
    fairface_n,deepface_n,fairface_prop,deepface_prop,source_prop) %>%
  rename(
    Race=test_race,Category=test_age,
    f_p_value=fairface_p_value,
    d_p_value=deepface_p_value
  )

#extract the data from Carl's calculations race by gender
#transform to have similar columns to the result table for an inner-join
p_race_gender <- p_value_results %>%
  filter(test_prop=='genders',test_age=='All',test_gender!='All',test_race!="All") %>% 
  #select(test_race,test_gender,fairface_p_value,deepface_p_value) %>%
  select(
    test_race,test_gender,fairface_p_value,deepface_p_value,
    fairface_n,deepface_n,fairface_prop,deepface_prop,source_prop) %>%
  rename(
    Race=test_race,Category=test_gender,
    f_p_value=fairface_p_value,
    d_p_value=deepface_p_value
  )

#union the two sets of results from Carl's work to a single tibble
hyp_test <- union(p_race_age,p_race_gender)

#inner-join Carl and Bav's results
combined_results <- result_table%>%inner_join(hyp_test,by=c('Race'='Race','Category'='Category'))
```

### Updated Table Version with Data from Carl, Bav
```{r}
combined_results%>%
  select(Race:d_p_value)%>% knitr::kable()
  
```

### Statistical Power


$$
\beta = P\bigg(\bigg|\frac{\sqrt{n}\cdot\hat{p}-p_a}{\sqrt{p_a(1-p_a)}}\bigg|\geq\frac{\sqrt{n}\cdot p_0-p_a}{\sqrt{p_0(1-p_0)}}\bigg)
$$

Our selected level of significance is 99.7% (3-sigma).  Type-II error is denoted by $\beta$ above, and Power will be $1-\beta$  

With $p_0$ being our *assumed* population proportion (from the source dataset and what we used in our tests), $p_a$ being the *actual* population proportion (from one or more of the below methods), $n$ being the number of predicted members of a racial group (i.e. "Indian"), 

* For Gender - assume that sex at birth is a bernoulli trial, over time, the proportion for both genders should be 0.5

* For age groups - assume that age has a true normal distribution.  Each race may have different means and standard deviations for their distribution of age, but still adhere to a normal distribution.  The "population" proportions may be a bit more challenging to calculate, but under this framework, we may be able to get there.

  * May be able to get via bootstrapping the source dataset, average age by race - I think that's what we did in our last project?

  * Could look at external data? May not have time to look through everything.


```{r PowerCalcs}

TypeII <- function(p0,pa,n){
  z <- (sqrt(n)*(p0-pa))/(sqrt(p0*(1-p0)))
}

```


<!-- PC? - will edit / remove below items. Want to merge Carl and Bav's work !-->

```{r, include=FALSE}
#pull in the master data frame for use
master_df <- read_csv('https://raw.githubusercontent.com/CUBoulder-DS/5301-5000-Final-Report/main/data/MasterDataFrame.csv', show_col_types = FALSE)

#get the deepface-only results
DF_results <- master_df %>% filter(pred_model=='DeepFace') %>% drop_na(pred_age_grp)
DF_results

#get the fairface-only results
FF_results <- master_df %>% filter(pred_model=='FairFace') %>% drop_na(pred_age_grp)
#FF_results

#isolate the source information
master_src <- master_df %>% filter(!duplicated(file)) %>% select(file,src_age,src_age_grp,src_gender,src_race)
```

```{r}

#some example functions for getting proportions

# get_proportion <- function(df,evaluate_column,evaluate_value){
#   x <- df %>% filter(!!as.symbol(evaluate_column)==evaluate_value)%>% count() %>% unlist() %>% unname()
#   if (x==0){
#     0
#   } else {
#     result <- df %>% group_by(!!as.symbol(evaluate_column)) %>%
#       summarise(n=n())%>%
#       mutate(prop=n/sum(n))%>%
#       filter(!!as.symbol(evaluate_column)==evaluate_value)%>%
#       select(prop)%>%unlist()%>% unname()
#     print(result)
#     # if (!is.na(result)) {
#     #   result
#     # } else {
#     #   0
#     # }
#   }
# }

# #fiters down to a specific group, first, then 
# get_proportion_subset <- function(df,filter_column,filter_value,evaluate_column,evaluate_value){
#   x <- df %>% filter(!!as.symbol(evaluate_column)==evaluate_value)%>% count() %>% unlist() %>% unname()
#   if (x==0){
#     0
#   } else {
#     result <- df %>% filter(!!as.symbol(filter_column) == filter_value) %>%
#       group_by(!!as.symbol(evaluate_column)) %>%
#       summarise(n=n()) %>%
#       mutate(prop = n/sum(n)) %>%
#       filter(!!as.symbol(evaluate_column)==evaluate_value) %>%
#       select(prop) %>% unlist() %>% unname()
#     # if (!is.na(result)) {
#     #   result
#     # } else {
#     #   0
#     # }
#   }
# }

# get_counts <- function(df,evaluate_column,evaluate_value){
#   x <- df %>% filter(!!as.symbol(evaluate_column)==evaluate_value)%>% count() %>% unlist() %>% unname()
#   if (x==0){
#     0 
#   } else {
#     df %>% group_by(!!as.symbol(evaluate_column)) %>%
#       summarise(n=n())%>%
#       filter(!!as.symbol(evaluate_column)==evaluate_value) %>%
#       select(n)%>%unlist()%>%unname()
#   }
# }

# r_groups <- c("Asian","Black","Indian","Other","White")
# a_groups <- c("0-2","3-9","10-19","20-29","30-39","40-49","50-59","60-69","70-130")
# g_groups <- c("Male","Female")

# #examples - 
# #give the proportion of black people in the source data
# #   get_proportion(master_src,'src_race','Black')
# #filters on black being the predicted race, then gets the proportion of predicted gender for females.
# #   get_proportion_subset(FF_results,'pred_race','Black','pred_gender','Female')

# #get all the source data proportions into arrays (referenceable by group name)
# source_race_props <- sapply(r_groups,get_proportion,df=master_src,evaluate_column="src_race")
# source_age_props <- sapply(a_groups,get_proportion,df=master_src,evaluate_column="src_age_grp")
# source_gen_props <- sapply(g_groups,get_proportion,df=master_src,evaluate_column="src_gender")
# source_race_counts <- sapply(r_groups,get_counts,df=master_src,evaluate_column="src_race")
# source_age_counts <- sapply(a_groups,get_counts,df=master_src,evaluate_column="src_age_grp")
# source_gen_counts <- sapply(g_groups,get_counts,df=master_src,evaluate_column="src_gender")

# #deepface prediction proportions
# DF_pred_race_props <- sapply(r_groups,get_proportion,df=DF_results,evaluate_column="pred_race")
# DF_pred_age_props <- sapply(a_groups,get_proportion,df=DF_results,evaluate_column="pred_age_grp")
# DF_pred_gen_props <-sapply(g_groups,get_proportion,df=DF_results,evaluate_column="pred_gender")
# DF_pred_race_counts <- sapply(r_groups,get_counts,df=DF_results,evaluate_column="pred_race")
# DF_pred_age_counts <- sapply(a_groups,get_counts,df=DF_results,evaluate_column="pred_age_grp")
# DF_pred_gen_counts <- sapply(g_groups,get_counts,df=DF_results,evaluate_column="pred_gender")

# #fairface prediction proportions
# FF_pred_race_props <- sapply(r_groups,get_proportion,df=FF_results,evaluate_column="pred_race")
# FF_pred_age_props <-sapply(a_groups,get_proportion,df=FF_results,evaluate_column="pred_age_grp")
# FF_pred_gen_props <-sapply(g_groups,get_proportion,df=FF_results,evaluate_column="pred_gender")
# FF_pred_race_counts <- sapply(r_groups,get_counts,df=FF_results,evaluate_column="pred_race")
# FF_pred_age_counts <- sapply(a_groups,get_counts,df=FF_results,evaluate_column="pred_age_grp")
# FF_pred_gen_counts <- sapply(g_groups,get_counts,df=FF_results,evaluate_column="pred_gender")

# n_DF <- count(DF_results%>%filter(!is.na(pred_gender))) %>% unlist() %>% unname()

# n_FF <- count(FF_results %>% filter(!is.na(pred_gender))) %>% unlist() %>% unname()

# prop_p_values <- function(group,src_prop,pred_prop,pred_n){

#   num <- (sqrt(pred_n[group])*(src_prop[group]-pred_prop[group]))
#   den <- (sqrt(pred_prop[group]*(1-pred_prop[group])))
#   test_stat <- abs(num/den)
#   pnorm(-test_stat) + (1 - pnorm(test_stat))
# }

# DF_race_p_values <- sapply(
#   r_groups,
#   prop_p_values,
#   src_prop=source_race_props,
#   pred_prop=DF_pred_race_props,
#   pred_n=DF_pred_race_counts
# )
# names(DF_race_p_values)<- str_c("p.",r_groups)

# FF_race_p_values <- sapply(
#   r_groups,
#   prop_p_values,
#   src_prop=source_race_props,
#   pred_prop=FF_pred_race_props,
#   pred_n=FF_pred_race_counts
# )
# names(FF_race_p_values)<- str_c("p.",r_groups)

# DF_gen_p_values <- sapply(
#   g_groups,
#   prop_p_values,
#   src_prop=source_gen_props,
#   pred_prop=DF_pred_gen_props,
#   pred_n=DF_pred_gen_counts
# )
# names(DF_gen_p_values)<- str_c("p.",g_groups)

# FF_gen_p_values <- sapply(
#   g_groups,
#   prop_p_values,
#   src_prop=source_gen_props,
#   pred_prop=FF_pred_gen_props,
#   pred_n=FF_pred_gen_counts
# )
# names(FF_gen_p_values)<- str_c("p.",g_groups)

# FF_age_p_values <- sapply(
#   a_groups,
#   prop_p_values,
#   src_prop=source_age_props,
#   pred_prop=FF_pred_age_props,
#   pred_n=FF_pred_age_counts
# )
# names(FF_age_p_values)<- str_c("p.",a_groups)

# DF_age_p_values <- sapply(
#   a_groups,
#   prop_p_values,
#   src_prop=source_age_props,
#   pred_prop=DF_pred_age_props,
#   pred_n=DF_pred_age_counts
# )
# names(DF_age_p_values)<- str_c("p.",a_groups)

# str_c("p.",a_groups)

#DF_race_p_values <- sapply(r_groups, prop_p_values, src_prop=source_race_props, pred_prop=DF_pred_race_props,pred_n=n_DF)
#FF_race_p_values <- sapply(r_groups, prop_p_values, src_prop=source_race_props, pred_prop=FF_pred_race_props,pred_n=n_FF)
#DF_age_p_values <- sapply(a_groups, prop_p_values, src_prop=source_age_props, pred_prop=DF_pred_age_props,pred_n=n_DF)
#DF_gender_p_values <- sapply(g_groups,prop_p_values, src_prop=source_gen_props, pred_prop=DF_pred_gen_props,pred_n=n_DF)
```

```{r}
#get_proportion_subset <- function(df,filter_column,filter_value,evaluate_column,evaluate_value){
#sapply(r_groups,get_proportion_a_given_b,filter_column="",filter_value="",evaluate_column="")

#sapply(r_groups, prop_p_values, src_prop=source_race_props, pred_prop=DF_pred_race_props,pred_n=DF_pred_race_counts)

```

```{r}
# test <- function(df,src_col,pred_col,val){
#   y <- df %>% select(!!as.symbol(pred_col))
#   x <- df %>% select(!!as.symbol(src_col))
#   c(x,y)
# }

# test1 <- function(df,tuple){
#   print(tuple)
# }

# iter <- t(data.frame(
#   src_col = c(
#     replicate(length(r_groups),"src_race"),
#     replicate(length(a_groups),"src_age_grp"),
#     replicate(length(g_groups),"src_gender")
#   ),
#   pred_col = c(
#     replicate(length(r_groups),"pred_race"),
#     replicate(length(a_groups),"pred_age_grp"),
#     replicate(length(g_groups),"pred_gender")
#   ),
#   val = c(
#     r_groups,
#     a_groups,
#     g_groups
#   )
# ))

# lapply(iter,print)
# sapply(iter,test1,df=master_df)
```

```{r}
# knitr::kable(FF_gen_p_values)

# knitr::kable(DF_gen_p_values)
```

```{r}
# knitr::kable(FF_race_p_values)

# knitr::kable(DF_race_p_values)
```

$$
\frac{\sqrt{n_M}\cdot(\bar{p}_M-p_S)}{\sqrt{p_S\cdot(1-P_S)}}
$$

```{r}
# source_gen_props['Female']

# source_race_props['Asian']

# source_race_props
# FF_pred_race_props
# DF_pred_race_props

# source_gen_props
# FF_pred_gen_props
# DF_pred_gen_props
```
