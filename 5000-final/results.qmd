# Results

```{r setup, include=FALSE}
#| include: false
# BJ
library(tidyverse)
library(caret)
library(kableExtra)
library(gt)
library(broom)
```

<!-- BJ !-->

```{r load_data, include=FALSE}
# CK, BJ
# master dataframe url
output_name <- 'https://raw.githubusercontent.com/CUBoulder-DS/5301-5000-Final-Report/main/data/MasterDataFrame.csv'

# entire master dataframe
output_df <- read_csv(output_name, show_col_types = FALSE) %>% 
  select(-c(img_path, file)) %>%
  mutate_if(is.character, as.factor) 

# Get chr columns as factors, re-ordered as they should
output_df$src_age_grp = factor(output_df$src_age_grp, 
                               levels = c("0-2", "3-9", "10-19", "20-29", "30-39", "40-49", "50-59", "60-69", "70-130"))
output_df$pred_age_grp = factor(output_df$pred_age_grp, 
                               levels = c("0-2", "3-9", "10-19", "20-29", "30-39", "40-49", "50-59", "60-69", "70-130"))
output_df$src_race = factor(output_df$src_race, levels=c("White", "Black", "Asian", "Indian", "Other"))
output_df$pred_race = factor(output_df$pred_race, levels=c("White", "Black", "Asian", "Indian", "Other"))

# Add correctness columns
output_df = output_df %>% 
  mutate(correct_gender = (src_gender == pred_gender), 
         correct_age = (src_age_grp == pred_age_grp), 
         correct_race = (src_race == pred_race))
  

# fairface dataframe
# exclude the indexing column and deepface only column
fairface_df <- output_df %>%
  filter(pred_model == 'FairFace') %>%
  select(-c(...1, pred_age_DF_only)) %>%
  drop_na()

# deepface dataframe
# exclude the indexing column
deepface_df <- output_df %>%
  filter(pred_model == 'DeepFace') %>%
  select(-...1) %>%
  drop_na()

# source dataframe
# use one of the models (since the data is doubled)
# include only the source ("src") columns
source_df <- output_df %>%
  filter(pred_model == 'FairFace') %>%
  select(c(src_age, src_age_grp, src_gender, src_race, src_timestamp)) %>%
  drop_na()

# p-value two sample calcs table
# df_name <- 'https://raw.githubusercontent.com/CUBoulder-DS/5301-5000-Final-Report/main/data/pvalue_results_two_sample.csv'
# p_value_results <- read_csv(df_name)

#added DeepFace only T-testing for age when controlled for gender/race
DeepFace_Only_T_tests <- read_csv('https://raw.githubusercontent.com/CUBoulder-DS/5301-5000-Final-Report/main/data/DF_t_tests.csv') %>% select(test_gender:power) %>% rename(gender=test_gender,race=test_race)

stats_results <- read_csv('https://raw.githubusercontent.com/CUBoulder-DS/5301-5000-Final-Report/main/data/combined_p_val_F1_acc.csv')

table_ages <- c("0-2", "3-9", "10-19", "20-29", "30-39", "40-49", "50-59", "60-69", "70-130")
table_races <- c("White", "Black", "Asian", "Indian", "Other")
table_genders <- c("Female", "Male")
```

<!-- BJ !-->

## Model Output

The two models, DeepFace and FairFace, were run on the dataset described previously. In @fig-output-hists, one can see the results of the predictions done by each model, by each factor that was considered: age, gender, and race. Note that the total (across correct and incorrect) histogram distributions match the correct (source dataset) distributions of values in each category, so we can see exactly the difference between what was provided and what was predicted, along with how well each model did on each category within each factor.

```{r plot_hists}
#| label: fig-output-hists
#| fig-cap: Histograms of the output from DeepFace and FairFace, with correct vs incorrect values colored. Note that the distributions match the correct (source dataset) distributions.
#| fig-subcap: 
#|   - Gender predictions
#|   - Age predictions
#|   - Race predictions
#| layout-ncol: 2
#| layout-nrow: 2
# BJ

plot_category = function(src, correct, label) {
  num_cats = length(levels(output_df[[src]]))
  
  plot = ggplot() +
    geom_bar(mapping=aes(x=as.numeric(interaction(output_df[["pred_model"]], output_df[[src]])),
                         fill=interaction(output_df[["pred_model"]], output_df[[correct]]))) +
    scale_x_continuous(label, 
                       breaks=seq(1.5, 2*num_cats, 2), 
                       labels=levels(output_df[[src]]), 
                       limits=c(0,2*num_cats + 1)) +
    scale_fill_manual("Model and Correctness",
                      values = c("orangered", "firebrick", "springgreen", "green4"),
                      labels = c("DeepFace, incorrect", "FairFace, incorrect", "DeepFace, correct", "FairFace, correct"))
  
  return(plot)
}


plot_category("src_gender", "correct_gender", "Gender")
plot_category("src_age_grp", "correct_age", "Age")
plot_category("src_race", "correct_race", "Race")
```

## Model Performance

### TODO: Remove

```{r perfomance_table}
# BJ 

# get_f1_acc = function(df) {
#   age = confusionMatrix(df$pred_age_grp, df$src_age_grp, mode="everything")[["byClass"]]
#   race = confusionMatrix(df$pred_race, df$src_race, mode="everything")[["byClass"]]
#   gender = confusionMatrix(df$pred_gender, df$src_gender, mode="everything")[["byClass"]]
#   
#   names = c(age[, "F1"] %>% names() %>% str_replace("Class: ", ""), 
#             race[, "F1"] %>% names() %>% str_replace("Class: ", ""), 
#             "Female")
#   f1 = c(age[, "F1"], race[, "F1"], gender["F1"])
#   acc = c(age[, "Balanced Accuracy"], race[, "Balanced Accuracy"], gender["Balanced Accuracy"])
#   
#   values = tibble(Category = names, F1 = f1, Accuracy = acc)
#   return(values)
# }
# 
# perf_table = full_join(get_f1_acc(fairface_df), 
#                        get_f1_acc(deepface_df), 
#                        suffix=c("_F", "_D"), 
#                        by="Category")

```

```{r tbl-model-perf}
#| label: tbl-model-perf
#| tbl-cap: Table of F1 score and accuracy, by each category evaluated by the models
#output: asis
# BJ 

# perf_table %>%
#   gt() %>%
#   tab_options(quarto.use_bootstrap=TRUE) %>%
#   fmt_number(columns = -c(1), decimals=5) %>%
#   tab_spanner(label = md("**FairFace**"), columns = c(2, 3)) %>% 
#   tab_spanner(label = md("**DeepFace**"), columns = c(4, 5)) %>%
#   tab_row_group(label = md("**Gender**"), rows = c(15)) %>%
#   tab_row_group(label = md("**Race**"), rows = 10:14) %>%
#   tab_row_group(label = md("**Age**"), rows = 1:9) %>%
#   cols_label(starts_with("F1") ~ md("**F1**"), starts_with("Accuracy") ~ md("**Accuracy**")) %>%
#   tab_options(table.width = pct(100)) %>%
#   data_color(columns=2:5, palette="PiYG", domain=c(0, 1), alpha=0.75)
  ## BJ NOTE: Cannot have interactive table with also column spanning headings / row groups!
  # opt_interactive(use_search=TRUE, use_filters=FALSE, use_highlight=TRUE)
```

## Hypothesis Testing

### TODO: Remove

<!-- CK !-->

```{r pval_ages}
# p_value_results %>%
#   filter(test_gender == "All") %>%
#   filter(test_race == "All") %>%
#   select(test_age, source_prop, fairface_prop,
#          fairface_p_value, deepface_prop, deepface_p_value) %>%
#   arrange(factor(test_age, levels = table_ages)) %>%
#   kbl(col.names = c("Test cateogry", "Null Proportion", "FairFace Proportion", "FairFace P-Value",
#                     "DeepFace Proportion", "DeepFace P-Value")) %>% 
#   kable_styling(full_width = T) %>%
#   column_spec(1, bold = T)
```

```{r pval_races}
# p_value_results %>%
#   filter(test_gender == "All") %>%
#   filter(test_age == "All") %>%
#   select(test_race, source_prop, fairface_prop,
#          fairface_p_value, deepface_prop, deepface_p_value) %>%
#   arrange(factor(test_race, levels = table_races)) %>%
#   kbl(col.names = c("Test cateogry", "Null Proportion", "FairFace Proportion", "FairFace P-Value",
#                     "DeepFace Proportion", "DeepFace P-Value")) %>% 
#   kable_styling(full_width = T) %>%
#   column_spec(1, bold = T)
```

```{r pval_genders}
# p_value_results %>%
#   filter(test_race == "All") %>%
#   filter(test_age == "All") %>%
#   select(test_gender, source_prop, fairface_prop,
#          fairface_p_value, deepface_prop, deepface_p_value) %>%
#   arrange(factor(test_gender, levels = table_genders)) %>%
#   kbl(col.names = c("Test cateogry", "Null Proportion", "FairFace Proportion", "FairFace P-Value",
#                     "DeepFace Proportion", "DeepFace P-Value")) %>% 
#   kable_styling(full_width = T) %>%
#   column_spec(1, bold = T)
```

```{r pval_races_by_gender}
# p_value_results %>%
#   filter(test_prop == 'genders') %>%
#   filter(test_age == 'All') %>%
#   filter(test_gender != 'All') %>%
#   filter(test_race != 'All') %>%
#   select(test_gender, test_race,test_race, source_prop, fairface_prop,
#          fairface_p_value, deepface_prop, deepface_p_value) %>%
#   arrange(factor(test_gender, levels = table_genders)) %>%
#   kbl(col.names = c("Test Category", "Test Condition", "Null Proportion", "FairFace Proportion", "FairFace P-Value",
#                     "DeepFace Proportion", "DeepFace P-Value")) %>% 
#   kable_styling(full_width = T) %>%
#   column_spec(1, bold = T)
```

```{r PC_subgroup_pval_acc_f1}

#subgroups 
  #control for source? pred? race, then breakdown F1/accuracy for age and gender
  #Carl's tables - same story
  #do a left-join between on main group (race) and respective sub-group
  #merge into and present single table
  #provide color-coding for areas of issue:
    # p-value: where we're below 1-.997 (3-sigma significance level)
    # F1 and Accuracy - ?

# rename_f_d_cols = function(x) {
#   rename_with(x, ~ paste("fairface", str_replace(., "_f", ""), sep="_"), ends_with("_f")) %>%
#     rename_with(~ paste("deepface", str_replace(., "_d", ""), sep="_"), ends_with("_d"))
# }
# 
# rgrps <- as.character(unique(source_df$src_race))
# #modified version of Bav's function - allows to first filter by racial group
# #then proceed to compute accuracy for age and gender in each category
# f1_acc_subset <- function(df,rgrp){
#   tdf <- df %>% filter(as.character(src_race)==as.character(rgrp))
#   age <- confusionMatrix(tdf$pred_age_grp, tdf$src_age_grp, mode="everything")[["byClass"]]
#   #added additional steps for male and female so we have rows for each in the results.
#   gen_m <- confusionMatrix(tdf$pred_gender, tdf$src_gender, mode="everything",positive='Male')[["byClass"]]
#   gen_f <- confusionMatrix(tdf$pred_gender, tdf$src_gender, mode="everything",positive='Female')[["byClass"]]
#   g_names <- c("Class: Male","Class: Female")
#   gender<- cbind(gen_m,gen_f)
#   colnames(gender) <- g_names
#   gender <- t(gender)
#   #end additional steps
#   f1 <- c(age[,'F1'],gender[,'F1'])
#   acc <- c(age[, "Balanced Accuracy"],gender[, "Balanced Accuracy"])
#   names <- c(
#     age[, "F1"] %>% names() %>% str_replace("Class: ",""),
#     gender[, "F1"] %>% names() %>% str_replace("Class: ","")
#   )
#   res <- tibble(Category = names,F1=f1, Accuracy=acc, Race=rgrp)
#   res %>% mutate(Race=rgrp)#,Key=str_c(rgrp,"-",Category)) #use to inner-join with hypothesis test results.
# }
# 
# #helper function to merge results from sapply
# table_join <- function(ff,df,rgrp){
#   full_join(as_tibble(ff[, rgrp]),as_tibble(df[,rgrp]), suffix=c("_f", "_d"),by=c('Category','Race')) %>%
#     rename_f_d_cols()
# }
# 
# #use sapply to get a list of tibbles (one for each race) from fairface and deepface
# FairFace <-sapply(rgrps,f1_acc_subset,df=fairface_df)
# DeepFace <-sapply(rgrps,f1_acc_subset,df=deepface_df)
# 
# #take the results and extract the sub-tibbles from fairface and deepface, combine into single sub-tibble in one list
# full <- sapply(rgrps,table_join,ff=FairFace,df=DeepFace)
# 
# #create a master table to which we can aggregate all results
# result_table <- tibble(Race=character(),Category=character(),fairface_F1=numeric(),fairface_Accuracy=numeric(),deepface_F1=numeric(),deepface_Accuracy=numeric())
# 
# #build the result table
# for (g in rgrps){
#   x <- as_tibble(full[,g]) %>% select(Race,Category,fairface_F1,fairface_Accuracy,deepface_F1,deepface_Accuracy)
#   result_table<-union(result_table,x)
# }
# 
# #extract the data from Carl's calculations race by age
# #transform to have similar columns to the result table for an inner-join
# p_race_age <- p_value_results %>%
#   filter(test_prop=='age_bins',test_gender=='All',test_age!='All',test_race!='All') %>% 
#   select(
#     test_race,test_age,fairface_p_value,deepface_p_value,
#     fairface_n,deepface_n,fairface_prop,deepface_prop,source_prop, fairface_power, deepface_power) %>%
#   rename(Race=test_race,Category=test_age)
# 
# #extract the data from Carl's calculations race by gender
# #transform to have similar columns to the result table for an inner-join
# p_race_gender <- p_value_results %>%
#   filter(test_prop=='genders',test_age=='All',test_gender!='All',test_race!="All") %>% 
#   #select(test_race,test_gender,fairface_p_value,deepface_p_value) %>%
#   select(
#     test_race,test_gender,fairface_p_value,deepface_p_value,
#     fairface_n,deepface_n,fairface_prop,deepface_prop,source_prop, fairface_power, deepface_power) %>%
#   rename(Race=test_race,Category=test_gender)
# 
# #union the two sets of results from Carl's work to a single tibble
# hyp_test <- union(p_race_age,p_race_gender)
# 
# ## BJ
# ## Include columns for no race condition
# all_cats = c("race", "age", "gender")
# filter_pvalues_no_cond = function(category) {
#   test_cat = \(x) paste("test", x, sep="_")
#   cats = all_cats[all_cats != category]
#   
#   p_value_results %>%
#     filter(.data[[test_cat(cats[1])]] == "All", .data[[test_cat(cats[2])]] == "All") %>%
#     select(test_cat(category), fairface_p_value, deepface_p_value, 
#            fairface_prop, deepface_prop, source_prop, fairface_n, deepface_n, fairface_power, deepface_power) %>%
#     rename_with(\(x) "Category", starts_with("test_")) %>%
#     # rename_f_d_cols() %>%
#     mutate("Race" = "All")
# }
# 
# perf_all_race = full_join(get_f1_acc(fairface_df), get_f1_acc(deepface_df), suffix=c("_f", "_d"), by="Category") %>%
#                 mutate(Race = "All") %>%
#                 rename_f_d_cols()
# 
# pvalues_all_race = bind_rows(lapply(all_cats, filter_pvalues_no_cond))
# 
# 
# #inner-join Carl and Bhav's results
# combined_results <- result_table%>%inner_join(hyp_test,by=c('Race'='Race','Category'='Category'))
# combined_results <- full_join(perf_all_race, pvalues_all_race, by=c("Category", "Race")) %>%
#                       bind_rows(combined_results) %>%
#                       # Reorder
#                       select(Race, Category, all_of(order(names(combined_results))))
# 

# BJ
# Pivot columns to reduce num of cols, add model column
```

```{r view_stat_results}
# BJ
view_results = stats_results %>% 
                filter(test_age == "All" | test_gender == "All" | test_race == "All") %>%
                select(-c(source_n, model_n, model_prop, source_prop)) %>% 
                replace(. == "age_bins", "ages")
```

### Updated Table Version with Data from Carl, Bhav

#### TODO: Remove

```{r}
# PC?

# combined_results %>%
#   select(Race:p_value_f)%>% knitr::kable()
# 
# 
# combined_results %>% 
#   select(Race:Category,source_prop,n_d,prop_d,p_value_d,n_f,prop_f,p_value_f) #%>% knitr::kable()
# 
# combined_results %>%
#   ggplot()+
#   geom_point(aes(x=Accuracy_d,y=p_value_d),color='black')+
#   geom_point(aes(x=Accuracy_f,y=p_value_f),color='blue')+
#   xlim(0,1)+ylim(0,1)
# 
# combined_results %>%
#   mutate(logp_d = as.integer(p_value_d > .003)) %>% 
#   ggplot()+
#   geom_point(aes(x=Accuracy_d,y=logp_d),color='black')#+
#   #xlim(0,1)+ylim(0,1)
# 
# combined_results %>% 
#   mutate(logp_f = as.integer(p_value_d > .003)) %>% 
#   ggplot()+
#   geom_point(aes(x=Accuracy_f,y=logp_f),color='blue')#+
  #xlim(0,1)+ylim(0,1)


# combined_results %>% 
#   mutate(
#     new_p_value_f = 
#   )

```

<!-- BJ !-->

## Model Performance, Hypothesis Testing

For each category and model, we calculate the F1 score, accuracy, and p-value, as described in section 3. Cell values are colored according to the strength of the metric. We also specifically looked at the performance metrics of the models, when controlled for specific source categories; TODO

### TODO

-   Add color key
-   Better description of signifiance of numerical values of Accuracy, F1 score, power

::: {.content-visible when-format="html"}
The results are summarized in @tbl-perf-pvalue. 

::: {#tbl-perf-pvalue}
```{r perf-pvalue}
#| label: tbl-perf-pvalue
# BJ
# Note: For some reason, making the table interactive (aka HTML) breaks Quarto table labeling/captioning/crossref
# That's why we use a combination of table div and label.

colnames = setNames(c("**Test Factor**", "**Age**", "**Gender**", "**Race**", "**p-Value**", "**Power**", "**F1 Score**", "**Accuracy**", "**Model**"),
                    names(view_results))

view_results %>%
  gt() %>%
  opt_interactive(use_search = T, use_filters = T, use_highlight = T, page_size_default = 15, use_resizers=T) %>%
  tab_options(table.width = pct(100), quarto.use_bootstrap=T) %>%
  fmt_scientific(columns = 5, n_sigfig=3, drop_trailing_zeros=T, exp_style="e") %>%
  fmt_number(columns = 6:8, decimal=4) %>%
  cols_label(.list=as.list(colnames), .fn=md) %>%
  data_color(columns=6:8, palette="PiYG", domain=c(0, 1), alpha=0.75) %>%
  data_color(columns=5, method="bin", palette = c("#B1DC96", "#F2B8D2"), bins=c(0, 0.003, 1))
```

```{r}
## PC
# combined_results %>%
#   select(Race:p_value_f) %>%
#   gt() %>%
#   tab_options(quarto.use_bootstrap=TRUE, table.width = pct(100), table.font.size=8) %>%
#   fmt_number(columns = -c(1, 2), decimals=5) %>%
#   # tab_spanner(label = md("**FairFace**"), columns = c(2, 3)) %>% 
#   # tab_spanner(label = md("**DeepFace**"), columns = c(4, 5)) %>%
#   # tab_row_group(label = md("**Gender**"), rows = c(15)) %>%
#   # tab_row_group(label = md("**Race**"), rows = 10:14) %>%
#   # tab_row_group(label = md("**Age**"), rows = 1:9) %>%
#   # cols_label(starts_with("F1") ~ md("**F1**"), starts_with("Accuracy") ~ md("**Accuracy**")) %>%
#   data_color(columns=3:6, palette="PiYG", domain=c(0, 1), alpha=0.75) %>%
#   data_color(columns=9:10, palette="PiYG", alpha=0.75, reverse=T) %>%
#   opt_interactive(use_search = T, use_filters = T, use_highlight = T, page_size_default = 15) %>%
#   tab_caption("TODO 2 Table of F1 score and accuracy, by each category evaluated by the models")
```

TODO 3 Table of F1 score, accuracy, p-value, and power, by each category evaluated by the models
:::
:::

::: {.content-visible when-format="pdf"}
The results are summarized in @fig-perf-pvalue. 

![Screenshot of the interactive table showing TODO. To see and interact with this table, go to [the website link](https://cuboulder-ds.github.io/5301-5000-Final-Report/results.html)]("images/table_interactive.png"){#fig-perf-pvalue}
:::

### p-value Critical Values

From the previous table, we extract and highlight key values; namely, the p-values where we reject the null hypothesis at a significance level of 99.7%, and where there is no conditional filtering based on another category. The values are displayed in @tbl-perf-selected.

```{r tbl-perf-selected}
#| label: tbl-perf-selected
#| tbl-cap: TODO 
# BJ

view_results %>%
  filter(model_p_value < 0.003, 
         model_power > 0.8, 
         (test_age == "All") + (test_gender == "All") + (test_race == "All") > 1) %>%
  replace(. == "All", NA) %>%
  unite("test_subcat", test_age:test_race, remove=T, na.rm=T) %>%
  gt()

# tbl_gt = combined_results %>% 
#   filter(p_value_f > 0.03 | p_value_d > 0.03) %>%
#   select(Race, Category, p_value_d, p_value_f) %>%
#   unite(cat, c(Race, Category)) %>%
#   # t() %>% data.frame() %>% row_to_names(1) %>%
#   # add_column("Model p-value" = c("DeepFace", "FairFace"), .before=1) %>%
#   gt(rowname_col = "cat") %>%
#   tab_options(column_labels.font.weight="bold", 
#           row_group.font.weight="bold",
#           # stub.font.weight="bold",
#           # table.width = pct(100), 
#           # TODO: DOESN'T WORK?!?!!
#           # row_group.as_column = T
#           ) %>%
#   fmt_number(decimals=4) %>%
#   tab_stubhead("Test Condition, Category") %>%
#   text_transform( \(x) str_remove(x, ".*_"), locations = cells_stub()) %>%
#   cols_label(p_value_d="DeepFace", p_value_f="FairFace") %>%
#   tab_spanner("p-value", columns=1:3) %>%
#   data_color(method="bin", palette = c("#B1DC96", "#F2B8D2"), bins=c(0, 0.03, 1)) %>%
#   tab_row_group("No Test Condition", rows=starts_with("All"), id="All")
# for (r in table_races) {
#   tbl_gt = tab_row_group(tbl_gt, sprintf("Race: %s", r), rows=starts_with(r), id=r)
# }
# 
# # tbl_gt = gt_split(tbl_gt, row_every_n=5)
# 
# tbl_gt
```

```{r tbl-DF-T-Tests, warning=F}
#| label: tbl-DF-T-Tests
#| tbl-cap: Rejected Null Hypotheses for DeepFace Mean Age T-Testing

#PC
##ran t tests to compare mean ages between source data and DeepFace
# DeepFace_Only_T_tests %>%
#   filter(p_value <0.003,power > 0.8) %>%
#   gt()

# T-Test Parameters: 

# * Confidence level: 0.997

# * Two-sided test

# Statistical Power T-Test Parameters: 

# * Effect Size: +/- 5 years in age

# * Significance level: 0.003

# * Two-sided test
```


### Comparison Plots

```{r, warning=F}
# BJ

#PC - commented out, we decided this plot didn't make sense.
# ggplot(stats_results) +
#   geom_point(aes(x=model_F1, y=model_p_value, color=model, fill=model_power), shape=21)

# ggplot(stats_results) +
#   geom_point(aes(x=model_F1, y=model_Accuracy, color=model))

# ggplot(stats_results) +
#   geom_point(aes(x=model_power, y=model_p_value, color=model))


#classify our test results as TP,TN,FP,FN or unknown.
classify <- function(p_val,power,F1){
  #handle NAs...
	if (!is.numeric(p_val) | !is.numeric(F1) | is.nan(p_val) | is.nan(F1)){
			"Unknown"
  #assume cases where we have no F1 or P-value
	} else if (is.na(F1) | is.na(p_val)) {
    if (!is.na(p_val)&p_val < 0.003){
		"True Positive"  #TP = reject the null, and we should
    } else {
      "Unknown"
    }
	} else if(p_val >=0.003 & F1 >= 0.9 & power < 0.8){
		"True Negative" #TN = fail to reject the null when we shouldn't
	} else if (p_val < 0.003 & F1 < 0.9 & power >= 0.8) {
		"True Positive" #TP = reject the null, and we should
	} else if (p_val >= 0.003 & F1 < 0.9 & power < 0.8) {
		"False Negative" #FN = fail to reject the null when it's false 
	} else if (p_val < 0.003 & F1 > 0.9 & power >= 0.8) {
		"False Positive" #FP = reject the null when it's true 
	} else {
		"Unknown" #not sure how we should classify the case.
	}
}

test_result <- function(pval){
  if(is.na(pval) | is.nan(pval)){
    "Unknown"
  } else if (pval<.003){
    "reject null"
  } else {
    "fail to reject null"
  }
}

result_confusion <- function(p_val,power,F1){
    #handle NAs...
	if (!is.numeric(p_val) | !is.numeric(F1) | is.nan(p_val) | is.nan(F1)){
			"Unknown"
  #assume cases where we have no F1 or P-value
	} else if (is.na(F1) | is.na(p_val)) {
    if (!is.na(p_val)&p_val < 0.003){
		"reject null"  #TP = reject the null, and we should
    } else {
      "Unknown"
    }
	} else if(p_val >=0.003 & F1 >= 0.9 & power < 0.8){
		"fail to reject null" #TN = fail to reject the null when we shouldn't
	} else if (p_val < 0.003 & F1 < 0.9 & power >= 0.8) {
		"reject null" #TP = reject the null, and we should
	} else if (p_val >= 0.003 & F1 < 0.9 & power < 0.8) {
		"reject null" #FN = fail to reject the null when it's false 
	} else if (p_val < 0.003 & F1 > 0.9 & power >= 0.8) {
		"fail to reject null" #FP = reject the null when it's true 
	} else {
		"Unknown" #not sure how we should classify the case.
	}
}

categorized_results <- stats_results %>% 
  rowwise %>%
  mutate(
    result_category=classify(model_p_value,model_power,model_F1),
    p_value_classification=test_result(model_p_value),
    f1_classification=result_confusion(model_p_value,model_power,model_F1)
  ) %>%
  mutate(
    F1_pass = as.numeric(model_F1>=.9),
    reject_null = as.numeric(model_p_value < 0.003 & model_power > 0.8)
  )

###plot the graph as jitter points
categorized_results %>% filter(model=='DeepFace') %>%
  ggplot()+
    geom_jitter(aes(x=reject_null,y=F1_pass,color=result_category))

categorized_results %>% filter(model=='FairFace') %>%
  ggplot()+
    geom_jitter(aes(x=reject_null,y=F1_pass,color=result_category))


#try to make confusion matrices and turn them into tile charts.

fac_lev <- categorized_results %>% pull(f1_classification) %>% unique()

plot_cm <- categorized_results %>% 
  mutate(
    p_value_classification=factor(p_value_classification,levels=fac_lev),
    f1_classification=factor(f1_classification,levels=fac_lev)
  )

ff_tests <- plot_cm %>% filter(model=='FairFace')
ff_results <- confusionMatrix(data=ff_tests$p_value_classification,reference=ff_tests$f1_classification)$table
df_tests <- plot_cm %>% filter(model=='DeepFace')
df_results <- confusionMatrix(data=df_tests$p_value_classification,reference=df_tests$f1_classification,)$table



```


<!-- ### Statistical Power - TODO REMOVE -->
<!-- $$
\beta = P\bigg(\bigg|\frac{\sqrt{n}\cdot\hat{p}-p_a}{\sqrt{p_a(1-p_a)}}\bigg|\geq\frac{\sqrt{n}\cdot p_0-p_a}{\sqrt{p_0(1-p_0)}}\bigg)
$$ -->


<!-- Our selected level of significance is 99.7% (3-sigma). Type-II error is denoted by $\beta$ above, and Power will be $1-\beta$

With $p_0$ being our *assumed* population proportion (from the source dataset and what we used in our tests), $p_a$ being the *actual* population proportion (from one or more of the below methods), $n$ being the number of predicted members of a racial group (i.e. "Indian"),

-   For Gender - assume that sex at birth is a bernoulli trial, over time, the proportion for both genders should be 0.5

-   For age groups - assume that age has a true normal distribution. Each race may have different means and standard deviations for their distribution of age, but still adhere to a normal distribution. The "population" proportions may be a bit more challenging to calculate, but under this framework, we may be able to get there.

    -   May be able to get via bootstrapping the source dataset, average age by race - I think that's what we did in our last project?

    -   Could look at external data? May not have time to look through everything. -->

```{r PowerCalcs}
#can be removed.
# TypeII <- function(p0,pa,n){
#   z <- (sqrt(n)*(p0-pa))/(sqrt(p0*(1-p0)))
# }

```

<!-- PC? - will edit / remove below items. Want to merge Carl and Bav's work !-->

```{r, include=FALSE}
# #pull in the master data frame for use
# master_df <- read_csv('https://raw.githubusercontent.com/CUBoulder-DS/5301-5000-Final-Report/main/data/MasterDataFrame.csv', show_col_types = FALSE)
# 
# #get the deepface-only results
# DF_results <- master_df %>% filter(pred_model=='DeepFace') %>% drop_na(pred_age_grp)
# DF_results
# 
# #get the fairface-only results
# FF_results <- master_df %>% filter(pred_model=='FairFace') %>% drop_na(pred_age_grp)
# #FF_results
# 
# #isolate the source information
# master_src <- master_df %>% filter(!duplicated(file)) %>% select(file,src_age,src_age_grp,src_gender,src_race)
```

```{r}

#some example functions for getting proportions

# get_proportion <- function(df,evaluate_column,evaluate_value){
#   x <- df %>% filter(!!as.symbol(evaluate_column)==evaluate_value)%>% count() %>% unlist() %>% unname()
#   if (x==0){
#     0
#   } else {
#     result <- df %>% group_by(!!as.symbol(evaluate_column)) %>%
#       summarise(n=n())%>%
#       mutate(prop=n/sum(n))%>%
#       filter(!!as.symbol(evaluate_column)==evaluate_value)%>%
#       select(prop)%>%unlist()%>% unname()
#     print(result)
#     # if (!is.na(result)) {
#     #   result
#     # } else {
#     #   0
#     # }
#   }
# }

# #fiters down to a specific group, first, then 
# get_proportion_subset <- function(df,filter_column,filter_value,evaluate_column,evaluate_value){
#   x <- df %>% filter(!!as.symbol(evaluate_column)==evaluate_value)%>% count() %>% unlist() %>% unname()
#   if (x==0){
#     0
#   } else {
#     result <- df %>% filter(!!as.symbol(filter_column) == filter_value) %>%
#       group_by(!!as.symbol(evaluate_column)) %>%
#       summarise(n=n()) %>%
#       mutate(prop = n/sum(n)) %>%
#       filter(!!as.symbol(evaluate_column)==evaluate_value) %>%
#       select(prop) %>% unlist() %>% unname()
#     # if (!is.na(result)) {
#     #   result
#     # } else {
#     #   0
#     # }
#   }
# }

# get_counts <- function(df,evaluate_column,evaluate_value){
#   x <- df %>% filter(!!as.symbol(evaluate_column)==evaluate_value)%>% count() %>% unlist() %>% unname()
#   if (x==0){
#     0 
#   } else {
#     df %>% group_by(!!as.symbol(evaluate_column)) %>%
#       summarise(n=n())%>%
#       filter(!!as.symbol(evaluate_column)==evaluate_value) %>%
#       select(n)%>%unlist()%>%unname()
#   }
# }

# r_groups <- c("Asian","Black","Indian","Other","White")
# a_groups <- c("0-2","3-9","10-19","20-29","30-39","40-49","50-59","60-69","70-130")
# g_groups <- c("Male","Female")

# #examples - 
# #give the proportion of black people in the source data
# #   get_proportion(master_src,'src_race','Black')
# #filters on black being the predicted race, then gets the proportion of predicted gender for females.
# #   get_proportion_subset(FF_results,'pred_race','Black','pred_gender','Female')

# #get all the source data proportions into arrays (referenceable by group name)
# source_race_props <- sapply(r_groups,get_proportion,df=master_src,evaluate_column="src_race")
# source_age_props <- sapply(a_groups,get_proportion,df=master_src,evaluate_column="src_age_grp")
# source_gen_props <- sapply(g_groups,get_proportion,df=master_src,evaluate_column="src_gender")
# source_race_counts <- sapply(r_groups,get_counts,df=master_src,evaluate_column="src_race")
# source_age_counts <- sapply(a_groups,get_counts,df=master_src,evaluate_column="src_age_grp")
# source_gen_counts <- sapply(g_groups,get_counts,df=master_src,evaluate_column="src_gender")

# #deepface prediction proportions
# DF_pred_race_props <- sapply(r_groups,get_proportion,df=DF_results,evaluate_column="pred_race")
# DF_pred_age_props <- sapply(a_groups,get_proportion,df=DF_results,evaluate_column="pred_age_grp")
# DF_pred_gen_props <-sapply(g_groups,get_proportion,df=DF_results,evaluate_column="pred_gender")
# DF_pred_race_counts <- sapply(r_groups,get_counts,df=DF_results,evaluate_column="pred_race")
# DF_pred_age_counts <- sapply(a_groups,get_counts,df=DF_results,evaluate_column="pred_age_grp")
# DF_pred_gen_counts <- sapply(g_groups,get_counts,df=DF_results,evaluate_column="pred_gender")

# #fairface prediction proportions
# FF_pred_race_props <- sapply(r_groups,get_proportion,df=FF_results,evaluate_column="pred_race")
# FF_pred_age_props <-sapply(a_groups,get_proportion,df=FF_results,evaluate_column="pred_age_grp")
# FF_pred_gen_props <-sapply(g_groups,get_proportion,df=FF_results,evaluate_column="pred_gender")
# FF_pred_race_counts <- sapply(r_groups,get_counts,df=FF_results,evaluate_column="pred_race")
# FF_pred_age_counts <- sapply(a_groups,get_counts,df=FF_results,evaluate_column="pred_age_grp")
# FF_pred_gen_counts <- sapply(g_groups,get_counts,df=FF_results,evaluate_column="pred_gender")

# n_DF <- count(DF_results%>%filter(!is.na(pred_gender))) %>% unlist() %>% unname()

# n_FF <- count(FF_results %>% filter(!is.na(pred_gender))) %>% unlist() %>% unname()

# prop_p_values <- function(group,src_prop,pred_prop,pred_n){

#   num <- (sqrt(pred_n[group])*(src_prop[group]-pred_prop[group]))
#   den <- (sqrt(pred_prop[group]*(1-pred_prop[group])))
#   test_stat <- abs(num/den)
#   pnorm(-test_stat) + (1 - pnorm(test_stat))
# }

# DF_race_p_values <- sapply(
#   r_groups,
#   prop_p_values,
#   src_prop=source_race_props,
#   pred_prop=DF_pred_race_props,
#   pred_n=DF_pred_race_counts
# )
# names(DF_race_p_values)<- str_c("p.",r_groups)

# FF_race_p_values <- sapply(
#   r_groups,
#   prop_p_values,
#   src_prop=source_race_props,
#   pred_prop=FF_pred_race_props,
#   pred_n=FF_pred_race_counts
# )
# names(FF_race_p_values)<- str_c("p.",r_groups)

# DF_gen_p_values <- sapply(
#   g_groups,
#   prop_p_values,
#   src_prop=source_gen_props,
#   pred_prop=DF_pred_gen_props,
#   pred_n=DF_pred_gen_counts
# )
# names(DF_gen_p_values)<- str_c("p.",g_groups)

# FF_gen_p_values <- sapply(
#   g_groups,
#   prop_p_values,
#   src_prop=source_gen_props,
#   pred_prop=FF_pred_gen_props,
#   pred_n=FF_pred_gen_counts
# )
# names(FF_gen_p_values)<- str_c("p.",g_groups)

# FF_age_p_values <- sapply(
#   a_groups,
#   prop_p_values,
#   src_prop=source_age_props,
#   pred_prop=FF_pred_age_props,
#   pred_n=FF_pred_age_counts
# )
# names(FF_age_p_values)<- str_c("p.",a_groups)

# DF_age_p_values <- sapply(
#   a_groups,
#   prop_p_values,
#   src_prop=source_age_props,
#   pred_prop=DF_pred_age_props,
#   pred_n=DF_pred_age_counts
# )
# names(DF_age_p_values)<- str_c("p.",a_groups)

# str_c("p.",a_groups)

#DF_race_p_values <- sapply(r_groups, prop_p_values, src_prop=source_race_props, pred_prop=DF_pred_race_props,pred_n=n_DF)
#FF_race_p_values <- sapply(r_groups, prop_p_values, src_prop=source_race_props, pred_prop=FF_pred_race_props,pred_n=n_FF)
#DF_age_p_values <- sapply(a_groups, prop_p_values, src_prop=source_age_props, pred_prop=DF_pred_age_props,pred_n=n_DF)
#DF_gender_p_values <- sapply(g_groups,prop_p_values, src_prop=source_gen_props, pred_prop=DF_pred_gen_props,pred_n=n_DF)
```

```{r}
#get_proportion_subset <- function(df,filter_column,filter_value,evaluate_column,evaluate_value){
#sapply(r_groups,get_proportion_a_given_b,filter_column="",filter_value="",evaluate_column="")

#sapply(r_groups, prop_p_values, src_prop=source_race_props, pred_prop=DF_pred_race_props,pred_n=DF_pred_race_counts)

```

```{r}
# test <- function(df,src_col,pred_col,val){
#   y <- df %>% select(!!as.symbol(pred_col))
#   x <- df %>% select(!!as.symbol(src_col))
#   c(x,y)
# }

# test1 <- function(df,tuple){
#   print(tuple)
# }

# iter <- t(data.frame(
#   src_col = c(
#     replicate(length(r_groups),"src_race"),
#     replicate(length(a_groups),"src_age_grp"),
#     replicate(length(g_groups),"src_gender")
#   ),
#   pred_col = c(
#     replicate(length(r_groups),"pred_race"),
#     replicate(length(a_groups),"pred_age_grp"),
#     replicate(length(g_groups),"pred_gender")
#   ),
#   val = c(
#     r_groups,
#     a_groups,
#     g_groups
#   )
# ))

# lapply(iter,print)
# sapply(iter,test1,df=master_df)
```

```{r}
# knitr::kable(FF_gen_p_values)

# knitr::kable(DF_gen_p_values)
```

```{r}
# knitr::kable(FF_race_p_values)

# knitr::kable(DF_race_p_values)

# $$
# \frac{\sqrt{n_M}\cdot(\bar{p}_M-p_S)}{\sqrt{p_S\cdot(1-P_S)}}
# $$
```

```{r}
# source_gen_props['Female']

# source_race_props['Asian']

# source_race_props
# FF_pred_race_props
# DF_pred_race_props

# source_gen_props
# FF_pred_gen_props
# DF_pred_gen_props
```
