# Conclusions {#sec-conclusions}

```{r setup, include=FALSE}
#| include: false

library(tidyverse)
```

::: callout-note
## From the report requirements

-   Summarize what the paper has done, and discuss the implications of your Results.

-   Explicitly connect the results to the research question.

-   Discuss how you would you extend this research

Like the introduction, this section should be written with a **non-expert** in mind. A person should be able to read Introduction+Conclusion and get a rough idea of the meaning and significance of your paper
:::

## Evaluation of Test Results

To evaluate our tests, we will first examine our hypothesis tests, and then move on to evaluate F1 and Accuracy scores.  Our hypothesis testing can tell us where bias may exist, whereas F1 and Accuracy scores may tell us specific instances where bias exists in favor of, or against, specific protected classes.

## Hypothesis Testing Results

The design of our hypothesis testing provides us with potential indicators of bias in each model.  When the test result produces a value less than 0.003 and with test power greater than or equal to 0.8, the test can be indicative of bias.  Inversely, a p-value greater than or equal to 0.003 will not provide sufficient evidence to indicate bias in the given test case.  The p-value alone, however, cannot tell us whether the indicated bias is in favor of, or against, the protected class group(s) in question. This is because the the hypothesis tests only tell us the probability that the source and predicted results come from the same population.

Overall, for both models, our tests may are indicative of bias across the spectrum of age, gender, and race.  Common threads between both FairFace and DeepFace include bias in predicting: 

* Subject age (for specific groups)

* Subject race (for specific groups)

### Age Prediction

#### FairFace
FairFace displays potential for bias in age prediciton with subjects in the age ranges 0-29, 40-49, and 70+.  The age group 50-59 may also be included in this bias, but we do not have conclusive evidence from our tests alone to indicate such a bias.

For age proportions, given gender, potential biases manifest solely for Females in age ranges 0-19, solely for Males 40-49, and all subjects 70+.  Additional biases arise for any subject from 20-29.  

For age proportions, given race, potential biases are most prominent in the "" Category.

#### DeepFace
DeepFace displays extreme potential for bias in age prediction for young subjects (0-19) and old subjects (70+), failing to make a single prediction in any of these age ranges.

For age proportions, given gender, the biases are accentuated to all age ranges.

### Race Prediction

#### FairFace

FairFace demonstrates biases in predicting race for Black, Indian, White, and Other categories.

#### DeepFace

DeepFace demonstrates biases in predicting 

### Gender Prediction

#### FairFace

We lack sufficient information to conclude that FairFace, absent other test conditions, holds a bias in correct prediction of subject gender.

#### DeepFace

DeepFace, abasent other test conditions, indicates bias in correct prediction of gender.

## Identifying Specific Biases with F1 and Accuracy Scores

--- GC & LN --- 
When examining the results of the f1 tests for age, no categories for DeepFace passed an f1 score of 0.9. This implies a lack of performance on the part of DeepFace. As DeepFace is unable to detect faces between the ages of 0-9 and 70-130, there is a bias against very young and very old faces. Additionally, The group with the highest f1 performance is 20-29, implying a favorable bias towards adults, but not older adults. 

	FairFace’s overall data, without input for race or gender, failed to produce any category that passed the f1 threshold of 0.9. This implies an overall lack of correct predictions for any one age group. However, the categories that did perform the best had a preferential bias towards the very young and very old faces, almost in opposition to DeepFace. The overall data for FairFace held a positive bias towards the ages of 0-9 and 70-130. When looking at specific categories, FairFace had a notable bias to identify male faces between the ages of 0-2 in the White, Asian, and Other categories, as only those categories passed the f1 threshold of 0.9. 

	Race performs significantly worse for both DeepFace and FairFace, due to the fact that no overall category reaches above the 0.9 f1 cutoff for significance. Both models show preference for certain races. DeepFace shows a preferential bias for classifying White, Black, and Asian faces, and FairFace shows a similar bias for classifying Asian, Black and White faces, in that order. Indian and Other faces perform the worst overall for both models. Their f1 scores were significantly lower than the other three categories, by at least 0.2 for FairFace and 0.3 for DeepFace.

	In terms of more specific preferences, DeepFace performs exceedingly poorly overall. No category for race given age scores over 0.9 for the f1 score. And overall, White faces score the highest, provided the identified faces are not 0-9. For FairFace, the only noted bias was a preference for Asian faces younger than 20, and White faces in the ranges of 0-9 and 60-130. For gender-specific biases, there are also no categories that score over 0.9, but it should be emphasized that DeepFace identified female faces for all races better than male faces. FairFace had a similar performance, except for Indian faces, where male faces scored above female ones.

	Gender shows a similar pattern as race for overall evaluation. DeepFace fails to have any category pass the 0.9 f1 barrier, but male faces do show a slightly higher score than female ones. FairFace had both male and female faces score above 0.9, showing a notably positive performance, with little to no difference between males and females. 

	DeepFace did show preference for certain genders given age, with the range of 30-69 performing above 0.9 for male faces, but only females age 20-29 were significant. This implies a positive bias towards identifying older male faces, as well as bias towards younger adult women. FairFace was more balanced, with significant scores for most age groups except for females age 0-2, and males 0-9. This showcases a negative bias against very young people in general, and particularly male children. For Gender given race, DeepFace had no statistically significant f1 scores, but did show a positive bias towards White faces, and negative biases towards Asian faces of all genders, and Black female faces. FairFace was far better in all categories, with f1 scores over 0.9 for all categories except Asian male faces. Therefore, it shows a significant negative bias against identifying Asian male faces.
--- GC & LN ---


<!----- GC --->
## Age Prediction Conclusions 

Based on the results of evaluating both models for age prediction accuracy, given age, gender, or no particular category, there is a definite bias in both models towards differing demographics. Overall, DeepFace displayed a significantly lower accuracy rate in classifying the ages of given faces and was unable to produce predictions for faces between the ages of 0-9 and 70-130, indicating that it is unable to predict younger and older faces. However, it did display consistent test scores to evaluate the accuracy and efficacy of its results, indicating that the null hypothesis should be rejected here. FairFace, on the other hand, showed higher accuracy results, especially in Figure 4.1.b, where the only age bracket which DeepFace performed better for was 30-39. There is the possibility that a testing error resulted from our efforts with FairFace, but it is unlikely for the overall results. Things get more complicated when we include gender and/or race as given statistics for evaluating age. While DeepFace was consistent with gender overall, its results for race given no other variables were less accurate. There were noticeable discrepancies in identifying non-white faces, particularly Indian, Black, and Other faces. When specified for race and gender together, a trend of male faces being identified more accurately was observed, particularly white and Asian faces. For FairFace, there was still a higher accuracy rate of identification, but error test scores were higher overall. While DeepFace struggled to identify very young and old faces, FairFace generally struggled with faces in the range of 20-69. While the actual results show a higher rate of identification for all faces, FairFace has higher error test rates for nearly all races, save white faces. FairFace also mirrors DeepFace in a trend of lower error scores for lighter faces, although FairFace seems to have more of a bias towards female faces instead of male ones.
	Using the above results, as well as the tables from earlier, we can conclude that there is bias present in both the FairFace and DeepFace models when predicting age given gender or race. There is a definite trend towards white faces in both models in terms of predictive accuracy. That being said, based on the accuracy scores of FairFace, it is more likely that FairFace is less biased than DeepFace, especially given that DeepFace is unable to predict the ages of very young and very old faces with any degree of accuracy. That being said, the high error scores (p-values and power scores) indicate that perhaps FairFace requires further testing, in case the tests we created are wrong, and we should not reject the null hypothesis. Given the nature of the results, combined with the test scores, it is difficult to say whether or not one model completely outperforms the other. DeepFace is technically more accurate and less prone to rejection errors, but FairFace produces better results, even though it is less accurate over a wide age range. Overall, FairFace does seem to be the better predictor, given its accuracy rating and better age range, as it includes younger and older faces far better than DeepFace. In terms of disparate outcomes, both FairFace and DeepFace are more likely to correctly predict the race of white or Asian faces, while races with typically darker skin tones, Black, Indian, or Other, have far lower accuracy ratings across the board. 
	In terms of what should be done in future research, further testing is required. It would be ideal to cross-reference either the models, the testing data, or both, with other predictive models and datasets to determine if any possible errors are present due to the match. The ideal goal would be to minimize any potential error scores while evaluating a multitude of models and using the results to craft better predictive models that display less disparity due to age. In the future, datasets should strive to account for a diverse range of faces from all possible races, genders, and ages.
	
<!--- GC --->


<!-- --- LN --- -->

## Race Prediction Conclusions

### Race by itself

Both FairFace and DeepFace demonstrate potential racial bias. We filter the data across five races (Asian, Black, Indian, White, and Other) and perform statistical hypothesis testing. From the test results, there presents strong evidence suggesting potential bias for all tests but one, the FairFace's Asian test. Upon reviewing the result data, it is highly possible that there is an error in the testing. Therefore, we cannot draw a solid conclusion for this particular test. There are multiple reasons which might lead to errors such as too small sample size. Further investigation and testing will be necessary to re-evaluate FairFace's Asian test.

(Note: CK and PC mentioned that they will ask the professor about the usage of power. So there might be some adjustment to the section above.)

Next, we examine the models' performance in how often they make correct predictions and not give out wrong positive outputs. Surprisingly, our results go against the trend that facial recognition models offer a poorer performance for dark-skinned faces compared to light skin. Both models perform the best with Asian face images. Black comes in second and then White with a slightly less performance score. Nonetheless, Indian and Other receive substantially less accurate predictions. In regards to race, a better prediction model is FairFace with a higher performance score across the board.


### Race given Age

In most tests, FairFace and DeepFace showcase a strong potential for bias in the context of race and age group. In some cases that the tests do not imply potential bias, there presents a hypothesis testing error. This prevents us from reaching the conclusion that the models have mitigated bias. In regards to models' performance, FairFace offers a higher score for all age groups of all races. For both models, Asian, Black, and White receive similar high test scores. Whereas, scores for Indian and Other are noticeably lower.

Using FairFace, not a single test across all combinations of race and age group has shown to alleviate bias. In addition, there are numerous tests with error output. For each race, there are up to 3 testing errors with the exception of the Asian dataset. Beside the age range of 30 - 39, errors are present in all other Asian age groups. Among the errors, there does not appear to be a pattern in which age group occurs the most error.

Its counterpart, DeepFace, also does not offer a better test result as most tests still signify potential bias. There are only two instances in which the model has successfully mitigated bias. Those are Indian and Black in the age range of 60 - 69. Furthermore, DeepFace is simply unable to predict face images that are younger than 9 years old and older than 70 years old. This proves that DeepFace is strongly biased against young and old people across all races.


### Race given Gender

With the context of race and gender, both FairFace and DeepFace also exhibit a high potential for bias. Among all tests, there are only four cases which might not showcase bias. Nevertheless, those results follow a common pattern of having hypothesis testing errors. Similarly, both models' performance go hand-in-hand with the pattern of higher scores for Asian, Black, and White and lower for Indian and Other.

With FairFace, most tests indicate a bias potential. There are three cases which come with errors. Those are White and Asian females and Asian male. As for DeepFace, there is only one error case which is Black male. In terms of performance, there is no discrepancy between male and female for any races for both models. Hence, there does not seem to be a commonly-believed pattern of bias against females.


### Verdict

FairFace and DeepFace display potential racial bias. Despite that, our test result goes against the widely believed notion that models are discriminatory towards darker-skinned faces and females. We found that Indian and Other always score the lowest in regards to both models' performance. There also does not appear to be a difference in performance for both genders. Nevertheless, there is solid evidence that DeepFace is biased against those who are very young and very old.

Overall, there are a significant number of errors in this study. This is quite detrimental to our finding as we can not draw a firm conclusion from those tests. Further study or change of methodology might be essential to reduce those errors. This would allow us to arrive at a stronger conclusion.

<!--- LN --->
<!----- DV --->
## Gender Prediction Conclusions 

###Gender by itself

When examining gender classification in isolation, a clear disparity emerges between DeepFace and FairFace. This distinction becomes evident when scrutinizing key metrics such as the p-value, statistical power, and F1 score. Our chosen threshold for the face model's acceptability necessitates a p-value below 0.003, a power exceeding 0.8, and an F1 score surpassing 0.9.

Remarkably, FairFace consistently meets these stringent criteria, showcasing its robust performance. This conclusion is not only supported by numerical metrics but is also visually reinforced through meticulously crafted graphs. The juxtaposition of the actual model and the UTK Face dataset reveals an almost complete overlap, affirming the reliability of FairFace.

Conversely, DeepFace falls short of these benchmarks. A closer examination of the statistical measures exposes a significant deviation. The p-value, power, and F1 score collectively fail to meet the established thresholds, signifying a subpar performance. This inadequacy is further illustrated through visual representations, where the plots exhibit only a partial overlap with the UTK Face dataset.

###Gender given Age

When examining gender classification across different age groups, a shared challenge becomes apparent for both models: the struggle to accurately detect toddlers in the 0 to 2 age bin. However, a stark contrast emerges when we closely analyze DeepFace's performance within specific age cohorts. Notably, DeepFace encounters difficulties not only in identifying the youngest individuals (0 to 2 years) but also in recognizing those in the age groups of 3 to 9 and 70 to 130. It's worth emphasizing that DeepFace consistently falls short of meeting the established threshold criteria across all these age brackets.

An intriguing observation arises when considering the instances where DeepFace fails to meet the threshold criteria—most of these instances involve females. This hints at a potential bias of underperformance towards females in the DeepFace model, raising important questions about the model's robustness and inclusivity. On the other hand, the performance of FairFace stands out as consistently strong and well-distributed between males and females. Notably, FairFace does not exhibit any prominent bias, offering reliable results across gender categories and age groups. This conclusion is substantiated not only through numerical calculations but also by insightful visualizations.

A compelling aspect is revealed when examining the graphs comparing FairFace to the UTK Face distributions. In stark contrast to FairFace, DeepFace shows minimal overlap in these plots, with the most significant disparity occurring in the age bins of 40 to 49 and 50 to 59. This visual representation accentuates the challenges DeepFace encounters, particularly in these age ranges. Conversely, the graphs comparing FairFace to UTK Face distributions tell a different story. While there is a slight underperformance in the age group of 70 to 130, the overall graphs showcase nearly complete overlap. This suggests superior performance by FairFace, reinforcing its effectiveness across various age groups.

###Gender given Race

When examining gender in relation to race, a striking initial observation is that most permutations for DeepFace do not align with the established thresholds for P-value, power, and F1 score.

However, a nuanced perspective emerges when scrutinizing both DeepFace and FairFace, revealing shared struggles in accurately classifying the "other" race. Notably, DeepFace exhibits suboptimal performance with the "black" race, hinting at potential bias.

A deeper dive into the graph distributions for the models against the UTK face dataset unveils distinctive patterns. DeepFace demonstrates minimal overlap in most graphs, with the highest convergence observed for the "white" race. In contrast, FairFace showcases substantial overlap, particularly with the "Asian" and "white" races.

Upon considering both numerical values and graphical representations, an additional noteworthy observation surfaces: females exhibit a slightly lower F1 score than males, potentially indicating bias in both models. Furthermore, there appears to be a trend of better performance towards the "white" race in both models, raising questions about potential biases in these gender and race classifications.

###verdict

While both models exhibit a bias towards females, DeepFace displays a more substantial inclination compared to FairFace. This bias is evident in instances where our calculations indicate a failure to reject the null hypothesis, particularly more frequently in DeepFace. Despite this, FairFace outshines DeepFace in overall performance, excelling in both gender given the age and gender given the race scenarios. Additionally, a discernible trend suggests a potential bias towards the white race in both models, with this tendency being more pronounced in DeepFace. These insights underscore the need for ongoing scrutiny and refinement to address biases and enhance the inclusivity of these models.
<!--- DV --->