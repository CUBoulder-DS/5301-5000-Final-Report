# Conclusions {#sec-conclusions}

```{r setup, include=FALSE}
#| include: false

library(tidyverse)
```

::: callout-note
## From the report requirements

-   Summarize what the paper has done, and discuss the implications of your Results.

-   Explicitly connect the results to the research question.

-   Discuss how you would you extend this research

Like the introduction, this section should be written with a **non-expert** in mind. A person should be able to read Introduction+Conclusion and get a rough idea of the meaning and significance of your paper
:::

## Evaluation of Test Results

To evaluate our tests, we will first examine our hypothesis tests, and then move on to evaluate F1 and Accuracy scores.  Our hypothesis testing can tell us where bias may exist, whereas F1 and Accuracy scores may tell us specific instances where bias exists in favor of, or against, specific protected classes.

## Hypothesis Testing Results

The design of our hypothesis testing provides us with potential indicators of bias in each model.  When the test result produces a value less than 0.003 and with test power greater than or equal to 0.8, the test can be indicative of bias.  Inversely, a p-value greater than or equal to 0.003 will not provide sufficient evidence to indicate bias in the given test case.  The p-value alone, however, cannot tell us whether the indicated bias is in favor of, or against, the protected class group(s) in question. This is because the the hypothesis tests only tell us the probability that the source and predicted results come from the same population.

Overall, for both models, our tests may are indicative of bias across the spectrum of age, gender, and race.  Common threads between both FairFace and DeepFace include bias in predicting: 

* Subject age (for specific groups)

* Subject race (for specific groups)

### Age Prediction

#### FairFace
FairFace displays potential for bias in age prediciton with subjects in the age ranges 0-29, 40-49, and 70+.  The age group 50-59 may also be included in this bias, but we do not have conclusive evidence from our tests alone to indicate such a bias.

For age proportions, given gender, potential biases manifest solely for Females in age ranges 0-19, solely for Males 40-49, and all subjects 70+.  Additional biases arise for any subject from 20-29.  

For age proportions, given race, potential biases are most prominent in the "" Category.

#### DeepFace
DeepFace displays extreme potential for bias in age prediction for young subjects (0-19) and old subjects (70+), failing to make a single prediction in any of these age ranges.

For age proportions, given gender, the biases are accentuated to all age ranges.

### Race Prediction

#### FairFace

FairFace demonstrates biases in predicting race for Black, Indian, White, and Other categories.

#### DeepFace

DeepFace demonstrates biases in predicting 

### Gender Prediction

#### FairFace

We lack sufficient information to conclude that FairFace, absent other test conditions, holds a bias in correct prediction of subject gender.

#### DeepFace

DeepFace, abasent other test conditions, indicates bias in correct prediction of gender.

## Identifying Specific Biases with F1 and Accuracy Scores

### FairFace

### DeepFace

## Summary


<!----- GC --->
## Age Prediction Conclusions 

Based on the results of evaluating both models for age prediction accuracy, given age, gender, or no particular category, there is a definite bias in both models towards differing demographics. Overall, DeepFace displayed a significantly lower accuracy rate in classifying the ages of given faces and was unable to produce predictions for faces between the ages of 0-9 and 70-130, indicating that it is unable to predict younger and older faces. However, it did display consistent test scores to evaluate the accuracy and efficacy of its results, indicating that the null hypothesis should be rejected here. FairFace, on the other hand, showed higher accuracy results, especially in Figure 4.1.b, where the only age bracket which DeepFace performed better for was 30-39. There is the possibility that a testing error resulted from our efforts with FairFace, but it is unlikely for the overall results. Things get more complicated when we include gender and/or race as given statistics for evaluating age. While DeepFace was consistent with gender overall, its results for race given no other variables were less accurate. There were noticeable discrepancies in identifying non-white faces, particularly Indian, Black, and Other faces. When specified for race and gender together, a trend of male faces being identified more accurately was observed, particularly white and Asian faces. For FairFace, there was still a higher accuracy rate of identification, but error test scores were higher overall. While DeepFace struggled to identify very young and old faces, FairFace generally struggled with faces in the range of 20-69. While the actual results show a higher rate of identification for all faces, FairFace has higher error test rates for nearly all races, save white faces. FairFace also mirrors DeepFace in a trend of lower error scores for lighter faces, although FairFace seems to have more of a bias towards female faces instead of male ones.
	Using the above results, as well as the tables from earlier, we can conclude that there is bias present in both the FairFace and DeepFace models when predicting age given gender or race. There is a definite trend towards white faces in both models in terms of predictive accuracy. That being said, based on the accuracy scores of FairFace, it is more likely that FairFace is less biased than DeepFace, especially given that DeepFace is unable to predict the ages of very young and very old faces with any degree of accuracy. That being said, the high error scores (p-values and power scores) indicate that perhaps FairFace requires further testing, in case the tests we created are wrong, and we should not reject the null hypothesis. Given the nature of the results, combined with the test scores, it is difficult to say whether or not one model completely outperforms the other. DeepFace is technically more accurate and less prone to rejection errors, but FairFace produces better results, even though it is less accurate over a wide age range. Overall, FairFace does seem to be the better predictor, given its accuracy rating and better age range, as it includes younger and older faces far better than DeepFace. In terms of disparate outcomes, both FairFace and DeepFace are more likely to correctly predict the race of white or Asian faces, while races with typically darker skin tones, Black, Indian, or Other, have far lower accuracy ratings across the board. 
	In terms of what should be done in future research, further testing is required. It would be ideal to cross-reference either the models, the testing data, or both, with other predictive models and datasets to determine if any possible errors are present due to the match. The ideal goal would be to minimize any potential error scores while evaluating a multitude of models and using the results to craft better predictive models that display less disparity due to age. In the future, datasets should strive to account for a diverse range of faces from all possible races, genders, and ages.
	
<!--- GC --->


<!-- --- LN --- -->

## Race Prediction Conclusions

### Race by itself

Both FairFace and DeepFace demonstrate potential racial bias. We filter the data across five races (Asian, Black, Indian, White, and Other) and perform statistical hypothesis testing. From the test results, there presents strong evidence suggesting potential bias for all tests but one, the FairFace's Asian test. Upon reviewing the result data, it is highly possible that there is an error in the testing. Therefore, we cannot draw a solid conclusion for this particular test. There are multiple reasons which might lead to errors such as too small sample size. Further investigation and testing will be necessary to re-evaluate FairFace's Asian test.

(Note: CK and PC mentioned that they will ask the professor about the usage of power. So there might be some adjustment to the section above.)

Next, we examine the models' performance in how often they make correct predictions and not give out wrong positive outputs. Surprisingly, our results go against the trend that facial recognition models offer a poorer performance for dark-skinned faces compared to light skin. Both models perform the best with Asian face images. Black comes in second and then White with a slightly less performance score. Nonetheless, Indian and Other receive substantially less accurate predictions. In regards to race, a better prediction model is FairFace with a higher performance score across the board.


### Race given Age

In most tests, FairFace and DeepFace showcase a strong potential for bias in the context of race and age group. In some cases that the tests do not imply potential bias, there presents a hypothesis testing error. This prevents us from reaching the conclusion that the models have mitigated bias. In regards to models' performance, FairFace offers a higher score for all age groups of all races. For both models, Asian, Black, and White receive similar high test scores. Whereas, scores for Indian and Other are noticeably lower.

Using FairFace, not a single test across all combinations of race and age group has shown to alleviate bias. In addition, there are numerous tests with error output. For each race, there are up to 3 testing errors with the exception of the Asian dataset. Beside the age range of 30 - 39, errors are present in all other Asian age groups. Among the errors, there does not appear to be a pattern in which age group occurs the most error.

Its counterpart, DeepFace, also does not offer a better test result as most tests still signify potential bias. There are only two instances in which the model has successfully mitigated bias. Those are Indian and Black in the age range of 60 - 69. Furthermore, DeepFace is simply unable to predict face images that are younger than 9 years old and older than 70 years old. This proves that DeepFace is strongly biased against young and old people across all races.


### Race given Gender

With the context of race and gender, both FairFace and DeepFace also exhibit a high potential for bias. Among all tests, there are only four cases which might not showcase bias. Nevertheless, those results follow a common pattern of having hypothesis testing errors. Similarly, both models' performance go hand-in-hand with the pattern of higher scores for Asian, Black, and White and lower for Indian and Other.

With FairFace, most tests indicate a bias potential. There are three cases which come with errors. Those are White and Asian females and Asian male. As for DeepFace, there is only one error case which is Black male. In terms of performance, there is no discrepancy between male and female for any races for both models. Hence, there does not seem to be a commonly-believed pattern of bias against females.


### Verdict

FairFace and DeepFace display potential racial bias. Despite that, our test result goes against the widely believed notion that models are discriminatory towards darker-skinned faces and females. We found that Indian and Other always score the lowest in regards to both models' performance. There also does not appear to be a difference in performance for both genders. Nevertheless, there is solid evidence that DeepFace is biased against those who are very young and very old.

Overall, there are a significant number of errors in this study. This is quite detrimental to our finding as we can not draw a firm conclusion from those tests. Further study or change of methodology might be essential to reduce those errors. This would allow us to arrive at a stronger conclusion.

<!--- LN --->
