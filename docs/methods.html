<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Bias in Facial Classification ML Models - 3&nbsp; Methods</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./results.html" rel="next">
<link href="./data.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Bias in Facial Classification ML Models</span>
    </a>
  </div>
        <div class="quarto-navbar-tools ms-auto">
    <a href="https://github.com/CUBoulder-DS/5301-5000-Final-Report" rel="" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <a href="./STAT_5000_Final_Report.pdf" rel="" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./methods.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Methods</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Abstract</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./methods.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./results.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Results</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conclusions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Conclusions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-big-picture" id="toc-the-big-picture" class="nav-link active" data-scroll-target="#the-big-picture"><span class="header-section-number">3.1</span> The Big Picture</a></li>
  <li><a href="#measuring-performance" id="toc-measuring-performance" class="nav-link" data-scroll-target="#measuring-performance"><span class="header-section-number">3.2</span> Measuring Performance</a>
  <ul class="collapse">
  <li><a href="#accuracy" id="toc-accuracy" class="nav-link" data-scroll-target="#accuracy"><span class="header-section-number">3.2.1</span> Accuracy</a></li>
  <li><a href="#precision" id="toc-precision" class="nav-link" data-scroll-target="#precision"><span class="header-section-number">3.2.2</span> Precision</a></li>
  <li><a href="#recall" id="toc-recall" class="nav-link" data-scroll-target="#recall"><span class="header-section-number">3.2.3</span> Recall</a></li>
  <li><a href="#f1-score" id="toc-f1-score" class="nav-link" data-scroll-target="#f1-score"><span class="header-section-number">3.2.4</span> F1-Score</a></li>
  </ul></li>
  <li><a href="#hypothesis-testing" id="toc-hypothesis-testing" class="nav-link" data-scroll-target="#hypothesis-testing"><span class="header-section-number">3.3</span> Hypothesis Testing</a>
  <ul class="collapse">
  <li><a href="#demographics" id="toc-demographics" class="nav-link" data-scroll-target="#demographics"><span class="header-section-number">3.3.1</span> Demographics</a></li>
  <li><a href="#demographics-subgroups" id="toc-demographics-subgroups" class="nav-link" data-scroll-target="#demographics-subgroups"><span class="header-section-number">3.3.2</span> Demographics’ Subgroups</a></li>
  <li><a href="#the-general-proportion-tests" id="toc-the-general-proportion-tests" class="nav-link" data-scroll-target="#the-general-proportion-tests"><span class="header-section-number">3.3.3</span> The General Proportion Tests</a></li>
  <li><a href="#notation" id="toc-notation" class="nav-link" data-scroll-target="#notation"><span class="header-section-number">3.3.4</span> Notation</a></li>
  <li><a href="#more-specific-proportion-tests" id="toc-more-specific-proportion-tests" class="nav-link" data-scroll-target="#more-specific-proportion-tests"><span class="header-section-number">3.3.5</span> More Specific Proportion Tests</a></li>
  </ul></li>
  <li><a href="#standardizing-output" id="toc-standardizing-output" class="nav-link" data-scroll-target="#standardizing-output"><span class="header-section-number">3.4</span> Standardizing output</a>
  <ul class="collapse">
  <li><a href="#from-fairface" id="toc-from-fairface" class="nav-link" data-scroll-target="#from-fairface"><span class="header-section-number">3.4.1</span> From FairFace</a></li>
  <li><a href="#from-deepface" id="toc-from-deepface" class="nav-link" data-scroll-target="#from-deepface"><span class="header-section-number">3.4.2</span> From DeepFace</a></li>
  </ul></li>
  <li><a href="#evaluating-permutations-of-inputs-and-models-for-equitable-evaluation" id="toc-evaluating-permutations-of-inputs-and-models-for-equitable-evaluation" class="nav-link" data-scroll-target="#evaluating-permutations-of-inputs-and-models-for-equitable-evaluation"><span class="header-section-number">3.5</span> Evaluating Permutations of Inputs and Models for Equitable Evaluation</a>
  <ul class="collapse">
  <li><a href="#deepface-analysis-options" id="toc-deepface-analysis-options" class="nav-link" data-scroll-target="#deepface-analysis-options"><span class="header-section-number">3.5.1</span> DeepFace Analysis Options</a></li>
  <li><a href="#fairface-analysis-options" id="toc-fairface-analysis-options" class="nav-link" data-scroll-target="#fairface-analysis-options"><span class="header-section-number">3.5.2</span> FairFace Analysis Options</a></li>
  <li><a href="#specific-permutations" id="toc-specific-permutations" class="nav-link" data-scroll-target="#specific-permutations"><span class="header-section-number">3.5.3</span> Specific Permutations</a></li>
  <li><a href="#permutation-sample-results-ln-dv" id="toc-permutation-sample-results-ln-dv" class="nav-link" data-scroll-target="#permutation-sample-results-ln-dv"><span class="header-section-number">3.5.4</span> Permutation Sample Results (LN &amp; DV)</a></li>
  <li><a href="#setting-selection" id="toc-setting-selection" class="nav-link" data-scroll-target="#setting-selection"><span class="header-section-number">3.5.5</span> Setting Selection</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Methods</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<!-- BJ !-->
<!-- CK !-->
<p><span class="citation" data-cites="fairface">Karkkainen and Joo (<a href="references.html#ref-fairface" role="doc-biblioref">2021</a>)</span></p>
<section id="the-big-picture" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="the-big-picture"><span class="header-section-number">3.1</span> The Big Picture</h2>
<ul>
<li>Is bias prevalent in facial recognition machine learning models?</li>
<li>Can one model be shown to have statistically significant less bias than the other?</li>
<li>Does one model outperform the other in a statistically significant manner, in all aspects?</li>
<li>Does one model outperform the other in a statistically significant manner, in certain aspects?
<ul>
<li>This is where we can dive into “conventional” bias</li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Thoughts on Bias
</div>
</div>
<div class="callout-body-container callout-body">
<p>We need to be careful how we define and use bias. Statistical bias is essentially error, and we could be crossing our definitions between statistical bias and conventional bias.</p>
</div>
</div>
</section>
<section id="measuring-performance" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="measuring-performance"><span class="header-section-number">3.2</span> Measuring Performance</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This performance section is important in choosing the correct models to ensure data integrity, however for the actual statistical tests, we’ll focused on more common statistics like mean and proportion.</p>
</div>
</div>
<p>There are four main measures of performance when evaluating a model:</p>
<ul>
<li><strong>Accuracy</strong></li>
<li><strong>Precision</strong></li>
<li><strong>Recall</strong></li>
<li><strong>F1-Score</strong></li>
</ul>
<p>Each of these performance measures has their own place in evaluating models, however, to begin to explain the differences between these models we should start with concepts of positive and negative outcomes.</p>
<ul>
<li><strong>True Positive:</strong> predicted positive, was actually positive (correct)</li>
<li><strong>False Positive:</strong> predicted positive, was actually negative (incorrect)</li>
<li><strong>True Negative:</strong> predicted negative, was actually negative (correct)</li>
<li><strong>False Negative:</strong> predicted negative, was actually positive (incorrect)</li>
</ul>
<p>These outcomes can be visualized on a confusion matrix. In the image below, green are correct predictions while red are incorrect predictions.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/confusion_matrix.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">confusion_matrix</figcaption>
</figure>
</div>
<section id="accuracy" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="accuracy"><span class="header-section-number">3.2.1</span> Accuracy</h3>
<p><strong>Accuracy</strong> is the ratio of correct predictions to all predictions. In other words, the total of the green squares divided by the entire matrix. This is arguably the most common concept of measuring performance.</p>
<p><span class="math inline">\(Acccuracy = \frac{TP+TN}{TP + TN + FN}\)</span></p>
</section>
<section id="precision" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="precision"><span class="header-section-number">3.2.2</span> Precision</h3>
<p><strong>Precision</strong> is the ratio of true positives to the total number of positives (true positive + true negative).</p>
<p><span class="math inline">\(Precision = \frac{TP}{TP+FP}\)</span></p>
</section>
<section id="recall" class="level3" data-number="3.2.3">
<h3 data-number="3.2.3" class="anchored" data-anchor-id="recall"><span class="header-section-number">3.2.3</span> Recall</h3>
<p><strong>Recall</strong> is the ratio of true positives to the number of total correct predictions (true positive + false negative).</p>
<p><span class="math inline">\(Recall = \frac{TP}{TP+FN}\)</span></p>
</section>
<section id="f1-score" class="level3" data-number="3.2.4">
<h3 data-number="3.2.4" class="anchored" data-anchor-id="f1-score"><span class="header-section-number">3.2.4</span> F1-Score</h3>
<p><strong>F1-Score</strong>* is known as the harmonic mean between precision and recall. <strong>Precision</strong> and <strong>Recall</strong> are useful in their own rights, but the f1-Score is useful in the fact it’s a balanced combination of both precision and recall.</p>
<p>F1-Score <span class="math inline">\(= \frac{2 * Precision * Recall}{Precision + Recall}\)</span></p>
</section>
</section>
<section id="hypothesis-testing" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="hypothesis-testing"><span class="header-section-number">3.3</span> Hypothesis Testing</h2>
<p>Our data consists of three main sets, the source input data, the Fairface output data, and the Deepface output data.</p>
<p>We’ll be creating our hypothesis tests by treating the source data as the basis for the original assumptions (our <em>null hypotheses</em>), and then using the output from Fairface and Deepface to test for statistically significant differences. Gaining a statistically significant result would allow us to reject our <em>null hypothesis</em> in favor of the <em>alternative hypothesis</em>. In other words, rejecting the original assumption means there is a statistically large enough difference between the source data and output data, and could indicate a bias in model.</p>
<p>We’ll be testing across different subsets contained within the data, as listed below:</p>
<section id="demographics" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="demographics"><span class="header-section-number">3.3.1</span> Demographics</h3>
<ul>
<li>Age Group</li>
<li>Gender</li>
<li>Race</li>
</ul>
</section>
<section id="demographics-subgroups" class="level3" data-number="3.3.2">
<h3 data-number="3.3.2" class="anchored" data-anchor-id="demographics-subgroups"><span class="header-section-number">3.3.2</span> Demographics’ Subgroups</h3>
<ul>
<li>Age Group (9 groups)
<ul>
<li>0-2</li>
<li>3-9</li>
<li>10-19</li>
<li>20-29</li>
<li>30-39</li>
<li>40-49</li>
<li>50-59</li>
<li>60-69</li>
<li>70-130</li>
</ul></li>
<li>Gender (2 groups)
<ul>
<li>Female</li>
<li>Male</li>
</ul></li>
<li>Race (5 groups)
<ul>
<li>Asian</li>
<li>Black</li>
<li>Indian</li>
<li>Other</li>
<li>White</li>
</ul></li>
</ul>
</section>
<section id="the-general-proportion-tests" class="level3" data-number="3.3.3">
<h3 data-number="3.3.3" class="anchored" data-anchor-id="the-general-proportion-tests"><span class="header-section-number">3.3.3</span> The General Proportion Tests</h3>
<p>Our hypothesis tests will be testing different proportions within these subgroups between the source data and the output data.</p>
<p>The general format of our hypothesis tests will be:</p>
<p><span class="math inline">\(H_0: p = p_{\text{Source Data Subset}}\)</span></p>
<p><span class="math inline">\(H_A: p \neq p_{\text{Source Data Subset}}\)</span></p>
<p>With the following test statistic:</p>
<p><span class="math inline">\(\frac{\sqrt{n}(\hat{p} - p)}{\sqrt{p(1 - p)}}\)</span></p>
<p>With the p-value being calculated by:</p>
<p><span class="math inline">\(P(|Z| &gt; \hat{p} | H_0)\)</span></p>
<p><span class="math inline">\(= P(|Z| &gt; \frac{\sqrt{n}(\hat{p} - p)}{\sqrt{p(1 - p)}})\)</span>,</p>
<p>where</p>
<ul>
<li><span class="math inline">\(n\)</span>: output data subset size</li>
<li><span class="math inline">\(\hat{p}\)</span>: output data subset proportion</li>
<li><span class="math inline">\(p\)</span>: source data subset proportion</li>
</ul>
</section>
<section id="notation" class="level3" data-number="3.3.4">
<h3 data-number="3.3.4" class="anchored" data-anchor-id="notation"><span class="header-section-number">3.3.4</span> Notation</h3>
<p>Before we list the specific tests, we should introduce some notation.</p>
<p>Let <span class="math inline">\(R\)</span> be race, then <span class="math inline">\(R \in \{Asian, Black, Indian, Other, White\} = \{A, B, I, O, W\}\)</span></p>
<p>Let <span class="math inline">\(G\)</span> be gender, then <span class="math inline">\(G \in \{Female, Male\} = \{F, M\}\)</span></p>
<p>Let <span class="math inline">\(A\)</span> be age, then <span class="math inline">\(A \in \{[0,2], [3,9], [10,19], [20,29], [30,39], [40,49], [50,59], [60,69], [70,130]\} = \{1, 2, 3, 4, 5, 6, 7, 8, 9\}\)</span></p>
<p>Let <span class="math inline">\(D\)</span> be the dataset, then <span class="math inline">\(D \in \{Source, Fairface, Deepface\} = \{D_0, D_f, D_d\}\)</span></p>
</section>
<section id="more-specific-proportion-tests" class="level3" data-number="3.3.5">
<h3 data-number="3.3.5" class="anchored" data-anchor-id="more-specific-proportion-tests"><span class="header-section-number">3.3.5</span> More Specific Proportion Tests</h3>
<p>Using this notation, we can simplify our nomenclature for testing a certain proportion of an overall demographic.</p>
<p>For example, we can test if the proportion of <em>Female</em> in the Fairface output is statistically different than the proportion of <em>Female</em> from the source.</p>
<p>Hypothesis Test:</p>
<p><span class="math inline">\(H_0: p_F = p_{F|D_0}\)</span></p>
<p><span class="math inline">\(H_A: p_F \neq p_{F|D_0}\)</span></p>
<p>P-value Calculation:</p>
<p><span class="math inline">\(P(|Z| &gt; \frac{\sqrt{n}(\hat{p} - p)}{\sqrt{p(1 - p)}})\)</span>,</p>
<p>where</p>
<ul>
<li><span class="math inline">\(p = p_{F|D_0}\)</span>: proportion of females from the source data</li>
<li><span class="math inline">\(\hat{p} = p_{F|D_f}\)</span>: proportion of females from the fairface output</li>
<li><span class="math inline">\(n = n_{F \cup M|D_f}\)</span>: number of data points in the gender subset form the fairface output</li>
</ul>
<p>Additionally, we could test for different combinations of subsets within demographics. For instance, if we wanted to test for a statistically significant difference between the proportion of those who <em>Female</em>, given that they were <em>Black</em>, then we could write a hypothesis test like:</p>
<p><span class="math inline">\(H_0: p_{F|B} = p_{F|D_0 \cap B}\)</span></p>
<p><span class="math inline">\(H_A: p_{F|B} \neq p_{F|D_0 \cap B}\)</span></p>
<p>P-value Calculation:</p>
<p><span class="math inline">\(P(|Z| &gt; \frac{\sqrt{n}(\hat{p} - p)}{\sqrt{p(1 - p)}})\)</span>,</p>
<p>where</p>
<ul>
<li><span class="math inline">\(p = p_{F|D_0 \cap B}\)</span>: proportion of females from the source data, given they were black</li>
<li><span class="math inline">\(\hat{p} = p_{F|D_f \cap B}\)</span>: proportion of females from the fairface output, given they were black</li>
<li><span class="math inline">\(n = n_{F \cup M|D_f \cap B}\)</span>: number of data points in the gender subset form the fairface output, given they were black.</li>
</ul>
<p>These were two specific hypothesis tests, however, we’ll be testing many combinations of these parameters and reporting back on any significant findings.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
From the report requirements
</div>
</div>
<div class="callout-body-container callout-body">
<p>Also can be called “Analyses”</p>
<p>This section might contain several subsections as needed.</p>
<ul>
<li><p>At least one subsection should describe the exploratory data analysis you did.</p></li>
<li><p>What modifications were necessary to make the dataset ready for analysis? (e.g.&nbsp;dealing with missing values, removing certain rows, replacing/cleaning text values, binning, etc)</p></li>
<li><p>Describe the analyses you did to answer the question of interest. <strong>Explain why you believe these methods are appropriate.</strong></p></li>
<li><p>At least one subsection should describe the exploratory data analysis you did.</p></li>
<li><p>What modifications were necessary to make the dataset ready for analysis? (e.g.&nbsp;dealing with missing values, removing certain rows, replacing/cleaning text values, binning, etc)</p></li>
<li><p>Describe the analyses you did to answer the question of interest. <strong>Explain why you believe these methods are appropriate.</strong></p></li>
<li><p>At least one subsection should describe the exploratory data analysis you did.</p></li>
<li><p>What modifications were necessary to make the dataset ready for analysis? (e.g.&nbsp;dealing with missing values, removing certain rows, replacing/cleaning text values, binning, etc)</p></li>
<li><p>Describe the analyses you did to answer the question of interest. <strong>Explain why you believe these methods are appropriate.</strong></p></li>
</ul>
<p>Some methods we learn in this class include distribution comparison, correlation analysis, and hypothesis testing. You are required to include hypothesis tests into the project, but feel free to use additional methods to tell a good story about the data.</p>
</div>
</div>
</section>
</section>
<section id="standardizing-output" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="standardizing-output"><span class="header-section-number">3.4</span> Standardizing output</h2>
<p>The model outputs for both FairFace and DeepFace do not conform to the categories provided within the University of Tennessee - Knoxville (UTK) dataset. We elected to take the outputs from each model and modify them based upon the categories specified in the UTK dataset, namely:</p>
<ul>
<li><p>“[race] is an integer from 0 to 4, denoting White, Black, Asian, Indian, and Others (like Hispanic, Latino, Middle Eastern).”</p></li>
<li><p>“[gender] is either 0 (male) or 1 (female)”</p></li>
<li><p>“[age] is an integer from 0 to 116, indicating the age”</p></li>
</ul>
<section id="from-fairface" class="level3" data-number="3.4.1">
<h3 data-number="3.4.1" class="anchored" data-anchor-id="from-fairface"><span class="header-section-number">3.4.1</span> From FairFace</h3>
<ul>
<li><p><strong>Race</strong>: The FairFace classification model had two options - one for “fair7” and one for “fair4.” The latter provided predictions of race in the following categories: [White, Black, Asian, Indian]. Of key note, the model omitted “Other” categories as listed in the race category for the UTK dataset. However, the “fair7” model provides predictions across [White, Black, Latino_Hispanic, East Asian, Southeast Asian, Indian, Middle Eastern]. We elected to use the the fair7 model, and to refactor the output categories to match those of the UTK dataset. Namely, we refactored instances of Middle Eastern and Latino_Hispanic as “Other,” and instances of “East Asian” and “Southeast Asian” as “Asian”</p></li>
<li><p><strong>Age</strong>: FairFace only provides a predicted age range as opposed to a specific, single, predicted age as a string. To enable comparison of actual values to the predicted values, we maintained this column as a categorical variable, and split it into a lower and upper bound of predicted age as an integer. This split will allow us to determine whether or not the prediction correctly binned the age (i.e.&nbsp;<span class="math inline">\(lowerBound \leq actualAge \leq upperBound\)</span>), and if not - how far outside of those bounds the actual age lay.</p></li>
<li><p><strong>Gender</strong>: no change to outputs of “Male” and “Female.”</p></li>
</ul>
</section>
<section id="from-deepface" class="level3" data-number="3.4.2">
<h3 data-number="3.4.2" class="anchored" data-anchor-id="from-deepface"><span class="header-section-number">3.4.2</span> From DeepFace</h3>
<ul>
<li><p><strong>Race</strong>: Racial categorical output from DeepFace includes the following categories [“middle eastern”, “asian”, “white”, “latino hispanic”, “black”, “indian”]</p></li>
<li><p><strong>Age</strong>: DeepFace provides a prediction of a single, specific, predicted age. We elected to match the predicted age to be the same range as would be predicted by Fair Face. For example, if DeepFace predicts an age like “19,” we assign it the same matching category as it would have in FairFace - “10-19.” From there, we also split this category into an upper and lower bound. In spite of the fact that DeepFace does not provide any bounds or ranges on its age prediction outputs, to have a similar and fair comparison of both models, we give it those same upper and lower bounds for equitable comparison.</p></li>
<li><p><strong>Gender</strong>: DeepFace outputs are “Man” and “Woman”, and we refactor those values to “Male” and “Female” respectively.</p></li>
</ul>
</section>
</section>
<section id="evaluating-permutations-of-inputs-and-models-for-equitable-evaluation" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="evaluating-permutations-of-inputs-and-models-for-equitable-evaluation"><span class="header-section-number">3.5</span> Evaluating Permutations of Inputs and Models for Equitable Evaluation</h2>
<p>Aside from the differences in the outputs of each model in terms of age, race, and gender, there are also substantial differences between FairFace and DeepFace in terms of their available settings when attempting to categorize an image in each of these categories.</p>
<p>The need for this permutation evaluation rose from some initial scripting and testing of these models on a small sample of images from another facial dataset - the Asian Face Age Dataset (need citation here). We immediately grew concerned with DeepFace’s performance using default settings (namely, enforcing requirement to detect a face prior to categorization, and using OpenCV as the default detection backend). Running these initial scripting tests, we encountered a failure rate in DeepFace of approximately 70% in identifying and categorizing an image of a face.</p>
<p>We performed further exploratory analysis on both models in light of these facts, and sought some specific permutations of settings to determine what settings may provide the most fair and equitable comparison of the models prior to proceeding to further analysis.</p>
<section id="deepface-analysis-options" class="level3" data-number="3.5.1">
<h3 data-number="3.5.1" class="anchored" data-anchor-id="deepface-analysis-options"><span class="header-section-number">3.5.1</span> DeepFace Analysis Options</h3>
<p>DeepFace has a robust degree of avaialble settings when performing facial categorization and recognition. These include enforcing facial detection prior to classification of an image, as well as 8 different facial detection models to detect a face prior to categorization. The default of these settings is OpenCV detection with detection enabled. Other detection backends include ssd, dlib, mtcnn, retinaface, mediapipe, yolov8, yunet, and fastmtcnn.</p>
<p>In a Python 3.8 environment, attempting to run detections using dlib, retinaface, mediapipe, yolov8, and yunet failed to run, or failed to install the appropriate models directly from source during exeuction. Repairing any challenges or issues with the core functionality of DeepFace and FairFace’s code is outside the scope of our work, and as such, we have excluded any of these non-functioning models from our permutation evaluation.</p>
</section>
<section id="fairface-analysis-options" class="level3" data-number="3.5.2">
<h3 data-number="3.5.2" class="anchored" data-anchor-id="fairface-analysis-options"><span class="header-section-number">3.5.2</span> FairFace Analysis Options</h3>
<p>The default script from FairFace provided no options via its command line script to change settings. It uses dlib/resnet34 models for facial detection and image pre-processing, and uses its own fair4 and fair7 models for categorization. There are no other options or flags that can be set by a user when processing a batch of images.</p>
<p>We converted the simple script to a class in Python without addressing any feature bugs or errors in the underlying code. This change provided us some additional options when performing the analysis of an input image using FairFace - namely, the ability to analyze and categorize an image with or without facial detection, similar to the functionality of DeepFace. FairFace remains limited in the fact that is only detection model backend is built in dlib, but this change gives us more options when considering what type of images to use and what settings to use on both models before generating our final dataset for analysis.</p>
</section>
<section id="specific-permutations" class="level3" data-number="3.5.3">
<h3 data-number="3.5.3" class="anchored" data-anchor-id="specific-permutations"><span class="header-section-number">3.5.3</span> Specific Permutations</h3>
<p>With the above options in mind, we designed the following permutations for evaluation on a subset of the UTK dataset:</p>
<div class="cell">
<div class="cell-output-display">
<table data-quarto-postprocess="true" class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">Detection</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Detection Model</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Image Source</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Results Output</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Enabled</td>
<td style="text-align: left;">FairFace=Dlib; DeepFace=OpenCV</td>
<td style="text-align: left;">Pre-cropped</td>
<td style="text-align: left;">new_ff_c_p.csv, crop_df_p_opencv.csv</td>
</tr>
<tr class="even">
<td style="text-align: left;">Enabled</td>
<td style="text-align: left;">FairFace=Dlib; DeepFace=OpenCV</td>
<td style="text-align: left;">In-The-Wild</td>
<td style="text-align: left;">new_ff_uc_p.csv, uncropped_df_p_opencv.csv</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Enabled</td>
<td style="text-align: left;">FairFace=Dlib; DeepFace=mtcnn</td>
<td style="text-align: left;">Pre-cropped</td>
<td style="text-align: left;">new_ff_c_p.csv, crop_df_p_mtcnn.csv</td>
</tr>
<tr class="even">
<td style="text-align: left;">Enabled</td>
<td style="text-align: left;">FairFace=Dlib; DeepFace=mtcnn</td>
<td style="text-align: left;">In-The-Wild</td>
<td style="text-align: left;">new_ff_uc_p.csv, uncropped_df_p_mtcnn.csv</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Disabled</td>
<td style="text-align: left;">FairFace,DeepFace=None</td>
<td style="text-align: left;">Pre-cropped</td>
<td style="text-align: left;">new_ff_c_np.csv, cropped_df_np.csv</td>
</tr>
<tr class="even">
<td style="text-align: left;">Disabled</td>
<td style="text-align: left;">FairFace,DeepFace=None</td>
<td style="text-align: left;">In-The-Wild</td>
<td style="text-align: left;">new_ff_uc_np.csv, uncropped_df_np.csv</td>
</tr>
</tbody>
</table>


</div>
</div>
<p>We processed each of the above setting permutations againnst approximately 9800 images, consisting of images from part 1 of 3 from the UTK datset. Each of the cropped images (cropped_UTK_dataset.csv) and uncropped images (uncropped_UTK_dataset.csv) came from the same underlying subject in each image; the only difference between each image was whether or not it was pre-processed before evaluation by each model.</p>
<!--End PC!-->
</section>
<section id="permutation-sample-results-ln-dv" class="level3" data-number="3.5.4">
<h3 data-number="3.5.4" class="anchored" data-anchor-id="permutation-sample-results-ln-dv"><span class="header-section-number">3.5.4</span> Permutation Sample Results (LN &amp; DV)</h3>
<p>(enforcement of facial detection, detection backend model, and cropped images vs.&nbsp;faces in-the-wild)</p>
</section>
<section id="setting-selection" class="level3" data-number="3.5.5">
<h3 data-number="3.5.5" class="anchored" data-anchor-id="setting-selection"><span class="header-section-number">3.5.5</span> Setting Selection</h3>
<!-- PC -->
<p>Upon completion of our evaluation, we determined the settings that gave both models the best chance of success included enabling facial detection with mtcnn for DeepFace and Dlib for FairFace on uncropped images.</p>
<p>From there, we proceeded to process the entirety of the UTK dataset using these settings. The only exception are 4 images that did not conform to UTK’s naming convention to identify age, gender, and race of the subject in the image.</p>
<p>We wrote a script, MasterScript.py, to enable us to perform batch iteration of images and generate output files. When processing, we generated both the non-normalized output content and normalized output content.</p>
<p>Due to the resource-intensive design of FairFace, our script enables multiprocessing of FairFace to allow for multiple simultaneous instances of the FairFace class as a pool of worker threads to iterate over all of the source data.</p>
<p>We attempted the same methodology for DeepFace, but encountered issues with silent errors and halting program execution when iterating over all images using DeepFace. To alleviate this challenge, we processed DeepFace in a single-threaded manner, and with smaller portions of the dataset vs.&nbsp;pursuing an all-in-one go execution. We proceeded to store the data for each of these smaller runs in multiple output files to combine once we completed all processing requirements.</p>
<p>The following table outlines the output files.</p>
<p>The last file, MasterDataFrame.csv, is the final output of our evaluation. This file is in the following format, with the following column definitions:</p>
<div class="cell">
<div class="cell-output-display">
<table data-quarto-postprocess="true" class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">Column Name</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Definition</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Data Type</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">img_path</td>
<td style="text-align: left;">Relative path location of the file within the UTK dataset</td>
<td style="text-align: left;">character vector</td>
</tr>
<tr class="even">
<td style="text-align: left;">file</td>
<td style="text-align: left;">The filename of each file within the UTK dataset</td>
<td style="text-align: left;">character vector</td>
</tr>
<tr class="odd">
<td style="text-align: left;">src_age</td>
<td style="text-align: left;">The age of the subject in each image from the UTK dataset</td>
<td style="text-align: left;">integer</td>
</tr>
<tr class="even">
<td style="text-align: left;">src_gender</td>
<td style="text-align: left;">The gender of the subject in each image from the UTK dataset</td>
<td style="text-align: left;">character vector</td>
</tr>
<tr class="odd">
<td style="text-align: left;">src_race</td>
<td style="text-align: left;">The race of the subject in each image from the UTK datset</td>
<td style="text-align: left;">character vector</td>
</tr>
<tr class="even">
<td style="text-align: left;">src_timestamp</td>
<td style="text-align: left;">The time at which the image was submitted to the UTK dataset</td>
<td style="text-align: left;">character vector</td>
</tr>
<tr class="odd">
<td style="text-align: left;">src_age_grp</td>
<td style="text-align: left;">The age group (matching age ranges from the FairFace outputs) for each image in the UTK dataset</td>
<td style="text-align: left;">character vector</td>
</tr>
<tr class="even">
<td style="text-align: left;">pred_model</td>
<td style="text-align: left;">The model used to produce the predicted output (FairFace or DeepFace)</td>
<td style="text-align: left;">character vector</td>
</tr>
<tr class="odd">
<td style="text-align: left;">pred_race</td>
<td style="text-align: left;">The race of the subject in the image predicted by the given prediction model</td>
<td style="text-align: left;">character vector</td>
</tr>
<tr class="even">
<td style="text-align: left;">pred_gender</td>
<td style="text-align: left;">The gender of the subject in the image predicted by the given prediction model</td>
<td style="text-align: left;">character vector</td>
</tr>
<tr class="odd">
<td style="text-align: left;">pred_age_DF_only</td>
<td style="text-align: left;">The integer-predicted age by DeepFace of the subject in the image</td>
<td style="text-align: left;">integer</td>
</tr>
<tr class="even">
<td style="text-align: left;">pred_age_grp</td>
<td style="text-align: left;">The age group of the subject in the image predicted by the given prediction model</td>
<td style="text-align: left;">character vector</td>
</tr>
<tr class="odd">
<td style="text-align: left;">pred_age_lower</td>
<td style="text-align: left;">The integer lower bound of the predicted age group</td>
<td style="text-align: left;">integer</td>
</tr>
<tr class="even">
<td style="text-align: left;">pred_age_upper</td>
<td style="text-align: left;">The integer upper bound of the predicted age group</td>
<td style="text-align: left;">integer</td>
</tr>
</tbody>
</table>


</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-fairface" class="csl-entry" role="listitem">
Karkkainen, Kimmo, and Jungseock Joo. 2021. <span>“FairFace: Face Attribute Dataset for Balanced Race, Gender, and Age for Bias Measurement and Mitigation.”</span> In <em>Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</em>, 1548–58.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="./data.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Data</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./results.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Results</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>